{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exploration15",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7LsH0cvfxH7"
      },
      "source": [
        "# Exploration15: 한국어 데이터로 챗봇 만들기\n",
        "챗봇 데이터는 송영숙 님이 공개한 챗봇 데이터를 사용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phW7sCzDidyU"
      },
      "source": [
        "## Step1. 데이터 로드하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhMnkrGZeexT"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAqDpUijhNul",
        "outputId": "bac264ea-b335-42e6-a0b8-457524de46d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "U3wTRG7FhNxm",
        "outputId": "247a3c50-0451-4907-d37c-4a1e1d0edfbd"
      },
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/Aiffel/Exploration/Exploration15/ChatbotData.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "print(data.shape)\n",
        "data.head(15)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11823, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SD카드 망가졌어</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SD카드 안돼</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
              "      <td>잘 모르고 있을 수도 있어요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
              "      <td>시간을 정하고 해보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
              "      <td>시간을 정하고 해보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SNS보면 나만 빼고 다 행복해보여</td>\n",
              "      <td>자랑하는 자리니까요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>가끔 궁금해</td>\n",
              "      <td>그 사람도 그럴 거예요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>가끔 뭐하는지 궁금해</td>\n",
              "      <td>그 사람도 그럴 거예요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>가끔은 혼자인게 좋다</td>\n",
              "      <td>혼자를 즐기세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>가난한 자의 설움</td>\n",
              "      <td>돈은 다시 들어올 거예요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Q                   A  label\n",
              "0                    12시 땡!          하루가 또 가네요.      0\n",
              "1               1지망 학교 떨어졌어           위로해 드립니다.      0\n",
              "2              3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
              "3           3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
              "4                   PPL 심하네          눈살이 찌푸려지죠.      0\n",
              "5                 SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0\n",
              "6                   SD카드 안돼  다시 새로 사는 게 마음 편해요.      0\n",
              "7            SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0\n",
              "8   SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0\n",
              "9         SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0\n",
              "10      SNS보면 나만 빼고 다 행복해보여         자랑하는 자리니까요.      0\n",
              "11                   가끔 궁금해       그 사람도 그럴 거예요.      0\n",
              "12              가끔 뭐하는지 궁금해       그 사람도 그럴 거예요.      0\n",
              "13              가끔은 혼자인게 좋다           혼자를 즐기세요.      0\n",
              "14                가난한 자의 설움      돈은 다시 들어올 거예요.      0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imNCb0l-hN0H"
      },
      "source": [
        "## Step 2. 데이터 전처리하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9BGQKDmkPsF"
      },
      "source": [
        "전처리는 정규표현식(Regular Expression)을 사용하여 구두점(punctuation)을 제거하며 단어를 토크나이징(tokenizing)하는 일에 방해가 되지 않도록 만드는 것을 목표로 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiTds7knimTl"
      },
      "source": [
        "데이터를 로드하는 동시에 전처리 함수를 호출하여 질문과 답변의 쌍을 전처리합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQG7Gmo_vh1P"
      },
      "source": [
        "# 전처리 함수\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "\n",
        "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
        "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
        "    # student와 온점 사이에 거리를 만듭니다.\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "\n",
        "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
        "    sentence = re.sub(r\"[^ㄱ-ㅣ가-힣a-zA-Z0-9?.!,]+\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    return sentence"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ky3nsk1Tvi79",
        "outputId": "61ce220a-18bd-488c-8d63-4c5d7080dfbd"
      },
      "source": [
        "questions = data['Q']\n",
        "questions = questions.values\n",
        "\n",
        "answers = data['A']\n",
        "answers = answers.values\n",
        "\n",
        "print(questions)\n",
        "print(answers)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['12시 땡!' '1지망 학교 떨어졌어' '3박4일 놀러가고 싶다' ... '흑기사 해주는 짝남.'\n",
            " '힘든 연애 좋은 연애라는게 무슨 차이일까?' '힘들어서 결혼할까봐']\n",
            "['하루가 또 가네요.' '위로해 드립니다.' '여행은 언제나 좋죠.' ... '설렜겠어요.'\n",
            " '잘 헤어질 수 있는 사이 여부인 거 같아요.' '도피성 결혼은 하지 않길 바라요.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShTLVycZvKKc",
        "outputId": "21c68c24-4d97-4009-a763-13a8e0d767a5"
      },
      "source": [
        "questions = list(map(preprocess_sentence, questions))\n",
        "questions[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['12시 땡 !',\n",
              " '1지망 학교 떨어졌어',\n",
              " '3박4일 놀러가고 싶다',\n",
              " '3박4일 정도 놀러가고 싶다',\n",
              " 'ppl 심하네',\n",
              " 'sd카드 망가졌어',\n",
              " 'sd카드 안돼',\n",
              " 'sns 맞팔 왜 안하지ㅠㅠ',\n",
              " 'sns 시간낭비인 거 아는데 매일 하는 중',\n",
              " 'sns 시간낭비인데 자꾸 보게됨']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsFHgCU9vKNK",
        "outputId": "4e8b7e9f-8620-4421-a643-148293bf4ed1"
      },
      "source": [
        "answers = list(map(preprocess_sentence, answers))\n",
        "answers[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['하루가 또 가네요 .',\n",
              " '위로해 드립니다 .',\n",
              " '여행은 언제나 좋죠 .',\n",
              " '여행은 언제나 좋죠 .',\n",
              " '눈살이 찌푸려지죠 .',\n",
              " '다시 새로 사는 게 마음 편해요 .',\n",
              " '다시 새로 사는 게 마음 편해요 .',\n",
              " '잘 모르고 있을 수도 있어요 .',\n",
              " '시간을 정하고 해보세요 .',\n",
              " '시간을 정하고 해보세요 .']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9MZfmqfvKPQ",
        "outputId": "e27a2672-febc-47f2-aa2c-c6831458e0c0"
      },
      "source": [
        "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
        "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
            "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n21ZAVPhN1-"
      },
      "source": [
        "## Step 3. SubwordTextEncoder 사용하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdlvsF_Bp6SN"
      },
      "source": [
        "### 병렬 데이터 전처리하기\n",
        "질문과 답변의 셋을 각각 question과 answers에 저장했으므로 전처리를 진행합니다.  \n",
        "1. TensorFlow Dataset SubwordTextEncoder를 토크나이저로 사용한다. 단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고 각 토큰을 고유한 정수로 인코딩한다.  \n",
        "2. 각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는 START_TOKEN 및 END_TOKEN을 추가한다.  \n",
        "3. 최대 길이 MAX_LENGTH를 넘을 문장들은 필터링한다.  \n",
        "4. MAX_LENGTH보다 짧은 문장들은 MAX_LENGTH에 맞도록 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9jlfZ1ap6VF"
      },
      "source": [
        "단어장 만들기  \n",
        "각 단어에 고유한 정수 인덱스를 부여하기 위해서 단어장(Vocabulary)을 만듭니다. 단어장을 만들 때는 질문과 답변 데이터셋을 모두 사용하여 만듭니다.  \n",
        "한국어 데이터는 형태소 분석기를 사용해 토크나이징을 진행하지만 여기서는 형태소 분석기가 아닌 내부 단어 토크나이저인 SubwordTextEncoder를 사용하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHsqLpyHp6X1"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# 질문과 답변 데이터셋에 대해서 Vocabulary생성.\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions+answers, target_vocab_size=2**13)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEfUpKkGp6ct"
      },
      "source": [
        "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbnot34Ep6fd",
        "outputId": "00ffc010-d2c8-48a0-ee67-89c8d76bc0a7"
      },
      "source": [
        "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
        "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START_TOKEN의 번호 : [8170]\n",
            "END_TOKEN의 번호 : [8171]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx2FAAVep6h-"
      },
      "source": [
        "각각 8170과 8171라는 점에서 현재 단어장의 크기가 8170(0번부터 8169번)이라는 의미입니다.  \n",
        "두 개의 토큰을 추가해 주었기 때문에 단어장의 크기도 +2임을 명시해 주어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmBWZ0x_p6pN",
        "outputId": "09c98ed4-54a4-4487-8e17-b5064b82f20c"
      },
      "source": [
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "print(VOCAB_SIZE)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BeYTvZ0p6rv"
      },
      "source": [
        "### 각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(Padding)\n",
        "tokenizer.encode()로 각 단어를 정수로 변환할 수 있고 또는 tokenizer.decode()를 통해 정수 시퀀스를 단어 시퀀스로 변환할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD6C1CDc21D8",
        "outputId": "a4b26d37-e6c8-40e6-8f3c-8b25ca1f5fc9"
      },
      "source": [
        "# 사용 예시. 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
        "# 각 토큰을 고유한 정수로 변환\n",
        "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
        "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정수 인코딩 후의 21번째 질문 샘플: [5761, 610, 2490, 4163]\n",
            "정수 인코딩 후의 21번째 답변 샘플: [2356, 7510, 7, 6273, 97, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4UpCSeS21Gz"
      },
      "source": [
        "각 단어에 고유한 정수가 부여된 Vocabulary를 기준으로 단어 시퀀스가 정수 시퀀스로 인코딩된 결과를 확인할 수 있습니다.  \n",
        "위의 결과와 마찬가지로 질문과 답변 셋에 대해서 전부 정수 인코딩을 수행합니다. 동시에 문장의 최대 길이를 정하고 해당 길이로 패딩(padding)합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSeJc4WK6J_o"
      },
      "source": [
        "questions_len = [len(i.split()) for i in questions]\n",
        "answers_len = [len(i.split()) for i in answers]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqoszGnW6J9m",
        "outputId": "72e9ca54-572a-408c-e175-9072be80825f"
      },
      "source": [
        "print('질문의 최소 길이: {}'.format(np.min(questions_len)))\n",
        "print('질문의 최대 길이: {}'.format(np.max(questions_len)))\n",
        "print('질문의 평균 길이: {}'.format(np.mean(questions_len)))\n",
        "\n",
        "print('답변의 평균 길이: {}'.format(np.min(answers_len)))\n",
        "print('답변의 평균 길이: {}'.format(np.max(answers_len)))\n",
        "print('답변의 평균 길이: {}'.format(np.mean(answers_len)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문의 최소 길이: 1\n",
            "질문의 최대 길이: 16\n",
            "질문의 평균 길이: 3.9409625306605767\n",
            "답변의 평균 길이: 1\n",
            "답변의 평균 길이: 24\n",
            "답변의 평균 길이: 4.716146494121627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqBIGeYy21J7",
        "outputId": "e937f535-0f37-4000-d283-51de2103eac8"
      },
      "source": [
        "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
        "MAX_LENGTH = 26\n",
        "print(MAX_LENGTH)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz76Cf703hbD"
      },
      "source": [
        "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "\n",
        "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  \n",
        "  return tokenized_inputs, tokenized_outputs"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3xtWozb3hd7",
        "outputId": "9f352a50-1656-4264-848e-bd99ede3577d"
      },
      "source": [
        "questions, answers = tokenize_and_filter(questions, answers)\n",
        "print('단어장의 크기 :',(VOCAB_SIZE))\n",
        "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
        "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어장의 크기 : 8172\n",
            "필터링 후의 질문 샘플 개수: 11819\n",
            "필터링 후의 답변 샘플 개수: 11819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YUnu62IhN4i"
      },
      "source": [
        "## Step 4. 모델 구성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5KcGaKz--EW"
      },
      "source": [
        "### 포지셔널 인코딩 레이어(Positional Encoding Layer)\n",
        "트랜스포머는 덱스트 문장을 입력으로 받기 위해 단어를 임베딩 벡터로 변환하는 벡터화 과정을 거칩니다.  \n",
        "하지만 트랜스포머 모델은 임베딩 벡터에 어떤 값을 더해준 뒤에 입력으로 사용한다는 점에서 다른 모델과 다릅니다.이는 포지셔널 인코딩(Prositional Encoding)에 해당하는 부분입니다.  \n",
        "문장의 모든 단어를 한꺼번에 문장 단위로 입력받는 트랜스포머는 'I ate lunch'와 'lunch ate I'를 구분할 수 없을 수 있기에 같은 단어라도 그 단어가 문장의 몇 번째 어순으로 입력되었는지를 알려주기 위해 위치 정보를 가진 벡터(Positional Encoding)값을 더해서 모델의 입력으로 삼는 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InVfTq9I_CST"
      },
      "source": [
        "# 포지셔널 인코딩 레이어\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, position, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "    def get_angles(self, position, i, d_model):\n",
        "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "        return position * angles\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "        # 각도 배열 생성\n",
        "        angle_rads = self.get_angles(\n",
        "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "            d_model=d_model)\n",
        "\n",
        "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
        "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
        "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        # sin과 cosine이 교차되도록 재배열\n",
        "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
        "        pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
        "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
        "\n",
        "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "        return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKbf9VPv_CVL"
      },
      "source": [
        "행의 크기가 50, 열의 크기가 512인 행렬을 만들어 봅니다.  \n",
        "이는 최대 문장의 길이가 50이고 워드 임베딩 차원이 512인 모델의 입력 벡터 모양과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "MTOqJ8ye_CXW",
        "outputId": "53eacbfd-ef49-4ab2-8006-a6a5857e7464"
      },
      "source": [
        "sample_pos_encoding = PositionalEncoding(50, 512)\n",
        "\n",
        "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVaWEKMt_CZ1"
      },
      "source": [
        "### 어텐션 메커니즘\n",
        "어텐션 함수는 주어진 쿼리(Query)에 대해서 모든 키(Key)와의 유사도를 각각 구합니다. 이후 구해낸 유사도를 키와 맵핑되어있는 각각의 값(Value)에 반영해 줍니다.  \n",
        "그리고 유사도가 반영된 값을 모두 더해서 뭉쳐주면 최종 결과인 어텐션 값(Attention Value)를 얻을 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J177IMr_T-7"
      },
      "source": [
        "트랜스포머는 총 세 가지 어텐션을 사용합니다.\n",
        "* 첫번째: 인코더 셀프 어텐션은 인코더에서 이루어지고\n",
        "* 두번째: 디코더 셀프 어텐션은 디코더에서 이루어지며\n",
        "* 세번째: 인코더-디코더 어텐션 또한 디코더에서 이루어집니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfySPuwF_UBb"
      },
      "source": [
        "트랜스포머의 어텐션 함수에 사용되는 쿼리(Query), 키(Key), 벨류(Value)는 기본적으로 '단어(정보를 함축한)벡터'입니다.  \n",
        "이 단어벡터란 초기 입력으로 사용되었던 임베딩 벡터가 아닌 트랜스포머의 여러 연산을 거친 후의 단어벡터 입니다.  \n",
        "그럼 위 세 가지 어텐션이 하는 일을 조금 더 자세히 알아보겠습니다.\n",
        "* 인코더 셀프 어텐션: 인코더의 입력으로 들어간 문장 내 단어들이 서로 유사도를 구한다.\n",
        "* 디코더 셀프 어텐션: 단어를 1개씩 생성하는 디코더가 이미 생성된 앞 단어들과의 유사도를 구한다.\n",
        "* 인코더-디코더 어텐션: 디코더가 잘 예측하기 위해서 인코더에 입력된 단어들과 유사도를 구한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5A7ZhbC_Z6L"
      },
      "source": [
        "**셀프 어텐션(Self Attention)**  \n",
        "셀프 어텐션이란 다른 문장의 단어가 아닌 현재 문장 내의 단어들이 서로 유사도를 구하는 것을 의미합니다.  \n",
        "The animal didn't cross the street bacause it was too tired.  \n",
        "여기서 It은 animal을 지칭하는데, 기계는 그렇지 않습니다. 셀프 어텐션은 문장 내의 단어들끼리 유사도를 구하여 it이 animal과 연관되었을 확률이 높다는 것을 찾아냅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKP-5wOH_Z9D"
      },
      "source": [
        "**스케일드 닷 프로덕트 어텐션(Scaled Dot Product Attention)**  \n",
        "문장행렬Q * 문장행렬K = 유사도 행렬 (단어 벡터의 유사도가 기록된 행렬)  \n",
        "softmax((유사도 행렬 / 차원 수 (Normalization) ) * 문장행렬V) = 어텐션 값 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn7aFRbS_Z_6"
      },
      "source": [
        "# 스케일드 닷 프로덕트 어텐션 함수\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
        "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "    # 가중치를 정규화\n",
        "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "    logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "    # 패딩에 마스크 추가\n",
        "    if mask is not None:\n",
        "        logits += (mask * -1e9)\n",
        "\n",
        "    # softmax적용\n",
        "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
        "    output = tf.matmul(attention_weights, value)\n",
        "    return output"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVIx0BFe_UEn"
      },
      "source": [
        "**병렬로 어텐션 수행하기**  \n",
        "트랜스포머에서 num_heads라는 변수는 기계가 몇 개의 병렬적인 어텐션 연산을 수행할지 결정하는 파라미터입니다.  \n",
        "트랜스포머의 초기 입력인 문장 행렬의 크기는 문장의 길이를 행으로, d_model을 열의 크기로 가집니다. 이렇게 입력된 문장 행렬을 num_heads의 수만큼 쪼개서 어텐션을 수행하고, 각각의 값 행렬을 다시 하나로 concatenate합니다.  \n",
        "이렇게 함으로써 it라는 토큰을 animal, sreet이라고 보는 각각의 관점을 한꺼번에 얻을 수 있습니다.  \n",
        "이처럼 어텐션을 병렬로 수행하는 것을 멀티 헤드 어텐션이라고 부릅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffIRJnkr_UGY"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "        super(MultiHeadAttention, self).__init__(name=name)\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    def split_heads(self, inputs, batch_size):\n",
        "        inputs = tf.reshape(\n",
        "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "            'value'], inputs['mask']\n",
        "        batch_size = tf.shape(query)[0]\n",
        "\n",
        "        # Q, K, V에 각각 Dense를 적용합니다\n",
        "        query = self.query_dense(query)\n",
        "        key = self.key_dense(key)\n",
        "        value = self.value_dense(value)\n",
        "\n",
        "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "\n",
        "        # 스케일드 닷 프로덕트 어텐션 함수\n",
        "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
        "        concat_attention = tf.reshape(scaled_attention,\n",
        "                              (batch_size, -1, self.d_model))\n",
        "\n",
        "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
        "        outputs = self.dense(concat_attention)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q11Iw-RH_CcF"
      },
      "source": [
        "### 마스킹\n",
        "마스킹(Masking)은 특정 값들을 가려서 실제 연산에 방해가 되지 않도록 하는 기법입니다.  \n",
        "트랜스포머에서는 어텐션을 위해 크게 두 가지 마스킹을 사용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwREHd3q_vYi"
      },
      "source": [
        "**패딩 마스킹(Padding masking)**  \n",
        "0으로 이루어진 패딩은 실제 의미가 있는 다넝가 아니므로 어텐션 연산에서는 제외할 필요가 있습니다.  \n",
        "패딩 마스킹은 이를 위해 숫자 0인 위치를 체크합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drlrItjg_vba"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "    # (batch_size, 1, 1, sequence length)\n",
        "    return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwjKEViX_veL"
      },
      "source": [
        "이 함수에 정수 시퀀스를 입력으로 하면 숫자가 0인 부분을 체크한 벡터를 리턴합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgFHH9B9_2jK",
        "outputId": "f015cdcf-ea1e-41f5-e6c8-9bfa846ab5b9"
      },
      "source": [
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44KcNsNp_7FK"
      },
      "source": [
        "**룩 어헤드 마스킹(Look-ahead masking, 다음 단어 가리기)**  \n",
        "RNN과 트랜스포머는 문장을 입력받는 방법이 전혀 다릅니다.  \n",
        "RNN은 각 step마다 단어가 순서대로 입력으로 들어가는 반면 트랜스포머의 경우 문장 행렬을 만들어 한 번에 행렬 형태의 입력이 들어갑니다.  \n",
        "우리가 원하는 것은 이전 단어들로부터 다음 단어를 예측하는 것이기 때문에 자신보다 다음에 나올 단어를 참고하지 않도록 가리는 기법이 룩어헤드 마스킹 기법입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RILGh0VG_7Hq"
      },
      "source": [
        "def create_look_ahead_mask(x):\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "    padding_mask = create_padding_mask(x)\n",
        "    return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F8rdyYO_7J1",
        "outputId": "bf837553-ecd8-4347-ff19-881da7ad7a07"
      },
      "source": [
        "# 테스트\n",
        "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1.]\n",
            "   [0. 0. 0. 0. 1.]\n",
            "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwiAWlCz_7Mb",
        "outputId": "c4f62601-b660-4ec4-a992-4ba80ee529cd"
      },
      "source": [
        "print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[1. 1. 1. 1. 1.]\n",
            "   [1. 0. 1. 1. 1.]\n",
            "   [1. 0. 0. 1. 1.]\n",
            "   [1. 0. 0. 0. 1.]\n",
            "   [1. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSsOuIyQ9_lc"
      },
      "source": [
        "### 인코더\n",
        "하나의 인코더 층은 크게 총 2개의 서브층(sublayer)으로 나누어집니다.  \n",
        "그것은 셀프 어텐션과 피드 포워드 신경망인데, 셀프어텐션은 멀티 헤드 어텐션으로 병렬적으로 이루어집니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuQVk0xt9_oE"
      },
      "source": [
        "# 인코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "    # 패딩 마스크 사용\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "    attention = MultiHeadAttention(\n",
        "        d_model, num_heads, name=\"attention\")({\n",
        "        'query': inputs,\n",
        "        'key': inputs,\n",
        "        'value': inputs,\n",
        "        'mask': padding_mask\n",
        "        })\n",
        "\n",
        "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
        "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "    attention = tf.keras.layers.LayerNormalization(\n",
        "        epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
        "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(\n",
        "        epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "    return tf.keras.Model(\n",
        "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIqxvCAm9_qL"
      },
      "source": [
        "**인코더 층을 쌓아 인코더 만들기**  \n",
        "인코더 층을 임베딩 층과 포지셔널 인코딩을 연결하고 원하는 만큼 인코더 층을 쌓음으로써 트랜스포머의 인코더가 완성됩니다.  \n",
        "인코더와 디코더 내부에는 각 서브 층 이후에 훈련을 돕는 Layer Normalization이라는 테크닉이 사용되었습니다.  \n",
        "트랜스포머는 하이퍼파라미터인 num_layers 개수의 인코더 층을 쌓습니다. 학습시간을 고려해 적은 개수를 사용하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VugaMXk69_su"
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "    # 패딩 마스크 사용\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    # 임베딩 레이어\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "    # 포지셔널 인코딩\n",
        "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    # num_layers만큼 쌓아올린 인코더의 층.\n",
        "    for i in range(num_layers):\n",
        "        outputs = encoder_layer(\n",
        "            units=units,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            name=\"encoder_layer_{}\".format(i),\n",
        "            )([outputs, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(\n",
        "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-zA3EEw21Rc"
      },
      "source": [
        "### 디코더\n",
        "디코더는 인코더와 비슷하지만 세 개의 서브 층으로 구성된다는 점에서 조금 더 복잡합니다.\n",
        "1. 셀프 어텐션  \n",
        "2. 인코더-디코더 어텐션  \n",
        "3. 피드 포워드 신경망  \n",
        "인코더-디코더 어텐션은 셀프 어텐션과는 달리 Query가 디코더의 벡터인 반면 Key와 Value가 인코더의 벡터라는 특징이 있습니다. 이 부분이 인코더가 입력 문장으로부터 정보를 디코더에 전달하는 과정입니다.  \n",
        "인코더의 셀프 어텐션과 마찬가지로 디코더의 셀프 어텐션, 인코더-디코더 어텐션, 두 가지 모두 스케일드 닷 프로덕트 어텐션을 멀티 헤드 어텐션으로 병렬적으로 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi8oj8Zmp6uQ"
      },
      "source": [
        "# 디코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "    look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "    attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "\n",
        "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "    attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
        "    attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
        "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "    attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
        "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "    outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "    return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23fv_Dyk-fnT"
      },
      "source": [
        "**디코더 층을 쌓아 디코더 만들기**  \n",
        "디코더의 층은 임베딩 층(Embedding layer)과 포지셔널 인코딩(Positional Encoding)을 연결하고 디코더 층을 쌓아 만듭니다.  \n",
        "위의 인코더와 유사하게 구성해 줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gDM2q_o-fqa"
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "    look_ahead_mask = tf.keras.Input(\n",
        "        shape=(1, None, None), name='look_ahead_mask')\n",
        "\n",
        "    # 패딩 마스크\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "    # 임베딩 레이어\n",
        "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "    # 포지셔널 인코딩\n",
        "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        outputs = decoder_layer(\n",
        "            units=units,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            name='decoder_layer_{}'.format(i),\n",
        "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "    return tf.keras.Model(\n",
        "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "        outputs=outputs,\n",
        "        name=name)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JssKLI5B-fs_"
      },
      "source": [
        "### 모델 정의 및 학습하기\n",
        "인코더 층 함수와 디코더 층 함수를 사용하여 트랜스포머 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax0OHvF2-fvL"
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "    # 인코더에서 패딩을 위한 마스크\n",
        "    enc_padding_mask = tf.keras.layers.Lambda(\n",
        "        create_padding_mask, output_shape=(1, 1, None),\n",
        "        name='enc_padding_mask')(inputs)\n",
        "\n",
        "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
        "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
        "    look_ahead_mask = tf.keras.layers.Lambda(\n",
        "        create_look_ahead_mask,\n",
        "        output_shape=(1, None, None),\n",
        "        name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
        "    # 디코더에서 패딩을 위한 마스크\n",
        "    dec_padding_mask = tf.keras.layers.Lambda(\n",
        "        create_padding_mask, output_shape=(1, 1, None),\n",
        "        name='dec_padding_mask')(inputs)\n",
        "\n",
        "    # 인코더\n",
        "    enc_outputs = encoder(\n",
        "        vocab_size=vocab_size,\n",
        "        num_layers=num_layers,\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "    )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "    # 디코더\n",
        "    dec_outputs = decoder(\n",
        "        vocab_size=vocab_size,\n",
        "        num_layers=num_layers,\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "    # 완전연결층\n",
        "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD13IXaT-fxu"
      },
      "source": [
        "**모델 생성**  \n",
        "num_layers, d-model, units는 전부 사용자가 정할 수 있는 하이퍼파라미터 값입니다.  \n",
        "실제 사용되는 것보다 작은 값을 사용하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZI3lPiX-ueM",
        "outputId": "2e880326-ce5f-4518-c322-39940213f748"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inputs (InputLayer)             [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "encoder (Functional)            (None, None, 256)    3146240     inputs[0][0]                     \n",
            "                                                                 enc_padding_mask[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Functional)            (None, None, 256)    3673600     dec_inputs[0][0]                 \n",
            "                                                                 encoder[0][0]                    \n",
            "                                                                 look_ahead_mask[0][0]            \n",
            "                                                                 dec_padding_mask[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "outputs (Dense)                 (None, None, 8172)   2100204     decoder[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,920,044\n",
            "Trainable params: 8,920,044\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1KneaNS-ug6"
      },
      "source": [
        "**손실함수(Loss function)**  \n",
        "레이블인 시퀀스에 패딩이 되어 있으므로 loss를 계산할 때 패딩 마스크를 적용해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo4ii3i--ukB"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "    \n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')(y_true, y_pred)\n",
        "    \n",
        "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "    loss = tf.multiply(loss, mask)\n",
        "    \n",
        "    return tf.reduce_mean(loss)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wuq4zNOv-f0b"
      },
      "source": [
        "**커스텀 된 학습률(Learning rate)**  \n",
        "딥러닝 모델 학습 시 learning rate는 매우 중요한 하이퍼파라미터입니다.  \n",
        "커스텁 학습률 스케쥴링(Custom Learning rate Scheduling)을 사용하면 적합한 lr을 찾을 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZvEfbfEAXJb"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    \n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "        \n",
        "        self.warmup_steps = warmup_steps\n",
        "        \n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps**-1.5)\n",
        "        \n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "hmO7BcgBAXML",
        "outputId": "2ff98aa8-c5a8-450b-b646-07b5ed219b28"
      },
      "source": [
        "# lr 시각화\n",
        "sample_learning_rate = CustomSchedule(d_model=128)\n",
        "\n",
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y6r9PrHAXPL"
      },
      "source": [
        "**모델 컴파일**  \n",
        "손실 함수와 커스텀 된 학습률을 사용하여 모델을 컴파일 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2jubCSLAXRj"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    y_ture = tf.reshape(y_true, shape=(-1, MAX_LENGTH -1))\n",
        "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWs0zzWjC-mn"
      },
      "source": [
        "**교사 강요(Teacher Forcing) 사용하기**  \n",
        "tf.data.Dataset API는 훈련 프로세스의 속도가 빨라지도록 입력 파이프라인을 구축하는 API입니다.  \n",
        "이를 사용하기 위해서 질문과 답변의 쌍을 tf.data.Dataset의 입력으로 넣어주는 작업을 합니다.  \n",
        "이 때 디코거의 입력과 실제값(레이블)을 정의해 주기 위해서는 교사 강요(Teacher Forcing) 언어 모델의 훈련 기법을 사용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3FR4mPUDGPD"
      },
      "source": [
        "질문과 답변의 쌍을 tf.data.Dataset API의 입력으로 사용하여 파이프라인을 구성합니다. 이때, 교사 강요를 위해서 answers[:, :-1]를 디코더의 입력값, answers[:, 1:]를 디코더의 레이블로 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD35aLPtDH2E"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
        "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7H7J8dWCN4m",
        "outputId": "c10afb19-4e2a-4983-cf47-98f3ddf338ad"
      },
      "source": [
        "EPOCHS = 30\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "185/185 [==============================] - 16s 89ms/step - loss: 1.3810 - accuracy: 0.0883\n",
            "Epoch 2/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 1.2863 - accuracy: 0.0947\n",
            "Epoch 3/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 1.1842 - accuracy: 0.1040\n",
            "Epoch 4/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 1.0721 - accuracy: 0.1155\n",
            "Epoch 5/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 0.9525 - accuracy: 0.1283\n",
            "Epoch 6/30\n",
            "185/185 [==============================] - 16s 89ms/step - loss: 0.8275 - accuracy: 0.1425\n",
            "Epoch 7/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 0.6998 - accuracy: 0.1578\n",
            "Epoch 8/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 0.5742 - accuracy: 0.1744\n",
            "Epoch 9/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 0.4550 - accuracy: 0.1917\n",
            "Epoch 10/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 0.3493 - accuracy: 0.2075\n",
            "Epoch 11/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 0.2586 - accuracy: 0.2226\n",
            "Epoch 12/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 0.1881 - accuracy: 0.2355\n",
            "Epoch 13/30\n",
            "185/185 [==============================] - 16s 87ms/step - loss: 0.1368 - accuracy: 0.2446\n",
            "Epoch 14/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 0.1040 - accuracy: 0.2504\n",
            "Epoch 15/30\n",
            "185/185 [==============================] - 16s 87ms/step - loss: 0.0832 - accuracy: 0.2543\n",
            "Epoch 16/30\n",
            "185/185 [==============================] - 16s 87ms/step - loss: 0.0729 - accuracy: 0.2559\n",
            "Epoch 17/30\n",
            "185/185 [==============================] - 16s 87ms/step - loss: 0.0674 - accuracy: 0.2566\n",
            "Epoch 18/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 0.0645 - accuracy: 0.2572\n",
            "Epoch 19/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 0.0586 - accuracy: 0.2583\n",
            "Epoch 20/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 0.0508 - accuracy: 0.2602\n",
            "Epoch 21/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 0.0460 - accuracy: 0.2614\n",
            "Epoch 22/30\n",
            "185/185 [==============================] - 16s 87ms/step - loss: 0.0382 - accuracy: 0.2632\n",
            "Epoch 23/30\n",
            "185/185 [==============================] - 16s 87ms/step - loss: 0.0346 - accuracy: 0.2642\n",
            "Epoch 24/30\n",
            "185/185 [==============================] - 16s 87ms/step - loss: 0.0329 - accuracy: 0.2646\n",
            "Epoch 25/30\n",
            "185/185 [==============================] - 16s 87ms/step - loss: 0.0297 - accuracy: 0.2653\n",
            "Epoch 26/30\n",
            "185/185 [==============================] - 16s 87ms/step - loss: 0.0257 - accuracy: 0.2665\n",
            "Epoch 27/30\n",
            "185/185 [==============================] - 16s 87ms/step - loss: 0.0245 - accuracy: 0.2668\n",
            "Epoch 28/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 0.0227 - accuracy: 0.2673\n",
            "Epoch 29/30\n",
            "185/185 [==============================] - 16s 88ms/step - loss: 0.0212 - accuracy: 0.2675\n",
            "Epoch 30/30\n",
            "185/185 [==============================] - 16s 87ms/step - loss: 0.0196 - accuracy: 0.2681\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d6f0c1c90>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4h9FOqqhN7W"
      },
      "source": [
        "## Step 5. 모델 평가하기\n",
        "예측(inference) 단계는 기본적으로 다음과 같은 과정을 거칩니다.  \n",
        "1. 새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거친다.  \n",
        "2. 입력 문장을 토크나이징하고, START_TOKEN과 END_TOKEN을 추가한다.\n",
        "3. 패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
        "4. 디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
        "5. 디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
        "6. END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tC9iyQUiMaG"
      },
      "source": [
        "def decoder_inference(sentence):\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
        "    sentence = tf.expand_dims(\n",
        "    START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
        "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장.\n",
        "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "    # 디코더의 인퍼런스 단계\n",
        "    for i in range(MAX_LENGTH):\n",
        "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
        "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
        "        predictions = predictions[:, -1:, :]\n",
        "\n",
        "        # 현재 예측한 단어의 정수\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
        "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "            break\n",
        "\n",
        "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
        "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
        "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output_sequence, axis=0)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J0ycWM9BI9L"
      },
      "source": [
        "임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 sentence_generation() 함수를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfgVDPUiBPI5"
      },
      "source": [
        "def sentence_generation(sentence):\n",
        "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴 받습니다.\n",
        "    prediction = decoder_inference(sentence)\n",
        "    \n",
        "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
        "    predicted_sentence = tokenizer.decode(\n",
        "        [i for i in prediction if i < tokenizer.vocab_size])\n",
        "    \n",
        "    print('입력 : {}'.format(sentence))\n",
        "    print('출력 : {}'.format(predicted_sentence))\n",
        "    \n",
        "    return predicted_sentence"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "v6GZYaY1BPpy",
        "outputId": "4d736b41-966a-419a-e311-54990652b373"
      },
      "source": [
        "sentence_generation('비오는데 너무 심심해. 할 거 없나?')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 비오는데 너무 심심해. 할 거 없나?\n",
            "출력 : 노래 불러 드릴까요 ? 북치기박치기 헥헥헥헥헥헥헥헥헥헥헥헥헥헥헥헥\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'노래 불러 드릴까요 ? 북치기박치기 헥헥헥헥헥헥헥헥헥헥헥헥헥헥헥헥'"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "2V0mKVchBPsm",
        "outputId": "e239ec25-d8ec-4240-d941-6c4995f8c4b2"
      },
      "source": [
        "sentence_generation('큰 북을 울려라 둥둥둥')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 큰 북을 울려라 둥둥둥\n",
            "출력 : 상처받고 있다고 말해보세요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'상처받고 있다고 말해보세요 .'"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "nD6qPt4jHyI_",
        "outputId": "30634bb9-fdb7-41fc-c71b-4895e98f391d"
      },
      "source": [
        "sentence_generation('상처받고 있어 너 때문에')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 상처받고 있어 너 때문에\n",
            "출력 : 먼저 다가가는 건 어떨까요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'먼저 다가가는 건 어떨까요 .'"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "HhuJsBH8H3Or",
        "outputId": "ba57a0fc-c1b5-4c5f-c747-0b2edd850d76"
      },
      "source": [
        "sentence_generation('도대체 무슨 소리를 하는거야')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 도대체 무슨 소리를 하는거야\n",
            "출력 : 당신이 사랑이라고 생각하는 경향이 있나 봅니다 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'당신이 사랑이라고 생각하는 경향이 있나 봅니다 .'"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "K-6nSD-rIR0k",
        "outputId": "6ac9ab60-8496-46f5-f31c-778f2532bc35"
      },
      "source": [
        "sentence_generation('우리는 이루어질 수 없는 사이야 미안해')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 우리는 이루어질 수 없는 사이야 미안해\n",
            "출력 : 이제 짝사랑 말고 둘이서 하는 사랑하세요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'이제 짝사랑 말고 둘이서 하는 사랑하세요 .'"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV2ZHFR2IVus"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8BDaympIZ54"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}