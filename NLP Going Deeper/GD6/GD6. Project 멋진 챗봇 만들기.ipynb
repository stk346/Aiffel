{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "foreign-tuition",
   "metadata": {},
   "source": [
    "# Project: 멋진 챗봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-seminar",
   "metadata": {},
   "source": [
    "지난 노드에서 챗봇과 번역기는 같은 집안이라고 했던 말을 기억하시나요?  \n",
    "앞서 배운 Seq2seq번역기와 Transfomer번역기에 적용할 수도 있겠지만, 이번 노드에서 배운 번역기 성능 측정법을 챗봇에도 적용해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-domestic",
   "metadata": {},
   "source": [
    "Step 1. 데이터 다운로드\n",
    "아래 링크에서 ChatbotData.csv 를 다운로드해 챗봇 훈련 데이터를 확보합니다. csv 파일을 읽는 데에는 pandas 라이브러리가 적합합니다. 읽어 온 데이터의 질문과 답변을 각각 questions, answers 변수에 나눠서 저장하세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-boundary",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "infrared-prescription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "curl is already the newest version (7.58.0-2ubuntu3.16).\n",
      "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
      "python3-dev is already the newest version (3.6.7-1~18.04).\n",
      "openjdk-8-jdk is already the newest version (8u292-b10-0ubuntu1~18.04).\n",
      "python3-pip is already the newest version (9.0.1-2.3~ubuntu1.18.04.5).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 86 not upgraded.\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (21.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: konlpy in /opt/conda/lib/python3.7/site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.7/site-packages (from konlpy) (1.19.5)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (1.2.1)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (4.6.2)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /opt/conda/lib/python3.7/site-packages (from konlpy) (3.10.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from konlpy) (0.4.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /opt/conda/lib/python3.7/site-packages (from tweepy>=3.7.0->konlpy) (2.25.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.26.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "curl is already the newest version (7.58.0-2ubuntu3.16).\n",
      "git is already the newest version (1:2.17.1-1ubuntu0.9).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 86 not upgraded.\n",
      "mecab-ko is already installed\n",
      "mecab-ko-dic is already installed\n",
      "mecab-python is already installed\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "! sudo apt-get install g++ openjdk-8-jdk python3-dev python3-pip curl\n",
    "! python3 -m pip install --upgrade pip\n",
    "! python3 -m pip install konlpy\n",
    "! sudo apt-get install curl git\n",
    "! bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sharp-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import gensim\n",
    "from konlpy.tag import Mecab\n",
    "from tqdm import tqdm_notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "external-experience",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SD카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
       "      <td>잘 모르고 있을 수도 있어요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Q                   A  label\n",
       "0                   12시 땡!          하루가 또 가네요.      0\n",
       "1              1지망 학교 떨어졌어           위로해 드립니다.      0\n",
       "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
       "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
       "4                  PPL 심하네          눈살이 찌푸려지죠.      0\n",
       "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0\n",
       "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0\n",
       "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0\n",
       "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0\n",
       "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.getenv(\"HOME\") + '/aiffel/transformer_chatbot/data/ChatbotData .csv'\n",
    "\n",
    "dataset = pd.read_csv(file_path)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "british-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = dataset['Q'], dataset['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "certified-division",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         12시 땡!\n",
       "1                    1지망 학교 떨어졌어\n",
       "2                   3박4일 놀러가고 싶다\n",
       "3                3박4일 정도 놀러가고 싶다\n",
       "4                        PPL 심하네\n",
       "                  ...           \n",
       "11818             훔쳐보는 것도 눈치 보임.\n",
       "11819             훔쳐보는 것도 눈치 보임.\n",
       "11820                흑기사 해주는 짝남.\n",
       "11821    힘든 연애 좋은 연애라는게 무슨 차이일까?\n",
       "11822                 힘들어서 결혼할까봐\n",
       "Name: Q, Length: 11823, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-benjamin",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 정제\n",
    "1. 영문자의 경우, 모두 소문자로 변환합니다.  \n",
    "2. 영문자와 한글, 숫자, 그리고 주요 특수문자를 제외하곤 정규식을 활용하여 모두 제거합니다.  \n",
    "문장부호 양옆에 공백을 추가하는 등 이전과 다르게 생략된 기능들은 우리가 사용할 토크나이저가 지원하기 때문에 굳이 구현하지 않아도 괜찮습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adjustable-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(dataset):\n",
    "    dataset = dataset.lower() # 영문자 소문자로 변환\n",
    "    re.sub(r\"[^a-zA-Zㅏ-ㅣㄱ-ㅎ-가-힣0-9,.?!]+\", \" \", dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-pottery",
   "metadata": {},
   "source": [
    "## Step 3. 데이터 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-trinidad",
   "metadata": {},
   "source": [
    "토큰화에는 KoNLPy의 mecab 클래스를 사용합니다.  \n",
    "1. 소스 문장 데이터와 타겟 문장 데이터를 입력으로 받습니다.  \n",
    "2. 데이터를 앞서 정의한 `preprocess_sentence()` 함수로 정제하고, 토큰화합니다.  \n",
    "3. 토큰화는 전달받은 토크나이즈 함수를 사용합니다. 이번엔 `mecab.morphs` 함수를 전달하면 됩니다.  \n",
    "4. 토큰의 개수가 일정 길이 이상인 문장은 데이터에서 제외됩니다.  \n",
    "5. 중복되는 문장은 데이터에서 제외합니다. 소스:타겟 쌍을 비교하지 않고 소스는 소스대로, 타겟은 타겟대로 검사합니다. 중복 쌍이 흐트러지지 않도록 유의하세요!  \n",
    "      \n",
    "구현한 함수를 활용하여 `questions`와 `answers`를 각각 `que_corpus,` `ans_corpus`에 토큰화하여 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "julian-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_corpus(src_sentence, tgt_sentence):\n",
    "    tokenized_src, tokenized_len_src = [], []\n",
    "    tokenized_tgt, tokenized_len_tgt = [], []\n",
    "    for src, tgt in zip(src_sentence, tgt_sentence):\n",
    "        tokenizer = Mecab()\n",
    "        mecab_src = tokenizer.morphs(preprocess_sentence(src))\n",
    "        mecab_tgt = tokenizer.morphs(preprocess_sentence(tgt))\n",
    "        \n",
    "        tokenized_src.append(mecab_src)\n",
    "        tokenized_tgt.append(mecab_tgt)\n",
    "        \n",
    "        tokenized_len_src.append(len(mecab_src))\n",
    "        tokenized_len_tgt.append(len(mecab_tgt))\n",
    "        \n",
    "    total_length = tokenized_len_src + tokenized_len_tgt\n",
    "    \n",
    "    max_len = np.max(total_length)\n",
    "    mean_len = np.mean(total_length)\n",
    "    mid_len = np.median([mean_len, max_len])\n",
    "    print(f'mid_len : {mid_len}')\n",
    "        \n",
    "    src_corpus, tgt_corpus = [], []\n",
    "    for s, t in zip(tokenized_src, tokenized_tgt):\n",
    "        if len(s) < mid_len and s not in tokenized_src:\n",
    "            tokenized_src.append(s)\n",
    "            \n",
    "        if len(t) < mid_len and t not in tokenized_tgt:\n",
    "            tokenized_tgt.append(t)\n",
    "            \n",
    "    return tokenized_src, tokenized_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "handled-rouge",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid_len : 23.852046857819506\n"
     ]
    }
   ],
   "source": [
    "que_corpus, ans_corpus = build_corpus(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "developing-techno",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12', '시', '땡', '!'], ['1', '지망', '학교', '떨어졌', '어'], ['3', '박', '4', '일', '놀', '러', '가', '고', '싶', '다'], ['3', '박', '4', '일', '정도', '놀', '러', '가', '고', '싶', '다'], ['ppl', '심하', '네']] \n",
      " [['하루', '가', '또', '가', '네요', '.'], ['위로', '해', '드립니다', '.'], ['여행', '은', '언제나', '좋', '죠', '.'], ['여행', '은', '언제나', '좋', '죠', '.'], ['눈살', '이', '찌푸려', '지', '죠', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(que_corpus[:5], \"\\n\",ans_corpus[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "chemical-bidder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 11823)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(que_corpus), len(ans_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-morris",
   "metadata": {},
   "source": [
    "## Step 4. Augmentation\n",
    "우리에게 주어진 데이터는 1만 개가량으로 적은 편에 속합니다. 이럴 때에 사용할 수 있는 테크닉을 배웠으니 활용해 봐야겠죠? Lexical Substitution을 실제로 적용해 보도록 하겠습니다.  \n",
    "  \n",
    "링크를 참고하여 한국어로 사전 훈련된 Embedding 모델을 다운로드합니다. `Korean(w)` 가 Word2Vec으로 학습한 모델이며 용량도 적당하므로 사이트에서 `Korean(w)`를 찾아 다운로드하고, `ko.bin` 파일을 얻으세요!  \n",
    "  \n",
    "다운로드한 모델을 활용해 데이터를 Augmentation 하세요! 앞서 정의한 `lexical_sub()` 함수를 참고하면 도움이 많이 될 겁니다.  \n",
    "  \n",
    "Augmentation된 `que_corpus` 와 원본 `ans_corpus` 가 병렬을 이루도록, 이후엔 반대로 원본 `que_corpus` 와 Augmentation된 `ans_corpus` 가 병렬을 이루도록 하여 전체 데이터가 원래의 3배 가량으로 늘어나도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "closing-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.0.X 버전부터는 vocab 코드가 패키지 안에서 사라지기 때문에 ko.bin을 로드하기\n",
    "# 위해서는 다운그레이드를 해줘야 함\n",
    "# pip install --upgrade gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "worse-charger",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ko_bin_path = os.getenv('HOME') + '/aiffel/NLPGD/GD6/ko.bin'\n",
    "word2vec = gensim.models.Word2Vec.load(ko_bin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "handed-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_sub(sentence, word2vec):\n",
    "    try: \n",
    "        _from = random.choice(sentence) # sentence에서 하나의 형태소를 무작위로 고름\n",
    "        _to = word2vec.most_similar(_from)[0][0] # 가장 비슷한 단어를 추출\n",
    "    except: # sentence 문장이 word2vec에 없으면 그냥 sentence를 반환\n",
    "        return sentence\n",
    "    \n",
    "    res = []\n",
    "    for x in sentence:\n",
    "        if x is _from: res.append(_to)\n",
    "        else: res.append(x)\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ecological-advocacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('힘들', 0.6567603349685669),\n",
       " ('귀찮', 0.634676456451416),\n",
       " ('일쑤', 0.6083942651748657),\n",
       " ('편하', 0.6059445738792419),\n",
       " ('꺼리', 0.5969125628471375),\n",
       " ('길들이', 0.5821220874786377),\n",
       " ('어렵', 0.5785283446311951),\n",
       " ('풀어쓰', 0.570091187953949),\n",
       " ('아깝', 0.5619203448295593),\n",
       " ('웃기', 0.5485275983810425)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '싫'\n",
    "b = word2vec.most_similar(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "polished-malaysia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '지망', '학교', '떨어졌', '어']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que_corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "hazardous-neighbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "arg_que_corpus = [lexical_sub(x, word2vec) for x in que_corpus]\n",
    "arg_ans_corpus = [lexical_sub(x, word2vec) for x in ans_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fatty-subcommittee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 12 시 땡 ! / 12 시 땡 !\n",
      "A: 하루 가 또 가 네요 . / 하루 놀드 또 가 네요 .\n",
      "Q: 1 지망 학교 떨어졌 어 / 1 지망 학교의 떨어졌 어\n",
      "A: 위로 해 드립니다 . / 위로 해 드립니다 는데\n",
      "Q: 3 박 4 일 놀 러 가 고 싶 다 / 3 박 4 일 놀 러 가 기에 싶 다\n",
      "A: 여행 은 언제나 좋 죠 . / 여행 은 언제나 좋 죠 는데\n",
      "Q: 3 박 4 일 정도 놀 러 가 고 싶 다 / 3 박 4 일 정도 놀 ㄹ래 가 고 싶 다\n",
      "A: 여행 은 언제나 좋 죠 . / 여행 은데 언제나 좋 죠 .\n",
      "Q: ppl 심하 네 / ppl 강하 네\n",
      "A: 눈살 이 찌푸려 지 죠 . / 눈살 이 찌푸려 지 죠 .\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Q:\", \" \".join(que_corpus[i]), \"/\" , \" \".join(arg_que_corpus[i]))\n",
    "    print(\"A:\", \" \".join(ans_corpus[i]), \"/\" , \" \".join(arg_ans_corpus[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dominant-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_corpus = que_corpus + arg_que_corpus + que_corpus\n",
    "ans_corpus = ans_corpus + ans_corpus + arg_ans_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "educational-wells",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35469, 35469)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(que_corpus), len(ans_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-estonia",
   "metadata": {},
   "source": [
    "### Step 5. 데이터 벡터화\n",
    "타겟 데이터인 `ans_corpus` 에 `<start>` 토큰과 `<end>` 토큰이 추가되지 않은 상태이니 이를 먼저 해결한 후 벡터화를 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "casual-butter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>', 'i', 'love', 'you', '<end>']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['i', 'love', 'you']\n",
    "a = ['<start>'] + a + ['<end>']\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "placed-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tokens(sentence):\n",
    "    added_tokens = []\n",
    "    for list in sentence:\n",
    "        temp_list = ['<start>'] + list + ['end>']\n",
    "\n",
    "        added_tokens.append(temp_list)\n",
    "    \n",
    "    return added_tokens\n",
    "\n",
    "ans_corpus = add_tokens(ans_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "peaceful-roommate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<start>', '하루', '가', '또', '가', '네요', '.', 'end>'],\n",
       " ['<start>', '위로', '해', '드립니다', '.', 'end>'],\n",
       " ['<start>', '여행', '은', '언제나', '좋', '죠', '.', 'end>'],\n",
       " ['<start>', '여행', '은', '언제나', '좋', '죠', '.', 'end>'],\n",
       " ['<start>', '눈살', '이', '찌푸려', '지', '죠', '.', 'end>']]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-mainland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
