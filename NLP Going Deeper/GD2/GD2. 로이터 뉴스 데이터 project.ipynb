{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conditional-continuity",
   "metadata": {},
   "source": [
    "## 1. 모든 단어 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-split",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "informal-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score #정확도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cellular-coast",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "restricted-tenant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 개수: 8982\n",
      "데스트 데이터 개수: 2246\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터 개수:', len(x_train))\n",
    "print('데스트 데이터 개수:', len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "revolutionary-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 27595, 28842, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 18292, 159, 9, 1084, 363, 13, 19231, 71, 9, 16273, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 16273, 7, 748, 48, 9, 19231, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 23406, 28185, 5, 192, 510, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(x_train[0])\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-discrimination",
   "metadata": {},
   "source": [
    "### 데이터 복원하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "accurate-bidding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "word_index['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-ability",
   "metadata": {},
   "source": [
    "reuters.get_word_index에 +3을 해주어야 학습이 올바르게 이루어질 수 있습니다. 또한 필요한 것은 index:word와 같은 형식이므로 변환해 주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "existing-moral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_word = {index+3:word for word, index in word_index.items()}\n",
    "index_to_word[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-cambodia",
   "metadata": {},
   "source": [
    "index_to_word에서 1,2,3 index는 비어 있으므로 적합한 토큰을 추가해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "european-passion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk>\n"
     ]
    }
   ],
   "source": [
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token\n",
    "print(index_to_word[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-timeline",
   "metadata": {},
   "source": [
    "훈련, 테스트 데이터를 텍스트 데이터로 변환하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "attractive-script",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "    \n",
    "x_train = decoded\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "champion-sword",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> mcgrath rentcorp said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "varied-hormone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "        \n",
    "x_test = decoded\n",
    "print(len(x_test))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "broadband-subdivision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to accommodate growth and expansion plans for waldbaum inc and shopwell inc over the next two years a and p said the acquisition of shopwell in august 1986 and waldbaum in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt tengelmann warenhandelsgesellschaft of west germany reuter 3'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-spread",
   "metadata": {},
   "source": [
    "### 복원 데이터를 다시 벡터화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "introductory-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "controlling-johnson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 26506)\n"
     ]
    }
   ],
   "source": [
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "broken-salmon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 26506)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "expressed-divide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 26506)\n"
     ]
    }
   ],
   "source": [
    "x_test_dtm = dtmvector.transform(x_test)\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-expression",
   "metadata": {},
   "source": [
    "### 나이브 베이즈 분류기(Multinomial Naive Bayes Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "tough-century",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "frozen-journalist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.5997328584149599\n"
     ]
    }
   ],
   "source": [
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
    "\n",
    "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-reporter",
   "metadata": {},
   "source": [
    "### Complement Naive Bayes Classifier(CNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "generic-press",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "applied-spank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7649154051647373\n"
     ]
    }
   ],
   "source": [
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-malpractice",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀(Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "studied-hacker",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "instant-avenue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.813446126447017\n"
     ]
    }
   ],
   "source": [
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-humidity",
   "metadata": {},
   "source": [
    "### 선형 서포트 벡터 머신(Linear Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "industrial-crystal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1000, dual=False, max_iter=500, penalty='l1')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "southeast-aquatic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7796081923419412\n"
     ]
    }
   ],
   "source": [
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-bracelet",
   "metadata": {},
   "source": [
    "### 결정 트리(Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "right-citizen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "liable-arrangement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6211041852181657\n"
     ]
    }
   ],
   "source": [
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-child",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dangerous-kruger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "unlikely-grenada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6544968833481746\n"
     ]
    }
   ],
   "source": [
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-category",
   "metadata": {},
   "source": [
    "### 그래디언트 부스팅 트리(GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "industrial-practitioner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "unknown-wrestling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7702582368655387\n"
     ]
    }
   ],
   "source": [
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-feelings",
   "metadata": {},
   "source": [
    "### 보팅(Voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "organizational-gather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=10000)),\n",
       "                             ('cb', ComplementNB()),\n",
       "                             ('grbt',\n",
       "                              GradientBoostingClassifier(random_state=0))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "entitled-disco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8187889581478184\n"
     ]
    }
   ],
   "source": [
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-thesaurus",
   "metadata": {},
   "source": [
    "### RNN(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "collaborative-standing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 import\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "integral-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_rnn, y_train_rnn), (x_test_rnn, y_test_rnn) = reuters.load_data(num_words=None, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "deluxe-cornwall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = max(y_train_rnn)+1\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "wrong-merchant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30982"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "under-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(index_to_word)\n",
    "tag_size = num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "foster-speaker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 사전의 개수: 30982\n",
      "레이블의 개수: 46\n"
     ]
    }
   ],
   "source": [
    "print('단어 사전의 개수:', vocab_size)\n",
    "print('레이블의 개수:', tag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "attractive-hamilton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11228"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = len(x_train_rnn) + len(x_test_rnn)\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "daily-jackson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 문장의 최대 길이: 2376\n",
      "테스트 문장의 최대 길이: 1032\n",
      "문장의 평균 길이: 116\n"
     ]
    }
   ],
   "source": [
    "total_data = len(x_train_rnn) + len(x_test_rnn)\n",
    "print('훈련 문장의 최대 길이:', max(len(i) for i in x_train_rnn))\n",
    "print('테스트 문장의 최대 길이:', max(len(i) for i in x_test_rnn))\n",
    "print('문장의 평균 길이:', sum(len(i) for i in x_train_rnn)//total_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-person",
   "metadata": {},
   "source": [
    "문장의 최대 길이는 200으로 지정하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "laughing-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "x_train_rnn = pad_sequences(x_train_rnn, padding='post', maxlen=max_len)\n",
    "x_test_rnn = pad_sequences(x_test_rnn, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "bright-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 데이터에 대해 원핫인코딩 수행\n",
    "y_train_rnn = to_categorical(y_train_rnn, num_classes=num_classes)\n",
    "y_test_rnn = to_categorical(y_test_rnn, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "central-bride",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n",
      "8982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation 데이터셋을 분리하기 위해서 데이터의 개수를 확인합니다.\n",
    "print(len(x_train_rnn)), print(len(y_train_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "loose-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation 데이터셋 분리\n",
    "x_train_rnn1 = x_train_rnn[:7000]\n",
    "x_valid_rnn1 = x_train_rnn[7000:]\n",
    "\n",
    "y_train_rnn1 = y_train_rnn[:7000]\n",
    "y_valid_rnn1 = y_train_rnn[7000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "therapeutic-wichita",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 200)\n",
      "(1982, 200)\n",
      "(7000, 46)\n",
      "(1982, 46)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_rnn1.shape)\n",
    "print(x_valid_rnn1.shape)\n",
    "\n",
    "print(y_train_rnn1.shape)\n",
    "print(y_valid_rnn1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "honey-beach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30982\n",
      "Epoch 1/50\n",
      "55/55 [==============================] - 6s 77ms/step - loss: 3.0339 - accuracy: 0.3212 - val_loss: 2.3569 - val_accuracy: 0.3456\n",
      "Epoch 2/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.3484 - accuracy: 0.3611 - val_loss: 2.3305 - val_accuracy: 0.3552\n",
      "Epoch 3/50\n",
      "55/55 [==============================] - 4s 65ms/step - loss: 2.3097 - accuracy: 0.3729 - val_loss: 2.3577 - val_accuracy: 0.3552\n",
      "Epoch 4/50\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 2.3361 - accuracy: 0.3697 - val_loss: 2.3878 - val_accuracy: 0.3340\n",
      "Epoch 5/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.3523 - accuracy: 0.3516 - val_loss: 2.2122 - val_accuracy: 0.3739\n",
      "Epoch 6/50\n",
      "55/55 [==============================] - 4s 65ms/step - loss: 2.1616 - accuracy: 0.4202 - val_loss: 2.0011 - val_accuracy: 0.4884\n",
      "Epoch 7/50\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.0223 - accuracy: 0.4828 - val_loss: 2.2928 - val_accuracy: 0.4546\n",
      "Epoch 8/50\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.1885 - accuracy: 0.4627 - val_loss: 2.0003 - val_accuracy: 0.4960\n",
      "Epoch 9/50\n",
      "55/55 [==============================] - 4s 65ms/step - loss: 2.0037 - accuracy: 0.5005 - val_loss: 1.9074 - val_accuracy: 0.5166\n",
      "Epoch 10/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 1.8221 - accuracy: 0.5326 - val_loss: 1.8344 - val_accuracy: 0.5308\n",
      "Epoch 11/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 1.7844 - accuracy: 0.5300 - val_loss: 1.7970 - val_accuracy: 0.5187\n",
      "Epoch 12/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 1.6905 - accuracy: 0.5484 - val_loss: 2.0135 - val_accuracy: 0.5121\n",
      "Epoch 13/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 1.8750 - accuracy: 0.5263 - val_loss: 1.9285 - val_accuracy: 0.4874\n",
      "Epoch 14/50\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 1.8292 - accuracy: 0.5150 - val_loss: 1.8887 - val_accuracy: 0.4803\n",
      "Epoch 15/50\n",
      "55/55 [==============================] - 4s 65ms/step - loss: 1.7234 - accuracy: 0.5240 - val_loss: 1.8482 - val_accuracy: 0.4879\n",
      "Epoch 16/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 1.6739 - accuracy: 0.5387 - val_loss: 1.8672 - val_accuracy: 0.5323\n",
      "Epoch 17/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.2037 - accuracy: 0.4108 - val_loss: 2.0310 - val_accuracy: 0.4556\n",
      "Epoch 18/50\n",
      "55/55 [==============================] - 4s 65ms/step - loss: 1.8917 - accuracy: 0.4821 - val_loss: 2.3478 - val_accuracy: 0.3713\n",
      "Epoch 19/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.1510 - accuracy: 0.4043 - val_loss: 2.0990 - val_accuracy: 0.3971\n",
      "Epoch 20/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.1662 - accuracy: 0.4064 - val_loss: 2.3942 - val_accuracy: 0.3572\n",
      "Epoch 21/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.4060 - accuracy: 0.3662 - val_loss: 2.3550 - val_accuracy: 0.3602\n",
      "Epoch 22/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.2961 - accuracy: 0.3777 - val_loss: 2.3391 - val_accuracy: 0.3592\n",
      "Epoch 23/50\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 2.2805 - accuracy: 0.3905 - val_loss: 2.3269 - val_accuracy: 0.3633\n",
      "Epoch 24/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.2798 - accuracy: 0.3852 - val_loss: 2.3194 - val_accuracy: 0.3658\n",
      "Epoch 25/50\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.2038 - accuracy: 0.3971 - val_loss: 2.3114 - val_accuracy: 0.3673\n",
      "Epoch 26/50\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.2129 - accuracy: 0.3959 - val_loss: 2.3088 - val_accuracy: 0.3668\n",
      "Epoch 27/50\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.2047 - accuracy: 0.3921 - val_loss: 2.3085 - val_accuracy: 0.3683\n",
      "Epoch 28/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.1931 - accuracy: 0.4038 - val_loss: 2.3923 - val_accuracy: 0.3749\n",
      "Epoch 29/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.2159 - accuracy: 0.3876 - val_loss: 2.3164 - val_accuracy: 0.3638\n",
      "Epoch 30/50\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.1759 - accuracy: 0.4061 - val_loss: 2.3168 - val_accuracy: 0.3708\n",
      "Epoch 31/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.1801 - accuracy: 0.4206 - val_loss: 2.3202 - val_accuracy: 0.3693\n",
      "Epoch 32/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.1123 - accuracy: 0.4235 - val_loss: 2.3256 - val_accuracy: 0.3703\n",
      "Epoch 33/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.1287 - accuracy: 0.4195 - val_loss: 2.3367 - val_accuracy: 0.3713\n",
      "Epoch 34/50\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.1256 - accuracy: 0.4344 - val_loss: 2.3328 - val_accuracy: 0.3703\n",
      "Epoch 35/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.1089 - accuracy: 0.4267 - val_loss: 2.3415 - val_accuracy: 0.3708\n",
      "Epoch 36/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.0928 - accuracy: 0.4299 - val_loss: 2.3478 - val_accuracy: 0.3703\n",
      "Epoch 37/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.0958 - accuracy: 0.4293 - val_loss: 2.3780 - val_accuracy: 0.3628\n",
      "Epoch 38/50\n",
      "55/55 [==============================] - 4s 65ms/step - loss: 2.2556 - accuracy: 0.3956 - val_loss: 2.3388 - val_accuracy: 0.3638\n",
      "Epoch 39/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.2038 - accuracy: 0.4181 - val_loss: 2.3177 - val_accuracy: 0.3663\n",
      "Epoch 40/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.1645 - accuracy: 0.4189 - val_loss: 2.3132 - val_accuracy: 0.3693\n",
      "Epoch 41/50\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.1174 - accuracy: 0.4365 - val_loss: 2.2932 - val_accuracy: 0.3729\n",
      "Epoch 42/50\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 2.4464 - accuracy: 0.3443 - val_loss: 2.4236 - val_accuracy: 0.3602\n",
      "Epoch 43/50\n",
      "55/55 [==============================] - 4s 65ms/step - loss: 2.3374 - accuracy: 0.3924 - val_loss: 2.3213 - val_accuracy: 0.3673\n",
      "Epoch 44/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.2383 - accuracy: 0.4043 - val_loss: 2.3233 - val_accuracy: 0.3678\n",
      "Epoch 45/50\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 2.2264 - accuracy: 0.4016 - val_loss: 2.3145 - val_accuracy: 0.3653\n",
      "Epoch 46/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.1917 - accuracy: 0.4131 - val_loss: 2.3197 - val_accuracy: 0.3643\n",
      "Epoch 47/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.1845 - accuracy: 0.4085 - val_loss: 2.3124 - val_accuracy: 0.3718\n",
      "Epoch 48/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.1812 - accuracy: 0.4196 - val_loss: 2.3141 - val_accuracy: 0.3688\n",
      "Epoch 49/50\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 2.1225 - accuracy: 0.4370 - val_loss: 2.3158 - val_accuracy: 0.3688\n",
      "Epoch 50/50\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.0762 - accuracy: 0.4522 - val_loss: 2.3164 - val_accuracy: 0.3678\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(index_to_word)\n",
    "print(vocab_size)\n",
    "word_vector_dim = 126\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim))\n",
    "model.add(keras.layers.LSTM(126))\n",
    "model.add(keras.layers.Dense(46, activation='softmax'))\n",
    "# 모델 훈련\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train_rnn1, y_train_rnn1, epochs=50, batch_size=128, validation_data=(x_valid_rnn1, y_valid_rnn1), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-audit",
   "metadata": {},
   "source": [
    "## 2. 빈도수 상위 5,000개의 단어만 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-romania",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "missing-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "interstate-bleeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 개수: 8982\n",
      "데스트 데이터 개수: 2246\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터 개수:', len(x_train))\n",
    "print('데스트 데이터 개수:', len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "handled-gallery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(x_train[0])\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-cabinet",
   "metadata": {},
   "source": [
    "### 데이터 복원하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "challenging-construction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "word_index['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-saint",
   "metadata": {},
   "source": [
    "reuters.get_word_index에 +3을 해주어야 학습이 올바르게 이루어질 수 있습니다. 또한 필요한 것은 index:word와 같은 형식이므로 변환해 주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "interested-wealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_word = {index+3:word for word, index in word_index.items()}\n",
    "index_to_word[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-landscape",
   "metadata": {},
   "source": [
    "index_to_word에서 1,2,3 index는 비어 있으므로 적합한 토큰을 추가해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "inside-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk>\n"
     ]
    }
   ],
   "source": [
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token\n",
    "print(index_to_word[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-textbook",
   "metadata": {},
   "source": [
    "훈련, 테스트 데이터를 텍스트 데이터로 변환하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "friendly-sandwich",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "    \n",
    "x_train = decoded\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "compatible-content",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "seven-contest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "        \n",
    "x_test = decoded\n",
    "print(len(x_test))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "focal-shade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to <unk> growth and expansion plans for <unk> inc and <unk> inc over the next two years a and p said the acquisition of <unk> in august 1986 and <unk> in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt <unk> <unk> of west germany reuter 3'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-blocking",
   "metadata": {},
   "source": [
    "### 복원 데이터를 다시 벡터화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "similar-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "proper-bonus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 4867)\n"
     ]
    }
   ],
   "source": [
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "twelve-seven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 4867)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "toxic-rubber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 4867)\n"
     ]
    }
   ],
   "source": [
    "x_test_dtm = dtmvector.transform(x_test)\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-leeds",
   "metadata": {},
   "source": [
    "### 나이브 베이즈 분류기(Multinomial Naive Bayes Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "legendary-premium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "southeast-voltage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6731967943009796\n"
     ]
    }
   ],
   "source": [
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
    "\n",
    "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-consultancy",
   "metadata": {},
   "source": [
    "### Complement Naive Bayes Classifier(CNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "cardiac-africa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "freelance-knowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7707034728406055\n"
     ]
    }
   ],
   "source": [
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-heaven",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀(Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "conceptual-hormone",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "sustained-reset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8058771148708815\n"
     ]
    }
   ],
   "source": [
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-ministry",
   "metadata": {},
   "source": [
    "### 선형 서포트 벡터 머신(Linear Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "damaged-smith",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1000, dual=False, max_iter=500, penalty='l1')"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "clear-respect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7595725734639359\n"
     ]
    }
   ],
   "source": [
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-board",
   "metadata": {},
   "source": [
    "### 결정 트리(Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "blond-color",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "threatened-czech",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6179875333926982\n"
     ]
    }
   ],
   "source": [
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-sculpture",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "respiratory-logan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "acknowledged-magic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.701246660730187\n"
     ]
    }
   ],
   "source": [
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-rogers",
   "metadata": {},
   "source": [
    "### 그래디언트 부스팅 트리(GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "federal-tobago",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "present-uncle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.767586821015138\n"
     ]
    }
   ],
   "source": [
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-amateur",
   "metadata": {},
   "source": [
    "### 보팅(Voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "american-martin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=10000)),\n",
       "                             ('cb', ComplementNB()),\n",
       "                             ('grbt',\n",
       "                              GradientBoostingClassifier(random_state=0))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "overhead-assist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8161175422974176\n"
     ]
    }
   ],
   "source": [
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-roommate",
   "metadata": {},
   "source": [
    "### RNN(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "appreciated-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 import\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "universal-steel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train_rnn, y_train_rnn), (x_test_rnn, y_test_rnn) = reuters.load_data(num_words=5000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "geographic-blind",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = max(y_train_rnn)+1\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "dress-marijuana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30982"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "phantom-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(index_to_word)\n",
    "tag_size = num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "hindu-dallas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 사전의 개수: 30982\n",
      "레이블의 개수: 46\n"
     ]
    }
   ],
   "source": [
    "print('단어 사전의 개수:', vocab_size)\n",
    "print('레이블의 개수:', tag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "meaning-honduras",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11228"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = len(x_train_rnn) + len(x_test_rnn)\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "documentary-processing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 문장의 최대 길이: 2376\n",
      "테스트 문장의 최대 길이: 1032\n",
      "문장의 평균 길이: 116\n"
     ]
    }
   ],
   "source": [
    "total_data = len(x_train_rnn) + len(x_test_rnn)\n",
    "print('훈련 문장의 최대 길이:', max(len(i) for i in x_train_rnn))\n",
    "print('테스트 문장의 최대 길이:', max(len(i) for i in x_test_rnn))\n",
    "print('문장의 평균 길이:', sum(len(i) for i in x_train_rnn)//total_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-patent",
   "metadata": {},
   "source": [
    "문장의 최대 길이는 200으로 지정하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "pregnant-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "x_train_rnn = pad_sequences(x_train_rnn, padding='post', maxlen=max_len)\n",
    "x_test_rnn = pad_sequences(x_test_rnn, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "bronze-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 데이터에 대해 원핫인코딩 수행\n",
    "y_train_rnn = to_categorical(y_train_rnn, num_classes=num_classes)\n",
    "y_test_rnn = to_categorical(y_test_rnn, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "sound-insulation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n",
      "8982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation 데이터셋을 분리하기 위해서 데이터의 개수를 확인합니다.\n",
    "print(len(x_train_rnn)), print(len(y_train_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "suited-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation 데이터셋 분리\n",
    "x_train_rnn1 = x_train_rnn[:7000]\n",
    "x_valid_rnn1 = x_train_rnn[7000:]\n",
    "\n",
    "y_train_rnn1 = y_train_rnn[:7000]\n",
    "y_valid_rnn1 = y_train_rnn[7000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "deadly-filling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 200)\n",
      "(1982, 200)\n",
      "(7000, 46)\n",
      "(1982, 46)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_rnn1.shape)\n",
    "print(x_valid_rnn1.shape)\n",
    "\n",
    "print(y_train_rnn1.shape)\n",
    "print(y_valid_rnn1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "handy-february",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30982\n",
      "Epoch 1/30\n",
      "55/55 [==============================] - 6s 75ms/step - loss: 3.0237 - accuracy: 0.3118 - val_loss: 2.3560 - val_accuracy: 0.3552\n",
      "Epoch 2/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.3688 - accuracy: 0.3610 - val_loss: 2.3353 - val_accuracy: 0.3557\n",
      "Epoch 3/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.3665 - accuracy: 0.3529 - val_loss: 2.2910 - val_accuracy: 0.3628\n",
      "Epoch 4/30\n",
      "55/55 [==============================] - 4s 67ms/step - loss: 2.2857 - accuracy: 0.3734 - val_loss: 2.3977 - val_accuracy: 0.3461\n",
      "Epoch 5/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.4241 - accuracy: 0.3566 - val_loss: 2.3449 - val_accuracy: 0.3552\n",
      "Epoch 6/30\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 2.3242 - accuracy: 0.3688 - val_loss: 2.2866 - val_accuracy: 0.3703\n",
      "Epoch 7/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.1994 - accuracy: 0.3883 - val_loss: 2.4041 - val_accuracy: 0.3572\n",
      "Epoch 8/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.3678 - accuracy: 0.3604 - val_loss: 2.3278 - val_accuracy: 0.3663\n",
      "Epoch 9/30\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 2.3258 - accuracy: 0.3727 - val_loss: 2.1405 - val_accuracy: 0.3885\n",
      "Epoch 10/30\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 2.0598 - accuracy: 0.4073 - val_loss: 2.0169 - val_accuracy: 0.3895\n",
      "Epoch 11/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 1.9974 - accuracy: 0.4148 - val_loss: 1.9576 - val_accuracy: 0.3971\n",
      "Epoch 12/30\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 2.1592 - accuracy: 0.3823 - val_loss: 1.9892 - val_accuracy: 0.4041\n",
      "Epoch 13/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.0138 - accuracy: 0.4297 - val_loss: 2.0834 - val_accuracy: 0.3875\n",
      "Epoch 14/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.1715 - accuracy: 0.3870 - val_loss: 2.0405 - val_accuracy: 0.4077\n",
      "Epoch 15/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.0292 - accuracy: 0.4201 - val_loss: 2.0419 - val_accuracy: 0.3935\n",
      "Epoch 16/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.0012 - accuracy: 0.4101 - val_loss: 1.9356 - val_accuracy: 0.4102\n",
      "Epoch 17/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 1.8958 - accuracy: 0.4301 - val_loss: 1.8207 - val_accuracy: 0.5172\n",
      "Epoch 18/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 1.7619 - accuracy: 0.5480 - val_loss: 1.7730 - val_accuracy: 0.5489\n",
      "Epoch 19/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 1.7662 - accuracy: 0.5591 - val_loss: 2.0516 - val_accuracy: 0.4082\n",
      "Epoch 20/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.0175 - accuracy: 0.4158 - val_loss: 1.9969 - val_accuracy: 0.4112\n",
      "Epoch 21/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 1.9914 - accuracy: 0.4293 - val_loss: 1.9915 - val_accuracy: 0.4092\n",
      "Epoch 22/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 1.9787 - accuracy: 0.4510 - val_loss: 1.9146 - val_accuracy: 0.4753\n",
      "Epoch 23/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 1.8412 - accuracy: 0.4992 - val_loss: 1.8881 - val_accuracy: 0.4430\n",
      "Epoch 24/30\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 1.8033 - accuracy: 0.4846 - val_loss: 2.3509 - val_accuracy: 0.3693\n",
      "Epoch 25/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.1508 - accuracy: 0.4403 - val_loss: 1.9867 - val_accuracy: 0.4763\n",
      "Epoch 26/30\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 1.8610 - accuracy: 0.5197 - val_loss: 1.8813 - val_accuracy: 0.4803\n",
      "Epoch 27/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 1.7967 - accuracy: 0.5236 - val_loss: 1.9765 - val_accuracy: 0.4712\n",
      "Epoch 28/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 1.9776 - accuracy: 0.4720 - val_loss: 1.9600 - val_accuracy: 0.4692\n",
      "Epoch 29/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 1.9214 - accuracy: 0.4882 - val_loss: 1.9439 - val_accuracy: 0.4733\n",
      "Epoch 30/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 1.9234 - accuracy: 0.4748 - val_loss: 2.0110 - val_accuracy: 0.4379\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(index_to_word)\n",
    "print(vocab_size)\n",
    "word_vector_dim = 126\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim))\n",
    "model.add(keras.layers.LSTM(126))\n",
    "model.add(keras.layers.Dense(46, activation='softmax'))\n",
    "# 모델 훈련\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train_rnn1, y_train_rnn1, epochs=30, batch_size=128, validation_data=(x_valid_rnn1, y_valid_rnn1), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-continuity",
   "metadata": {},
   "source": [
    "## 3. 직접 단어 개수를 설정해서 사용\n",
    "num_words = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "genuine-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=15000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "advised-level",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 개수: 8982\n",
      "데스트 데이터 개수: 2246\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터 개수:', len(x_train))\n",
    "print('데스트 데이터 개수:', len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "northern-humidity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(x_train[0])\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-identification",
   "metadata": {},
   "source": [
    "### 데이터 복원하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "encouraging-spare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "word_index['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-reynolds",
   "metadata": {},
   "source": [
    "reuters.get_word_index에 +3을 해주어야 학습이 올바르게 이루어질 수 있습니다. 또한 필요한 것은 index:word와 같은 형식이므로 변환해 주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "outside-islam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_word = {index+3:word for word, index in word_index.items()}\n",
    "index_to_word[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-disease",
   "metadata": {},
   "source": [
    "index_to_word에서 1,2,3 index는 비어 있으므로 적합한 토큰을 추가해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "authorized-holly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk>\n"
     ]
    }
   ],
   "source": [
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token\n",
    "print(index_to_word[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-vatican",
   "metadata": {},
   "source": [
    "훈련, 테스트 데이터를 텍스트 데이터로 변환하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "liked-crazy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "    \n",
    "x_train = decoded\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "domestic-decade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "cleared-dress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "        \n",
    "x_test = decoded\n",
    "print(len(x_test))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "advanced-seating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to <unk> growth and expansion plans for <unk> inc and <unk> inc over the next two years a and p said the acquisition of <unk> in august 1986 and <unk> in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt <unk> <unk> of west germany reuter 3'"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-seeker",
   "metadata": {},
   "source": [
    "### 복원 데이터를 다시 벡터화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "boxed-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "meaning-clause",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 14227)\n"
     ]
    }
   ],
   "source": [
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "cooperative-legislature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 14227)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "taken-sculpture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 14227)\n"
     ]
    }
   ],
   "source": [
    "x_test_dtm = dtmvector.transform(x_test)\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-evanescence",
   "metadata": {},
   "source": [
    "### 나이브 베이즈 분류기(Multinomial Naive Bayes Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "corporate-latin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "absolute-recall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6331255565449688\n"
     ]
    }
   ],
   "source": [
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
    "\n",
    "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-stewart",
   "metadata": {},
   "source": [
    "### Complement Naive Bayes Classifier(CNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "closed-ticket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "criminal-dairy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7720391807658059\n"
     ]
    }
   ],
   "source": [
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-wallpaper",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀(Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "raising-parking",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "turkish-airline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8125556544968834\n"
     ]
    }
   ],
   "source": [
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-kansas",
   "metadata": {},
   "source": [
    "### 선형 서포트 벡터 머신(Linear Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "crazy-blair",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1000, dual=False, max_iter=500, penalty='l1')"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "forty-remove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7836153161175423\n"
     ]
    }
   ],
   "source": [
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-excitement",
   "metadata": {},
   "source": [
    "### 결정 트리(Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "central-forge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "announced-category",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6193232413178985\n"
     ]
    }
   ],
   "source": [
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-intro",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "federal-species",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "applicable-wedding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6714158504007124\n"
     ]
    }
   ],
   "source": [
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-comparison",
   "metadata": {},
   "source": [
    "### 그래디언트 부스팅 트리(GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "through-seller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "bottom-charge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7707034728406055\n"
     ]
    }
   ],
   "source": [
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-winter",
   "metadata": {},
   "source": [
    "### 보팅(Voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "capable-blend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=10000)),\n",
       "                             ('cb', ComplementNB()),\n",
       "                             ('grbt',\n",
       "                              GradientBoostingClassifier(random_state=0))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "classified-publication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8165627782724845\n"
     ]
    }
   ],
   "source": [
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-peninsula",
   "metadata": {},
   "source": [
    "### RNN(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "muslim-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 import\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "concrete-reproduction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train_rnn, y_train_rnn), (x_test_rnn, y_test_rnn) = reuters.load_data(num_words=15000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "wound-billion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = max(y_train_rnn)+1\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "eight-channels",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30982"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "complicated-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(index_to_word)\n",
    "tag_size = num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "decreased-indicator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 사전의 개수: 30982\n",
      "레이블의 개수: 46\n"
     ]
    }
   ],
   "source": [
    "print('단어 사전의 개수:', vocab_size)\n",
    "print('레이블의 개수:', tag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "subtle-child",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11228"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = len(x_train_rnn) + len(x_test_rnn)\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "cordless-startup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 문장의 최대 길이: 2376\n",
      "테스트 문장의 최대 길이: 1032\n",
      "문장의 평균 길이: 116\n"
     ]
    }
   ],
   "source": [
    "total_data = len(x_train_rnn) + len(x_test_rnn)\n",
    "print('훈련 문장의 최대 길이:', max(len(i) for i in x_train_rnn))\n",
    "print('테스트 문장의 최대 길이:', max(len(i) for i in x_test_rnn))\n",
    "print('문장의 평균 길이:', sum(len(i) for i in x_train_rnn)//total_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-devon",
   "metadata": {},
   "source": [
    "문장의 최대 길이는 200으로 지정하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "original-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "x_train_rnn = pad_sequences(x_train_rnn, padding='post', maxlen=max_len)\n",
    "x_test_rnn = pad_sequences(x_test_rnn, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "eastern-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 데이터에 대해 원핫인코딩 수행\n",
    "y_train_rnn = to_categorical(y_train_rnn, num_classes=num_classes)\n",
    "y_test_rnn = to_categorical(y_test_rnn, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "solar-institute",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n",
      "8982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation 데이터셋을 분리하기 위해서 데이터의 개수를 확인합니다.\n",
    "print(len(x_train_rnn)), print(len(y_train_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "precise-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation 데이터셋 분리\n",
    "x_train_rnn1 = x_train_rnn[:7000]\n",
    "x_valid_rnn1 = x_train_rnn[7000:]\n",
    "\n",
    "y_train_rnn1 = y_train_rnn[:7000]\n",
    "y_valid_rnn1 = y_train_rnn[7000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "broad-database",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 200)\n",
      "(1982, 200)\n",
      "(7000, 46)\n",
      "(1982, 46)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_rnn1.shape)\n",
    "print(x_valid_rnn1.shape)\n",
    "\n",
    "print(y_train_rnn1.shape)\n",
    "print(y_valid_rnn1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "plastic-bread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30982\n",
      "Epoch 1/30\n",
      "55/55 [==============================] - 6s 75ms/step - loss: 2.9824 - accuracy: 0.3164 - val_loss: 2.3524 - val_accuracy: 0.3552\n",
      "Epoch 2/30\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 2.3570 - accuracy: 0.3667 - val_loss: 2.3462 - val_accuracy: 0.3496\n",
      "Epoch 3/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.3628 - accuracy: 0.3663 - val_loss: 2.3546 - val_accuracy: 0.3466\n",
      "Epoch 4/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.3543 - accuracy: 0.3694 - val_loss: 2.4140 - val_accuracy: 0.3552\n",
      "Epoch 5/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.3729 - accuracy: 0.3598 - val_loss: 2.3362 - val_accuracy: 0.3547\n",
      "Epoch 6/30\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 2.3284 - accuracy: 0.3599 - val_loss: 2.3280 - val_accuracy: 0.3597\n",
      "Epoch 7/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.3306 - accuracy: 0.3719 - val_loss: 2.2695 - val_accuracy: 0.3587\n",
      "Epoch 8/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.3074 - accuracy: 0.3659 - val_loss: 2.3270 - val_accuracy: 0.3628\n",
      "Epoch 9/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.3346 - accuracy: 0.3724 - val_loss: 2.3135 - val_accuracy: 0.3597\n",
      "Epoch 10/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.2088 - accuracy: 0.3829 - val_loss: 2.0631 - val_accuracy: 0.3976\n",
      "Epoch 11/30\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 2.1538 - accuracy: 0.3895 - val_loss: 2.0296 - val_accuracy: 0.3935\n",
      "Epoch 12/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.0052 - accuracy: 0.4114 - val_loss: 1.9817 - val_accuracy: 0.3885\n",
      "Epoch 13/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.0929 - accuracy: 0.3927 - val_loss: 2.0067 - val_accuracy: 0.3718\n",
      "Epoch 14/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.0011 - accuracy: 0.3943 - val_loss: 2.0790 - val_accuracy: 0.3905\n",
      "Epoch 15/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.0003 - accuracy: 0.4090 - val_loss: 1.9559 - val_accuracy: 0.4001\n",
      "Epoch 16/30\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 1.9214 - accuracy: 0.4178 - val_loss: 1.9468 - val_accuracy: 0.3986\n",
      "Epoch 17/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.4752 - accuracy: 0.3058 - val_loss: 2.3734 - val_accuracy: 0.3552\n",
      "Epoch 18/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.4085 - accuracy: 0.3444 - val_loss: 2.2450 - val_accuracy: 0.3461\n",
      "Epoch 19/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.2692 - accuracy: 0.3572 - val_loss: 2.1835 - val_accuracy: 0.3552\n",
      "Epoch 20/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.1975 - accuracy: 0.3585 - val_loss: 2.1264 - val_accuracy: 0.3552\n",
      "Epoch 21/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.1313 - accuracy: 0.3766 - val_loss: 2.1068 - val_accuracy: 0.3628\n",
      "Epoch 22/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.2251 - accuracy: 0.3677 - val_loss: 2.3623 - val_accuracy: 0.3461\n",
      "Epoch 23/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.3993 - accuracy: 0.3509 - val_loss: 2.3512 - val_accuracy: 0.3461\n",
      "Epoch 24/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.4088 - accuracy: 0.3474 - val_loss: 2.3467 - val_accuracy: 0.3461\n",
      "Epoch 25/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.3746 - accuracy: 0.3566 - val_loss: 2.3325 - val_accuracy: 0.3572\n",
      "Epoch 26/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.3676 - accuracy: 0.3578 - val_loss: 2.3290 - val_accuracy: 0.3461\n",
      "Epoch 27/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.3297 - accuracy: 0.3602 - val_loss: 2.3025 - val_accuracy: 0.3552\n",
      "Epoch 28/30\n",
      "55/55 [==============================] - 3s 64ms/step - loss: 2.2922 - accuracy: 0.3668 - val_loss: 2.2123 - val_accuracy: 0.3713\n",
      "Epoch 29/30\n",
      "55/55 [==============================] - 3s 63ms/step - loss: 2.1779 - accuracy: 0.3784 - val_loss: 2.1162 - val_accuracy: 0.3744\n",
      "Epoch 30/30\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 2.0866 - accuracy: 0.3848 - val_loss: 2.0443 - val_accuracy: 0.3673\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(index_to_word)\n",
    "print(vocab_size)\n",
    "word_vector_dim = 126\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim))\n",
    "model.add(keras.layers.LSTM(126))\n",
    "model.add(keras.layers.Dense(46, activation='softmax'))\n",
    "# 모델 훈련\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x_train_rnn1, y_train_rnn1, epochs=30, batch_size=128, validation_data=(x_valid_rnn1, y_valid_rnn1), verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
