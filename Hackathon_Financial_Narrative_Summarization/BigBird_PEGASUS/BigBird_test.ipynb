{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "name": "BigBird.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "900741d70a064519a5fa583c7bde49d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0fc508ab15a14f26a3c078de0b8fd2f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_367040265e5e45649ace96766933e8f7",
              "IPY_MODEL_6b02e5a3f71246abaf006c7a659af99f",
              "IPY_MODEL_e18195e7075e4e12a4ec4ec044d0eba9"
            ]
          }
        },
        "0fc508ab15a14f26a3c078de0b8fd2f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "367040265e5e45649ace96766933e8f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_869029232476464a97be7b1783c022f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validation sanity check:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d199c7371ffd4c5488fd6afe7279d9ea"
          }
        },
        "6b02e5a3f71246abaf006c7a659af99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_04e0aa90c8db41229a7b55915de2f558",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38378ae989484203b1ebce2dc7f22353"
          }
        },
        "e18195e7075e4e12a4ec4ec044d0eba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_696952ce36714c3381abcd157230fdf0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:01&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d05e0eb9e944ce9b1e767d026ff05a2"
          }
        },
        "869029232476464a97be7b1783c022f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d199c7371ffd4c5488fd6afe7279d9ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04e0aa90c8db41229a7b55915de2f558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38378ae989484203b1ebce2dc7f22353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "696952ce36714c3381abcd157230fdf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d05e0eb9e944ce9b1e767d026ff05a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8354c8f4a408403f8d4fef23dd6271b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8303c6fd6ff3496d889983a88acd2e43",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_92d7400aa453479da772b93f876fdf53",
              "IPY_MODEL_e032b02c31ae473dad9e70250744fb22",
              "IPY_MODEL_5f62ec10e00d4bc6b337b4c06dead7f6"
            ]
          }
        },
        "8303c6fd6ff3496d889983a88acd2e43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "92d7400aa453479da772b93f876fdf53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d19121155a2e429095c887cc1a2e72d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epoch 0:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d23dd575dc084601856ec7256617d9c9"
          }
        },
        "e032b02c31ae473dad9e70250744fb22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_afda38ab60cd414ab173fd36e0769102",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 2408,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cc1d2cdb1ee415eab5a0468e045396a"
          }
        },
        "5f62ec10e00d4bc6b337b4c06dead7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e135db516ab447febd2353f5451629bb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2408 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74b31331bf3e4b2480c53fe4f87933e0"
          }
        },
        "d19121155a2e429095c887cc1a2e72d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d23dd575dc084601856ec7256617d9c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afda38ab60cd414ab173fd36e0769102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cc1d2cdb1ee415eab5a0468e045396a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e135db516ab447febd2353f5451629bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74b31331bf3e4b2480c53fe4f87933e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZjAFykkB1f8",
        "outputId": "38d848f4-76e7-4fc2-f9d0-a0cb8494f391"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "fZjAFykkB1f8",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5lsP3uLB7ma",
        "outputId": "890a84b7-de35-4093-cc35-e4219f06b477"
      },
      "source": [
        "# colab pro 더 빠른 GPU 사용\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "id": "Q5lsP3uLB7ma",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 18 07:59:39 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    32W / 250W |  16251MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-qTvBuMB7gZ",
        "outputId": "082fb819-fd9e-4555-9fc1-1cb56d9e2f1f"
      },
      "source": [
        "# colab pro 추가 메모리\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "id": "T-qTvBuMB7gZ",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RpZZZ5afCIPn",
        "outputId": "e7dc13c7-f8a5-4e01-c0dc-c107c21b7b1c"
      },
      "source": [
        "! pip install transformers\n",
        "! pip install pytorch-lightning\n",
        "! pip install torchmetrics\n",
        "! pip install torchtext\n",
        "! pip install lightning-flash\n",
        "! pip install lightning-flash[image]"
      ],
      "id": "RpZZZ5afCIPn",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 87.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.2)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 90.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 59.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.5.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 71.8 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.10.0.2)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 58.7 MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n",
            "\u001b[K     |████████████████████████████████| 329 kB 77.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.2)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.7.0)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.10.0+cu111)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 72.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (2.4.7)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.41.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.4)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.1)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 94.3 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 76.3 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.2.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 81.4 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.6.0)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=9e4c3908641845da9fd7ba3012d931106cb6060e3ea3772ff9974058573fb55d\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built future\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, pyDeprecate, future, pytorch-lightning\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 frozenlist-1.2.0 fsspec-2021.11.0 future-0.18.2 multidict-5.2.0 pyDeprecate-0.3.1 pytorch-lightning-1.5.2 torchmetrics-0.6.0 yarl-1.7.2\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.2)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (2.4.7)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.62.3)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchtext) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Collecting lightning-flash\n",
            "  Downloading lightning_flash-0.5.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from lightning-flash) (21.2)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from lightning-flash) (1.10.0+cu111)\n",
            "Collecting jsonargparse[signatures]>=3.17.0\n",
            "  Downloading jsonargparse-4.0.0-py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 91.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightning-flash) (1.19.5)\n",
            "Requirement already satisfied: pyDeprecate in /usr/local/lib/python3.7/dist-packages (from lightning-flash) (0.3.1)\n",
            "Requirement already satisfied: pytorch-lightning>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from lightning-flash) (1.5.2)\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from lightning-flash) (7.1.2)\n",
            "Requirement already satisfied: pandas<1.3.0 in /usr/local/lib/python3.7/dist-packages (from lightning-flash) (1.1.5)\n",
            "Requirement already satisfied: torchmetrics!=0.5.1,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from lightning-flash) (0.6.0)\n",
            "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.7/dist-packages (from jsonargparse[signatures]>=3.17.0->lightning-flash) (6.0)\n",
            "Collecting docstring-parser>=0.7.3\n",
            "  Downloading docstring_parser-0.13.tar.gz (23 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<1.3.0->lightning-flash) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<1.3.0->lightning-flash) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas<1.3.0->lightning-flash) (1.15.0)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.4.0->lightning-flash) (2021.11.0)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.4.0->lightning-flash) (0.18.2)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.4.0->lightning-flash) (4.62.3)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.4.0->lightning-flash) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.4.0->lightning-flash) (3.10.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash) (3.8.1)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->lightning-flash) (2.4.7)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (0.37.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (1.41.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (4.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (3.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash) (4.0.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash) (1.7.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash) (2.0.7)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash) (21.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash) (5.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash) (3.6.0)\n",
            "Building wheels for collected packages: docstring-parser\n",
            "  Building wheel for docstring-parser (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docstring-parser: filename=docstring_parser-0.13-py3-none-any.whl size=31865 sha256=f7d07ebf0e4cc6242ebb505f763ebbcc6c50a209951698ddb30f3c5d55fa5585\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/88/3c/d1aa049309f7945178cac9fbe6561a86424f432da57c18ca0f\n",
            "Successfully built docstring-parser\n",
            "Installing collected packages: jsonargparse, docstring-parser, lightning-flash\n",
            "Successfully installed docstring-parser-0.13 jsonargparse-4.0.0 lightning-flash-0.5.2\n",
            "Requirement already satisfied: lightning-flash[image] in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: pytorch-lightning>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from lightning-flash[image]) (1.5.2)\n",
            "Requirement already satisfied: torchmetrics!=0.5.1,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from lightning-flash[image]) (0.6.0)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from lightning-flash[image]) (1.10.0+cu111)\n",
            "Requirement already satisfied: pandas<1.3.0 in /usr/local/lib/python3.7/dist-packages (from lightning-flash[image]) (1.1.5)\n",
            "Requirement already satisfied: jsonargparse[signatures]>=3.17.0 in /usr/local/lib/python3.7/dist-packages (from lightning-flash[image]) (4.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from lightning-flash[image]) (21.2)\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from lightning-flash[image]) (7.1.2)\n",
            "Requirement already satisfied: pyDeprecate in /usr/local/lib/python3.7/dist-packages (from lightning-flash[image]) (0.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightning-flash[image]) (1.19.5)\n",
            "Collecting timm>=0.4.5\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[K     |████████████████████████████████| 376 kB 9.8 MB/s \n",
            "\u001b[?25hCollecting lightning-bolts>=0.3.3\n",
            "  Downloading lightning_bolts-0.4.0-py3-none-any.whl (282 kB)\n",
            "\u001b[K     |████████████████████████████████| 282 kB 76.9 MB/s \n",
            "\u001b[?25hCollecting pystiche==1.*\n",
            "  Downloading pystiche-1.0.1-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting Pillow>=7.2\n",
            "  Downloading Pillow-8.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 80.2 MB/s \n",
            "\u001b[?25hCollecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.2.0-py3-none-any.whl (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting kornia<0.5.4,>=0.5.1\n",
            "  Downloading kornia-0.5.3-py2.py3-none-any.whl (281 kB)\n",
            "\u001b[K     |████████████████████████████████| 281 kB 61.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from lightning-flash[image]) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pystiche==1.*->lightning-flash[image]) (4.62.3)\n",
            "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.7/dist-packages (from jsonargparse[signatures]>=3.17.0->lightning-flash[image]) (6.0)\n",
            "Requirement already satisfied: docstring-parser>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from jsonargparse[signatures]>=3.17.0->lightning-flash[image]) (0.13)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<1.3.0->lightning-flash[image]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<1.3.0->lightning-flash[image]) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas<1.3.0->lightning-flash[image]) (1.15.0)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.4.0->lightning-flash[image]) (0.18.2)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.4.0->lightning-flash[image]) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.4.0->lightning-flash[image]) (3.10.0.2)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.4.0->lightning-flash[image]) (2021.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (3.8.1)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->lightning-flash[image]) (2.4.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (0.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (0.37.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (3.3.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (1.41.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (1.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (3.17.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (4.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (3.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (1.7.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (21.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (2.0.7)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (4.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (5.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (1.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.4.0->lightning-flash[image]) (3.6.0)\n",
            "Collecting efficientnet-pytorch==0.6.3\n",
            "  Downloading efficientnet_pytorch-0.6.3.tar.gz (16 kB)\n",
            "Collecting pretrainedmodels==0.7.4\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.8 MB/s \n",
            "\u001b[?25hCollecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-py3-none-any.whl size=12421 sha256=719b5191fdddb6ffcab28f6f73526729bdc3de406dd07036ea5483ddf21e4638\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/6b/0c/f0ad36d00310e65390b0d4c9218ae6250ac579c92540c9097a\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60965 sha256=82f13531329e08ef4f89f30aff0dc022e4f560e1479d9905ef2072a87d364f5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: Pillow, munch, timm, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch, pystiche, lightning-bolts, kornia\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-8.4.0 efficientnet-pytorch-0.6.3 kornia-0.5.3 lightning-bolts-0.4.0 munch-2.5.0 pretrainedmodels-0.7.4 pystiche-1.0.1 segmentation-models-pytorch-0.2.0 timm-0.4.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02bcb86e"
      },
      "source": [
        "from transformers import BigBirdPegasusForConditionalGeneration, AutoTokenizer, AdamW\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl \n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.auto import tqdm\n",
        "import gc"
      ],
      "id": "02bcb86e",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efbd7d9c"
      },
      "source": [
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "rcParams['figure.figsize'] = 16, 10"
      ],
      "id": "efbd7d9c",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e321844",
        "outputId": "bfc31060-da1b-4d52-ee13-22a5c1c7503e"
      },
      "source": [
        "pl.seed_everything(42) # 학습한 모델을 재생산(Reproduction)하기 위해 사용."
      ],
      "id": "9e321844",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0922472"
      },
      "source": [
        "#### 데이터 불러오기"
      ],
      "id": "e0922472"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4852b88"
      },
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Aiffel_Hackathon/Data/Training_Data_Clean.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Aiffel_Hackathon/Data/Test_Data_Clean.csv')"
      ],
      "id": "b4852b88",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "60ad1e19",
        "outputId": "460ec1b2-82b6-47fe-c3fd-52ba4d438bc0"
      },
      "source": [
        "train_df.head()"
      ],
      "id": "60ad1e19",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Original_Filename_x</th>\n",
              "      <th>Gold_Filename</th>\n",
              "      <th>Document</th>\n",
              "      <th>Full_Text</th>\n",
              "      <th>Summary_Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>15786_819157_2</td>\n",
              "      <td>15786_819156_1</td>\n",
              "      <td>15786</td>\n",
              "      <td>6 chief executive officer’s review the berong...</td>\n",
              "      <td>3 chairman’s statement in the 18 months since...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>15783_819108_2</td>\n",
              "      <td>15783_819107_1</td>\n",
              "      <td>15783</td>\n",
              "      <td>chief executive officer’s statement the beron...</td>\n",
              "      <td>chairman s statement it has always been your ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>15782_819091_2</td>\n",
              "      <td>15782_819090_1</td>\n",
              "      <td>15782</td>\n",
              "      <td>chief executive officer’s statement the compa...</td>\n",
              "      <td>chairman’s statement the celestial ipilan ore...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15787_819176_2</td>\n",
              "      <td>15787_819175_1</td>\n",
              "      <td>15787</td>\n",
              "      <td>page 6 toledo mining corporation plc annual r...</td>\n",
              "      <td>page 5 i should like to begin my message with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>15816_820156_2</td>\n",
              "      <td>15816_820155_1</td>\n",
              "      <td>15816</td>\n",
              "      <td>3 chief executive’s statement tomkins plc rep...</td>\n",
              "      <td>2 tomkins plc report accounts 2003 chairman’s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                       Summary_Text\n",
              "0           0  ...   3 chairman’s statement in the 18 months since...\n",
              "1           1  ...   chairman s statement it has always been your ...\n",
              "2           2  ...   chairman’s statement the celestial ipilan ore...\n",
              "3           3  ...   page 5 i should like to begin my message with...\n",
              "4           4  ...   2 tomkins plc report accounts 2003 chairman’s...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "21e76339",
        "outputId": "f78a57f7-0c3c-46a1-8a3f-95bac0b28b1c"
      },
      "source": [
        "train_df = train_df[['Full_Text', \"Summary_Text\"]]\n",
        "train_df.head(2)"
      ],
      "id": "21e76339",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Full_Text</th>\n",
              "      <th>Summary_Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6 chief executive officer’s review the berong...</td>\n",
              "      <td>3 chairman’s statement in the 18 months since...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>chief executive officer’s statement the beron...</td>\n",
              "      <td>chairman s statement it has always been your ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Full_Text                                       Summary_Text\n",
              "0   6 chief executive officer’s review the berong...   3 chairman’s statement in the 18 months since...\n",
              "1   chief executive officer’s statement the beron...   chairman s statement it has always been your ..."
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "2292ce77",
        "outputId": "d3c92069-ffe1-4dc8-e7c6-9658dee814ff"
      },
      "source": [
        "test_df = test_df[['Full_Text', 'Summary_Text']]\n",
        "test_df.head(2)"
      ],
      "id": "2292ce77",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Full_Text</th>\n",
              "      <th>Summary_Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25695 19 march 2018 3 29 pm proof 7 02 s . c ...</td>\n",
              "      <td>25695 19 march 2018 3 29 pm proof 7 a . c . q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10 staffline group plc annual report 2017 chi...</td>\n",
              "      <td>6 staffline group plc annual report 2017 a ye...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Full_Text                                       Summary_Text\n",
              "0   25695 19 march 2018 3 29 pm proof 7 02 s . c ...   25695 19 march 2018 3 29 pm proof 7 a . c . q...\n",
              "1   10 staffline group plc annual report 2017 chi...   6 staffline group plc annual report 2017 a ye..."
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9289b071",
        "outputId": "0a47ce79-d09b-4c19-8f59-4c0d02d15c8e"
      },
      "source": [
        "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
        "train_df.shape, val_df.shape"
      ],
      "id": "9289b071",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1926, 2), (482, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc3b6f3b",
        "outputId": "f7a843af-a412-4f8e-8379-5db262b996ab"
      },
      "source": [
        "test_df.shape"
      ],
      "id": "dc3b6f3b",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(280, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11555940"
      },
      "source": [
        "#### 데이터셋 만들기 "
      ],
      "id": "11555940"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71caf3f3"
      },
      "source": [
        "class FinancialSummaryDataset(Dataset):\n",
        "\n",
        "  def __init__(\n",
        "    self,\n",
        "    data: pd.DataFrame,\n",
        "    tokenizer: AutoTokenizer,\n",
        "    text_max_token_len: int = 2048,\n",
        "    summary_max_token_len: int = 500\n",
        "  ):\n",
        "    \n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = data\n",
        "    self.text_max_token_len = text_max_token_len\n",
        "    self.summary_max_token_len = summary_max_token_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index: int):\n",
        "    data_row = self.data.iloc[index]\n",
        "\n",
        "    text = data_row[\"Full_Text\"] \n",
        "\n",
        "    text_encoding = tokenizer(\n",
        "      text,\n",
        "      max_length=self.text_max_token_len,\n",
        "      padding=\"max_length\",\n",
        "      truncation=True,\n",
        "      return_attention_mask=True,\n",
        "      add_special_tokens=True,\n",
        "      return_tensors=\"pt\"\n",
        "    )\n",
        "  \n",
        "    summary_encoding = tokenizer(\n",
        "      data_row[\"Summary_Text\"], \n",
        "      max_length=self.summary_max_token_len, # summary max token len\n",
        "      padding=\"max_length\",\n",
        "      truncation=True,\n",
        "      return_attention_mask=True,\n",
        "      add_special_tokens=True,\n",
        "      return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    labels = summary_encoding[\"input_ids\"] # 사용할 실제 레이블을 생성. tokenizer의 입력 id를 인코딩 \n",
        "    labels[labels == 0] = -100 # idf가 0인 패딩 토큰을 -100으로 바꿔줍니다. 텍스트 생성에 필요한 올바른 레이블이 있는지 확인합니다.\n",
        "\n",
        "    return dict(\n",
        "      text=text,\n",
        "      summary=data_row[\"Summary_Text\"], \n",
        "      text_input_ids=text_encoding[\"input_ids\"].flatten(), \n",
        "      text_attention_mask=text_encoding[\"attention_mask\"].flatten(),\n",
        "      labels=labels.flatten(),\n",
        "      labels_attention_mask=summary_encoding[\"attention_mask\"].flatten()\n",
        "    )"
      ],
      "id": "71caf3f3",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c7bc56d"
      },
      "source": [
        "class FinancialSummaryDataModule(pl.LightningDataModule):\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      train_df : pd.DataFrame,\n",
        "      val_df : pd.DataFrame,\n",
        "      test_df : pd.DataFrame,\n",
        "      tokenizer: AutoTokenizer,\n",
        "      batch_size : int = 1,\n",
        "      text_max_token_len : int = 2048,\n",
        "      summary_max_token_len : int = 500\n",
        "  ):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    self.batch_size = batch_size\n",
        "    self.tokenizer = tokenizer\n",
        "    self.text_max_token_len = text_max_token_len\n",
        "    self.summary_max_token_len = summary_max_token_len\n",
        "\n",
        "  def setup(self, stage=None):\n",
        "    self.train_dataset = FinancialSummaryDataset(\n",
        "      self.train_df,\n",
        "      self.tokenizer,\n",
        "      self.text_max_token_len,\n",
        "      self.summary_max_token_len\n",
        "    )\n",
        "    \n",
        "    self.val_dataset = FinancialSummaryDataset(\n",
        "        self.val_df,\n",
        "        self.tokenizer,\n",
        "        self.text_max_token_len,\n",
        "        self.summary_max_token_len\n",
        "    )\n",
        "\n",
        "    self.test_dataset = FinancialSummaryDataset(\n",
        "      self.test_df,\n",
        "      self.tokenizer,\n",
        "      self.text_max_token_len,\n",
        "      self.summary_max_token_len\n",
        "    )\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(\n",
        "      self.train_dataset,\n",
        "      batch_size=self.batch_size,\n",
        "      shuffle=True,\n",
        "      # num_workers=4 # 주석처리 풀고 2에서 4로 바꿈\n",
        "      )\n",
        "    \n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(\n",
        "      self.val_dataset,  \n",
        "      batch_size=self.batch_size,\n",
        "      shuffle=False,\n",
        "      # num_workers=4 # 주석처리 풀고 2에서 4로 바꿈\n",
        "    )\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(\n",
        "      self.test_dataset,\n",
        "      batch_size=self.batch_size,\n",
        "      shuffle=False\n",
        "      #num_workers=2 \n",
        "    )"
      ],
      "id": "1c7bc56d",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7ca8973"
      },
      "source": [
        "MODEL_NAME = \"google/bigbird-pegasus-large-bigpatent\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "id": "e7ca8973",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfc20062"
      },
      "source": [
        "#### 토큰 수 확인"
      ],
      "id": "cfc20062"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fde021b",
        "outputId": "1355c73d-170d-420a-bbf7-65ab5662230a"
      },
      "source": [
        "text_token_counts, summary_token_counts = [], []\n",
        "\n",
        "for _, row in train_df.iterrows():\n",
        "  text_token_count = len(tokenizer.encode(row[\"Full_Text\"]))\n",
        "  text_token_counts.append(text_token_count)\n",
        "\n",
        "  summary_token_count = len(tokenizer.encode(row[\"Summary_Text\"]))\n",
        "  summary_token_counts.append(summary_token_count)"
      ],
      "id": "4fde021b",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (4551 > 4096). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "4bedceca",
        "outputId": "d2fd68c0-b7fd-44b3-a0d6-81fa37ecb4d6"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "\n",
        "sns.histplot(text_token_counts, ax=ax1)\n",
        "ax1.set_title(\"text token counts\")\n",
        "\n",
        "sns.histplot(summary_token_counts, ax=ax2)\n",
        "ax2.set_title(\"text token counts\")"
      ],
      "id": "4bedceca",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'text token counts')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAB38AAASrCAYAAACSZnK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdebRXZb0/8DeTzAhHUH8CpqngJU0JrmaQmoAtLdTMtEQrJ8rppmRJdbvdvKXZ7arLAeMiWuCQmQNQ3TKBnDIUFckhxCEFvCog05HpwDm/P1h8L8czcJjOgc3rtRZrfc/ez372833O/rL48N7fZzerqqqqCgAAAAAAAAA7tOZNPQAAAAAAAAAAtpzwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BYAc0bdq09O7dO7179859993X1MMBAACA7Yq6GYCdlfAXAAAAAAAAoACEvwBstvvuu690F+20adOaejgNduaZZ6Z379455phjtkp/7iamKe2on0MAANgZ7Kj/Xlc3UyQ76ucQYHMJfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACaFZVVVXV1IMAYMcybdq0fPnLX95ou8997nP5yU9+UmP76tWr88ADD+Shhx7KSy+9lEWLFqVt27bp0aNHBg4cmDPPPDO77757jeO+8Y1v5A9/+EOS5Morr8znP//5Ws87f/78nHjiiVm4cGE6d+6cCRMmZM8998zIkSNz//33b3Tc48aNy+GHH77RdnPnzs2gQYM22u6www7L+PHja2xfuHBhbr/99jz88MOZO3duli9fns6dO+eggw7KZz/72XzmM59Js2bNau1zw9/BVVddlZNPPrnWdjfffHOuu+66JMk///M/Z9SoUenUqVO1NrNnz87dd9+dadOm5e23386KFStSVlaWQw45JCeeeGIGDRpU5zjOPPPMPPnkk+nevXumTJmS8vLyjBs3Ln/4wx8yZ86cJMm+++6boUOHZtiwYdlll102Ol8N8dZbb+Xuu+/OE088kTfffDPLli1LmzZtsvfee6dv37759Kc/XefvsLKyMr/97W/z+9//Ps8//3wWL16cdu3apWfPnjnqqKNyxhlnpKysrM5z9+7dO0nd1/d6N9xwQ2688cYkyeTJk9OjR49q+ze8HmfNmpWKiorcddddmThxYt54441UVFSkR48eOfbYY3P22WenQ4cO1Y7f3M9hVVVV/ud//ieTJk3KSy+9lIULF6ZZs2bp0qVLunTpko9+9KMZOHBgjjnmmLRs2XKj/QMAADWpm9dRN6ub1c0Ajc/fTAA0qpdeeikXX3xxqcBZr6KiIi+++GJefPHF3H777fnJT36ST3/609Xa/OhHP8rf/va3zJs3Lz/60Y/St2/ffPjDH67WpqqqKt/+9rezcOHCJMmPf/zj7Lnnntv2TW2GyZMn51vf+lbef//9atvnz5+fqVOnZurUqbn99tszatSoeguqulRWVuY//uM/cueddyZJPv3pT+dnP/tZtSJy7dq1+c///M/88pe/TGVlZbXj33nnnTz44IN58MEHM3DgwFx33XXp2LFjvef8xz/+keHDh+eNN96otv2FF17ICy+8kClTpmTs2LFbXMiOHj06N9xwQyoqKqptLy8vL11Dd9xxR5566qkaBfuCBQty/vnnZ+bMmdW2L1myJEuWLMnzzz+fX/7yl7nmmmty1FFHbdE4N8V7772X8847L88//3y17bNnz87s2bPz4IMPZvz48enSpcsWnWfFihW54IIL8pe//KXGvrfffjtvv/12Xnrppdx99915+OGHt8vPDgAAFJ26eR118+ZTN28+dTNQBMJfADbZwQcfnEmTJmXy5Mmlu2OvvPLKHHzwwdXa7brrrtV+njVrVk4//fQsX748bdu2zamnnpqPfexj2WuvvbJ69eo888wzGTduXObPn59LL700Y8eOzRFHHFE6vmPHjrnmmmsybNiwLF++PCNGjMivf/3rakXRmDFjSv9AP+OMMzJ48ODSvksvvTRnn312vvOd7+T555/P7rvvnrFjx9Z4fx+807Que+yxRyZNmpS//e1v+e53v5skueSSS2rc1dy2bdtqPz/55JO5+OKLs3bt2rRo0SKnnnpqjj322HTq1Cmvv/56xo8fn+eeey7PPvtszjrrrNxzzz2bVPitWrUql112WR588MEkyemnn57vf//7ad68+tMevve975XuoD3ooINyyimn5EMf+lB23XXXzJs3LxMmTMhDDz2Uxx57LBdffHHGjh2bFi1a1HrOFStW5Gtf+1rmz5+f4cOHZ8CAAenYsWNeeeWVjBo1Kv/4xz/y5JNPZvTo0bn44osb/F4+6Oqrr86tt96aJGnXrl1OO+20HHHEEenWrVuWL1+e1157LY899limTJlS49iVK1fmrLPOyssvv5wk6du3b4YNG5Z99903S5cuzYMPPphf//rXKS8vzwUXXJBf/vKX6d+//2aPdVNceOGFpc/HoEGDUlZWljlz5uSWW27JzJkzM3v27Fx99dXV7kTenM/hjTfeWPp8HHLIIaXfeadOnVJeXp7XX38906ZNy9SpUxvhXQMAQHGpm9dRN/8fdfOWUTcDbIIqANhM9957b1WvXr2qevXqVfXXv/613rZr1qypOu6446p69epVNXTo0Kp333231nYLFiyoOvbYY6t69epVdeyxx1atXbu2RpvRo0eXznvFFVeUtj/77LNVffr0qerVq1fVCSecULVq1apaz3HGGWdU9erVq+pTn/rUJrzbuv31r38tjefee++tt+2aNWuqPvWpT1X16tWr6sADD6yaOnVqjTZr166t+sY3vlHq8/rrr2/wORcvXlx1+umnl/bddNNNtY5j0qRJpTZ33HFHneP9xS9+UWr3wAMP1Ni/fi579epV9bGPfazqpZdeqtFm4cKFVR//+MerevXqVfXxj3+8as2aNXWerz6PPfZY6VxDhgypmjNnTp1t33nnnarVq1dX23bttdeWjh8xYkSt19ZDDz1UdeCBB1b16tWravDgwbWOdX0fl19+eb3jvf7660ttaxvr5ZdfXtrfp0+fqscff7xGmxUrVlQdf/zxVb169ar6yEc+UrVw4cIabTblc3jUUUdV9erVq+rzn/98jfnZ0LJly+r8/AAAAA2nbl5H3axuro26GWDbaL7xeBgAttwf//jHvPrqq2nWrFl+9rOfpVu3brW222233TJy5MgkKd31+kHnnXdeBg4cmCS5/fbbM3ny5CxbtiwjRozImjVr0rZt21xzzTVb7Tk5W9PkyZMzb968JMmpp56ao48+ukab5s2b5z/+4z9KSxXdcccdNZZqqs3bb7+dYcOGZfr06WnZsmWuvPLKXHDBBbW2HTVqVJJ1y1qdfvrpdfb5la98JQcddFCS5J577qn3/P/yL/+SAw88sMb2srKy0rOV3nvvvbzyyisbfS+1ufnmm5MkzZo1y3XXXVfvnea77757WrVqVfp5/XOBknXX2A9/+MMad3QnyaBBg0rPxHrzzTcb7U7eYcOG5ROf+ESN7W3atMmwYcOSrHsPM2bM2KLzLFiwIEnSr1+/avPzQR06dNguPz8AAFBk6uZ11M3q5tqomwEaTvgLQKP405/+lCTp1atXevXqVW/bww47rPT6mWeeqbG/WbNmufrqq9O1a9ckyXe/+92MGDGiVBz+67/+a/bbb7+tNfSt6rHHHiu9/uIXv1hnu44dO+azn/1skmTRokV56aWX6u139uzZOe200zJ79uy0bds2N910U6kY+6BXX301r776apJk6NChGx3z+t/HjBkzsnbt2jrb1dfXhksqffC5VQ2xZMmSPP3000mSI444In369Nmk41944YUsXrw4SfKZz3wmHTp0qLPtl770pdLrDX9f29IJJ5xQ574tnbsN7bHHHkmSKVOmlJ7vBQAAbB/Uzeuom9XNtVE3AzScZ/4C0ChmzpyZZN3zi3r37t3g4+bPn1/r9q5du+anP/1pzjnnnCxevDiPPPJIknUFyimnnLLlA95G1j83p127dhudh759+2b8+PFJ1s3bRz/60VrbPfPMM/nJT36SJUuWpEuXLhk9enQOOeSQOvv929/+Vnp90UUXNXjsFRUVWbJkScrKymrs69KlS63b19vw+Tnl5eUNPud6L774YiorK5Mkhx9++CYfv37ek3XzWp9/+qd/Sps2bbJy5crMmjVrk8+1OT784Q/Xua9z586l15szdxv6whe+kGuvvTZvvvlmBg8enCFDhuQTn/hEDjnkkOyzzz5p1qzZFvUPAABsPnXzOupmdXNt1M0ADSf8BaBRvPfee5t13MqVK+vcN2DAgJxwwgmZMGFCkqRbt2654oorNus8jWX9XbRdunSpdfmkDa2/QztZdxdzXTZcVupHP/pRvQVski26c3XFihW1bm/Xrl29x234XtcXo5tiw/e/++67b/Lx6+c9qT6vtWnevHl22223zJs3r9px21J987dhYbk5c7eh4cOHZ/HixRk/fnyWL1+eCRMmlD4/ZWVlGThwYL7whS9U+xYBAADQONTN66ib1c21UTcDNJzwF4BGsWbNmiTrluK58sorG3zchne+ftCcOXMyefLk0s8LFy7MCy+8sFl3uO7IBg8enIcffjgVFRX5wQ9+kA996EM54IAD6my/4RJUV111VenZRA2xOQUk24/mzZtn5MiROfPMM/O73/0u06ZNy4wZM1JeXp733nsvEydOzMSJE3P88cfnpz/9ab3PNwIAALYudfO2o26modTNQBEIfwFoFGVlZXn77bezYsWKjT67qCEqKioyYsSIlJeXp3nz5mnTpk2WL1+eb33rW5kwYUK6dOmyFUa99a1fimjRokWprKys9y7mBQsWlF7X934GDRqUz33uc7nkkkuyYMGCfPnLX85tt92WAw88sNb2G/bVtm3brfL72NY2HPO77767ycdvuATUhvNam8rKytId9xset17z5s1TWVm50buJly9fvsnjbCzdu3fP8OHDM3z48FRWVubvf/97pkyZkrvuuisLFizI73//+3zoQx/KJZdc0tRDBQCAnYa6eR118+ZRN29d6mZgR1b/uhkAUI9Nec7JRz7ykSTJa6+9ttlLWW3ouuuuKz0P6fzzzy8tW/XOO+/ku9/97hb3vyk2ZR7WP69o+fLl1Z6nU5tnn322xnF1GTx4cG688cbssssuee+99/KVr3wlL774Yq1tN7xjefr06Q0depPq06dPqeCfNm3aJh+/4fzNmDGj3rYvvfRSaZmu2v4joH379kmSpUuX1tvPa6+9tqnD3Cxb+ryh5s2bp0+fPrnoooty9913p23btkmS3//+91tjeAAAsFNTN6+jbt721M11UzcDOxvhLwCbrXXr1qXXq1evrrftsccem2Td3aG33nrrFp338ccfz9ixY5Mk/fr1y4UXXpihQ4fmc5/7XJJkypQpuf322+s8vk2bNg0ac0Ot768hfQ4cOLD0+u67766zXXl5eX77298mWXf3d58+fTY6jqOPPjqjRo1KmzZtsnjx4nz1q18tFfobOvDAA9OzZ88kyQMPPLBFzzJqLLvuumv69++fJHniiSfqLNDr0qdPn9Jd0L/73e/y/vvv19l2w9/LgAEDauxfP3fPP/98qqqqau1j/vz5+ctf/rJJY9xcm/I53JgePXpk3333TbL5zxsDAAD+j7q5en8N6VPdvHnUzXVTNwM7G+EvAJttw+fY/OMf/6i37Wc/+9nSP47Hjh2b+++/v97277//fm677bYaSwQtXLgw3/72t1NVVZVdd901P/vZz9KiRYskyfe///3ss88+SZKrr746f//73+sd98KFC7Ns2bJ6x9EQmzIPxxxzTHr06JFkXbH0yCOP1GhTWVmZH/zgB1m0aFGSZNiwYWnZsmFPavjkJz+Zn//852nbtm2WLFmSs88+u8Ydu82aNctFF12UZF2xfMEFF2y0YJk5c2YefvjhBo1hW7nggguSJFVVVbnkkksyd+7cOtvOnz8/FRUVpZ9btWqVL33pS0nWLV/1wx/+sNYC9M9//nPuueeeJMnee++dT33qUzXaHHbYYaVzTJgwocb+1atXZ+TIkVvtP0k2pqHX3+LFi/PQQw/Vu+zWvHnz8uqrryb5v2IdAADYfOrm6v0l6uZtSd1cO3UzsLPxzF8ANlufPn3Srl27LF++PLfcckt222237LfffqWCq2PHjqV/YLds2TI33HBDvvSlL2XZsmUZOXJkHnjggXz2s5/N/vvvnzZt2mTp0qV59dVXM3369EydOjXLly/PmWeeWVq2qKqqKpdffnnp2TM/+tGPstdee5XG0759+1x77bU59dRTs3r16owYMSL33ntvaTme9fr375/f/OY3qayszHe/+92ceeaZ2W233Ur799prrxrH1GfPPfdM9+7dM2/evPzmN7/J/vvvn4MOOiitWrVKsu75QOvH2aJFi1x11VX56le/mrVr1+b888/PaaedlsGDB6dTp0554403Mn78+NLSVQceeGCGDx++Sb+XI444ImPGjMnw4cOzbNmynH322RkzZkz69etXanPSSSdl+vTpueeeezJjxowcd9xxOeWUU3LYYYelW7duqaioyLvvvpvnn38+U6ZMycsvv5yvf/3rOeqoozZpLFvTEUcckbPPPju33npr3njjjZxwwgk57bTT8olPfCJdu3bNihUr8tprr+XRRx/NlClT8vjjj5d+B0ny9a9/PQ899FBefvnlTJgwIW+++WbOOOOM7LPPPlm2bFn+9Kc/5Ve/+lUqKyvTsmXLXHXVVaX/INnQaaedljvuuCMVFRX5/ve/nzfffDNHHnlkmjdvnlmzZmXcuHF55ZVX0rdv32pLkG0rDf0clpeX58ILL8zuu++ewYMH55BDDknPnj3Trl27LFq0KDNnzswdd9yRVatWJUnOOOOMbT52AAAoOnXzOurmxqFurp26GdjZNKuqa90FAGiAG2+8MTfccEOt+z73uc/lJz/5SbVtr776ai699NLMmjVro323b98+Tz31VKmQGDt2bH76058mSb74xS/mhz/8Ya3H/eIXv8hVV12VJDnllFPy4x//uNr+lStX5uSTTy7dqflB48aNy+GHH77R8W3ovvvuy3e+851a9x122GEZP358tW0PPfRQvv3tb9e7jFLfvn0zatSolJWV1dg3bdq0fPnLX06SXHXVVTn55JNrtHn66aczfPjwlJeXp127dhk9enTp7ttk3X8K3HTTTfn5z39e7W7funzrW9/KueeeW23bmWeemSeffDLdu3fPlClT6jy2IeNtqJtuuimjRo3KmjVr6m331FNPpVOnTtW2LViwIOeff36ty3qt16FDh1xzzTX1Fux33nlnrrjiilrvgm7VqlX+9V//NfPnz8+NN96YJJk8eXLpzvX1Ro4cWbqTv77Pw9y5czNo0KAkyUUXXZSLL764RpuGfA437Kc+zZs3z9e//vV84xvf2GhbAABg49TN66ib1c3rqZsBti3f/AVgi1x00UXZZ599cv/99+fvf/97lixZUm9BtN9+++WBBx7IQw89lD/+8Y+ZOXNmFixYkNWrV6d9+/bp3r17+vTpkwEDBuRTn/pUqYD929/+lmuvvTZJcsABB9RZMCbJV77ylTzxxBP585//nN/85jcZMGBAjj/++NL+Nm3a5K677srYsWPz6KOP5s0338zy5cvrXdZnY04++eR069Ytd911V55//vm899579c7D4MGD86c//Snjx4/PI488kjlz5mTFihXp3LlzDjrooHzmM5/JZz7zmdLd25ujX79+ufXWW3POOedk2bJlGT58eG6++eYcccQRSf5vGatTTjkld999d/7617/mjTfeyJIlS9KyZcvstttu2XfffdO/f/8MGjQovXr12uyxbE3rn1V111135Yknnsi8efPy/vvvp3379unZs2f69euX4447rkYBmyRdu3bN3XffnUmTJuX3v/99XnjhhSxevDht27bN3nvvnSOPPDJnnnlmrf9xsKHTTz89+++/f2699dbMmDEj5eXlKSsry2GHHZavfvWrOeigg+osKreFhnwOu3fvnnvvvTePPfZYZsyYkblz52bBggVZunRp2rZtmx49euSf//mf84UvfCG9e/dutLEDAEDRqZvXUTc3HnVzTepmYGfim78AAAAAAAAABbD5t0UBAAAAAAAAsN0Q/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABRAy6YeANvOiy++mFWrVqVFixZp3bp1Uw8HAAAgSbJq1aqsXbs2rVu3Tp8+fZp6OOzE1M0AAMD2aEvqZuFvga1atSqVlZWprKxMRUVFUw8HAACgmlWrVjX1ENjJqZsBAIDt2ebUzcLfAmvRokUqKyvTvHnztGvXrqmHk/Ly8iRJhw4dmngkbI9cH9TFtUFdXBvUx/VBXVwb24fly5ensrIyLVq0aOqhsJNTN+/czHfjMt+Nx1w3LvPduMx34zLfjcdcN64dYb63pG4W/hZY69atU1FRkXbt2qV3795NPZw8/fTTSbJdjIXtj+uDurg2qItrg/q4PqiLa2P7MGvWrJSXl1tmlyanbt65me/GZb4bj7luXOa7cZnvxmW+G4+5blw7wnxvSd3cfBuMBwAAAAAAAIBGJvwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKICWTT0AgJ3N5WNeaZLzXn3e/k1yXgAAAGDn1BT/B+L/PwDY2fnmLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAWjb1AAAAAAAAoAguH/NKo5/z6vP2b/RzArD98s1fAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoAAK+czfVatW5dFHH81jjz2WmTNnZs6cOVm+fHk6dOiQAw44IMccc0xOPfXUdOjQod5+1qxZk1/96leZNGlSXn/99axevTp77bVXBg8enK9+9aspKyvb6Fjee++9/OIXv8hDDz2Ut956K7vsskv23XffDB06NF/84hfTsmUhfwUAAAAAAABAIytk8njEEUfk/fffr7F98eLFeeqpp/LUU0/ll7/8ZW644YZ89KMfrbWPZcuW5Zxzzslzzz1Xbfurr76aV199Nffdd1/GjBmTf/qnf6pzHC+++GKGDx+e+fPnl7atWLEiM2bMyIwZMzJp0qTccsst6dix42a+UwAAAAAAAIB1Chn+vv/++2nVqlUGDx6cwYMH5+CDD07nzp3z7rvvZuLEibn11lvz9ttv59xzz82kSZOyxx571OhjxIgRee6559KsWbN87Wtfy+c///m0adMmjz32WK688srMnz8/X/va1zJx4sR07ty5xvGLFy/O17/+9cyfPz+dOnXKd77znQwcODArV67Mvffem9GjR2fGjBkZMWJExowZ0xjTAgAAAEmSqqqqvPbaa5k5c2bpz6xZs1JRUZEkmTx5cnr06FHrsXPnzs2gQYM26Xzjxo3L4YcfXm3byJEjc//992/02GHDhuXf/u3fNul8AAAAO6tChr+nn356LrjggnTr1q3a9l133TXf/OY306tXr1x22WVZsmRJbr755vz7v/97tXYPP/xwHnnkkSTJN77xjZx//vmlfSeffHL23nvvnHHGGXnnnXdyyy235LLLLqsxhjFjxuSdd95Js2bNcvPNN6d///6lfZdeemnatGmT6667Lo888kgeeeSRHHnkkVtxBgAAAKBu8+bNy/HHH98o52rZsmX222+/RjkXAADAzvCWIfQAACAASURBVK6Q4e8PfvCDevcPHTo0//3f/52XX365FPJu6M4770ySdOnSJeecc06N/f3798/RRx+dqVOn5p577skll1xS7dm9a9asya9//eskydFHH10t+F3vnHPOyS9+8YssXrw4d955p/AXAACAJrHnnnvm4IMPzqJFizJ9+vSNtu/evXueeeaZetssXbo0Q4YMSUVFRQYMGJCuXbvW2bZfv371rojVqlWrjY4JAACAdZo39QCaygEHHJAkeffdd6ttX7lyZZ544okkyaBBg7LLLrvUevxxxx2XZN3yzk8//XS1fdOnT8/SpUurtfugXXbZJYMHD06S/OUvf8nKlSs3850AAADApuncuXNuuummPPbYY3n44Ydz44035uMf/3iDjm3WrFnat29f75+pU6eWlpA+6aST6u2vRYsW9fZVV10OAABATTtt+LtgwYIkSceOHattnz17dlatWpUkOfTQQ+s8fsN9L7zwQrV9G/7ckD5WrVqVV155pYEjBwAAgC3ToUOHDB48uMbjkraWCRMmJFlXc2/q84EBAADYfDtl+LtgwYLSElV9+/attu/1118vve7Ro0edfey1115p3rx5jWM2/Ll58+bZa6+96uxjw/4/2AcAAADsiN54443MmDEjybrVsFq3bt3EIwIAANh57JTh73/913+Vlp/60pe+VG3fokWLSq932223Ovto1apVOnXqlGTd0s+19dGpU6d6n01UVlZWev3BPgAAAGBH9MADD5Ren3jiiQ0+bu3atVm7du22GBIAAMBOo2VTD6CxTZw4Mffdd1+S5JhjjsknP/nJavtXrFhRer2xu5PX71++fHmtfWzs+DZt2pRef7CPram8vLzGc4mb0vY0FrY/Rb4++vXrlyRZtmxZk45jR53jHXXcbHuuDerj+qAurg3YNqqqqjJx4sQkSc+ePdO/f/+NHvPyyy9nyJAhmTt3bqqqqtK5c+cceuihOfnkkzNkyJA0a9ZsWw8bAACgMHaqb/7OnDkz3//+95Mk/+///b/8+Mc/buIRAQAAQHFMnz49c+fOTZKcdNJJDTpm8eLFefPNN1NZWZmqqqosWrQoU6dOzcUXX5xzzjknS5Ys2ZZDBgAAKJSd5pu/r732WoYPH56VK1emc+fOueWWW6otu7xe27ZtS69XrVpVb5/r97dr167WPjZ2/MqVK0uvP9jH1tShQ4f07t17m/XfUOu/XbH+24+woZ3p+ujYsWOTnn9Hm+Od6dpg07g2qI/rg7q4NrYPs2bNSnl5eVMPg21g/ZLPzZo12+iSz127ds25556bT37yk+nZs2e6deuW8vLyPPPMMxk9enRmzpyZxx9/PBdeeGHGjRuX5s233f3rVszauZnvxmW+G09TzvX2sPpZU73/nfE9N4Wd6b1uD8x34zHXjauo871ThL9vvfVWzj777CxatCjt27fPmDFjsv/++9fatkuXLqXXCxcurLPPioqKLF26NEnSuXPnWvtYunRp1qxZk5Yta5/m9957r/T6g30AAADAjmTVqlX54x//mCT52Mc+lp49e9bb/rLLLquxraysLIMHD87RRx+dSy+9NA8++GCeeuqpTJw4scHfJAYAANiZFT78XbBgQc4666z87//+b9q0aZOf//zn+ehHP1pn+3333bf0ev1SVbV56623UllZWeOYDX+urKzMvHnz8qEPfajWPjbs/4N9AAAAwI5k8uTJpW87bWlQ27Jly1xxxRV59NFHs2LFikyaNGmbhr9WzNo5me/GZb4bz/Y01025+lljvf8PfmtsZ3jPTWl7ur53Bua78ZjrxrUjzPeWrJhV6Gf+LlmyJGeddVb+8Y9/pFWrVrn++utz2GGH1XvMAQcckNatWydJnnvuuTrbzZgxo/T6Ix/5SLV9G/7ckD5at25d5zeRAQAAYEewfsnn1q1b57jjjtvi/rp06ZK+ffsmSV588cUt7g8AAGBnUNjw9/3338+5556bl19+Oc2bN89Pf/rTHHXUURs9rk2bNjniiCOSrLtrefXq1bW2+8Mf/pBk3XLNH7wzoH///unUqVO1dh+0evXqTJkyJUnyiU98Im3atGnYGwMAAIDtzIIFC/L4448nSQYNGrTVvvVUVlaWpGmfnwgAALAjKWT4u3r16px//vmZOXNmkuSKK67I8ccf3+DjTz/99CTrnsl722231dj/9NNP589//nOS5Atf+EKNZ/q2bNkyp556apJk6tSptT4w+rbbbis983f9+QAAAGBH9Nvf/jZr1qxJsuVLPm9owYIFSZp2CU0AAIAdSeHC37Vr1+aSSy7JtGnTkiT/8i//kuOPPz7vv/9+nX+qqqqq9XHUUUflyCOPTJJcd911ue666zJnzpzMnz8/999/f84///xUVlZmjz32yLnnnlvrOM4777zsscceqayszPnnn5/7778/8+fPz5w5c3LttdfmuuuuS5IceeSRpXMBAADAjmjChAlJkq5du2bgwIFbpc+FCxfm2WefTZL06dNnq/QJAABQdC033mTH8r//+7+ZPHly6efrr78+119/fb3HTJ48OT169Ki27b/+679y7rnn5rnnnsvNN9+cm2++udr+bt26ZfTo0encuXOtfXbu3Dk///nPM3z48MyfPz8jR46s0ebQQw/NNddc09C3BgAAANud2bNnl57JO3To0LRo0WKjx8yfPz9lZWV1tl29enW+973vZdWqVUmSE044YesNGAAAoMAKF/5uLZ06dcqdd96ZX/3qV5k4cWJef/31VFRUZK+99sqgQYNy1llnlZ49VJc+ffpk4sSJue222zJ58uS89dZbadWqVT784Q9n6NCh+eIXv1hjyWgAAABoDK+88krKy8tLP7/99tul1y+99FJpyeUk2Xvvveusge+///7S64Yu+fy73/0ut99+e4YOHZrDDz88++yzT9q3b5+lS5fm6aefztixY/P3v/89SXL44Ydn6NChm/TeAAAAdlaFSx579OiRWbNmbZW+WrZsmTPOOCNnnHHGZvdRVlaWb37zm/nmN7+5VcYEAAAAW8MPf/jDPPnkk7Xuu+iii6r9fNVVV+Xkk0+u0a6ysjKTJk1KkvTu3TsHHnhgg88/Z86cjBo1KqNGjaqzzaBBg3L11VenefPCPbUKAABgmyhc+AsAAAA0jieeeCLvvvtukoZ/6zdJhgwZkqqqqjz77LN55ZVXsmjRoixdujStW7fOHnvskUMPPTQnnnhiPv7xj2+roQMAABSS8BcAAAB2QuPHj9/iPgYMGLBZq2917949Z511Vs4666wtHgMAAAD/x7pJAAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABRAy6YeAACN6/IxrzTJea8+b/8mOS8AAAAAAOwsfPMXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAJo2dQDAGhsl495pUnOe/V5+zfJeQEAAAAAgJ2Db/4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKoGVTDwAAAAAAgK2jX79+TT2EnYr5BmB745u/AAAAAAAAAAXgm78AAAAAANvQ5WNeabRzLVu2LEkyakTfRjvn9qix5tx8A7C98c1fAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoAAK+czfqqqqvPbaa5k5c2bpz6xZs1JRUZEkmTx5cnr06FHrsXPnzs2gQYM26Xzjxo3L4YcfXm3byJEjc//992/02GHDhuXf/u3fNul8AAAAAAAAAB9UyPB33rx5Of744xvlXC1btsx+++3XKOcCAAAAAAAAqEshw98N7bnnnjn44IOzaNGiTJ8+faPtu3fvnmeeeabeNkuXLs2QIUNSUVGRAQMGpGvXrnW27devX8aMGVPn/latWm10TAAAAAAAAAAbU8jwt3PnzrnppptyyCGHpFu3bkmSG264oUHhb7NmzdK+fft620yYMKG0hPRJJ51Ub9sWLVpstD8AAAAAAACALVXI8LdDhw4ZPHjwNut/woQJSZKOHTtu8vOBAQAAAAAAALaF5k09gB3NG2+8kRkzZiRJjjvuuLRu3bqJRwQAAAAAAAAg/N1kDzzwQOn1iSee2ODj1q5dm7Vr126LIQEAAAAAAAAUc9nnbaWqqioTJ05MkvTs2TP9+/ff6DEvv/xyhgwZkrlz56aqqiqdO3fOoYcempNPPjlDhgxJs2bNtvWwAQAAAAAAgJ2A8HcTTJ8+PXPnzk2SnHTSSQ06ZvHixVm8eHHp50WLFmXq1KmZOnVqBgwYkGuvvTa77rrrNhkvAAAAALBzu3zMK41+zqvP27/RzwkArCP83QTrl3xu1qzZRpd87tq1a84999x88pOfTM+ePdOtW7eUl5fnmWeeyejRozNz5sw8/vjjufDCCzNu3Lg0b77tVuAuLy/P008/vc3631Tb01jY/mzL66Nfv35JkmXLlm2zczTEzn7+zf0d+7uDurg2qI/rg7q4NgAAAIAiEv420KpVq/LHP/4xSfKxj30sPXv2rLf9ZZddVmNbWVlZBg8enKOPPjqXXnppHnzwwTz11FOZOHFig79JDAAAAAAAAFAb4W8DTZ48ufRtuS0Nalu2bJkrrrgijz76aFasWJFJkyZt0/C3Q4cO6d279zbrv6HWf7ti/bcvYUONeX107Nhxm5/D+eu2qb9jf3dQF9cG9XF9UBfXxvZh1qxZKS8vb+phAAAAQOFsu7WGC2b9ks+tW7fOcccdt8X9denSJX379k2SvPjii1vcHwAAAAAAALBzE/42wIIFC/L4448nSQYNGrTVvjVXVlaWpOmfvwkAAAAAAADs+IS/DfDb3/42a9asSbLlSz5vaMGCBUmafglWAAAAAAAAYMcn/G2ACRMmJEm6du2agQMHbpU+Fy5cmGeffTZJ0qdPn63SJwAAAAAAALDzEv5uxOzZs0vP5B06dGhatGix0WPmz5+ftWvX1rl/9erV+d73vpdVq1Yl/5+9+4/tsrz3x/9s5ZeWslLHMMpwKsRzUCcKm25zPWaWZJLUTXY0Tj06RJxm6om6Rcmyneh2bPzjGBaDTnGyM4waz+YWGZnToR44+xEEreTwa+vwTARFGLDSWWiBfv/wQ79WWn723cLdxyNpcr/f131d1+t905ZcPLnuO8kll1zSM8UCAAAAAAAA/daAvi6gVBobG9Pc3Nzx+p133uk4XrlyZcctl5Nk9OjRHc/f/bCf//znHccHesvn+fPn5/HHH09dXV3OO++8fOITn0hFRUWampqydOnS/OhHP8qqVauSJOedd17q6uoO6rMBAAAAAAAAfFhhw9+77747ixcv7rLt5ptv7vS6vr4+U6ZM2eu83bt3Z968eUmS008/Pf/wD/9wwPOvXbs2Dz74YB588MFuz7noooty3333pbzcBmwAAAAAAADg8BQ2/O0Jv//97/Puu+8mOfBdv0kyadKktLe357XXXktjY2O2bNmSpqamDB48OCNHjsz48ePzpS99Keeff36pSgcAAIButbe3Z82aNVm2bFnH1+rVq9PW1pYkWbBgQUaNGtVt/2eeeSYzZszY7zxjx47NL3/5y32es3nz5vz4xz/Ob37zm6xfvz6DBg3KKaeckrq6ulxxxRUZMMA/XQAAAByowq6g5s6de9hjfO5zn8vq1asPut9JJ52UqVOnZurUqYddAwAAAPS0devWZfLkyX1dRlasWJEbbrghGzdu7HivpaUlDQ0NaWhoyLx58/Loo4+msrKyD6sEAAA4ehQ2/AUAAAD274QTTshZZ52VLVu2ZMmSJQfd/9VXX+227Zhjjum2bevWrbnxxhuzcePGDBs2LDNmzMgFF1yQ7du352c/+1kefvjhNDQ05Pbbb8/s2bMPui4AAID+SPgLAAAA/UxVVVVmzZqVs88+OyNGjEiSPPDAA4cU/lZUVBxSDbNnz86GDRtSVlaWhx56KBMnTuxou+222zJkyJDMnDkzCxcuzMKFC1NTU3NI8wAAAPQn5X1dAAAAANC7hg4dmtra2o7gt7ft3LkzTz/9dJLkwgsv7BT87jFt2rRUVVUlSZ544olerQ8AAOBoJfwFAAAAetWSJUvS1NSUJLn44ou7PGfQoEGpra1Nkvzud7/L9u3be60+AACAo5XwFwAAADhsra2tB3zu8uXLO47Hjx/f7Xl72nbs2JHGxsZDLw4AAKCf8MxfAAAA4JBdeuml+dOf/pS2trYcd9xxGTduXCZNmpTLL788xx13XJd93njjjSRJeXl5TjzxxG7HHjVqVKc+Z555Zs8WDwAAUDB2/gIAAACHbMWKFWlra0uSvPfee1myZEnq6+tzySWXZNWqVV322bJlS5Jk2LBhGThwYLdjV1dXdxxv3bq1B6sGAAAoJjt/AQAAgIMyZMiQXHrppamtrc1pp52WE044Ibt27cqqVavyxBNPZP78+Vm7dm2mTZuWZ555JiNHjuzUv6WlJUkyePDg/c6zx3vvvdfzH+T/aW5uztKlS0s2/sE6kmrpD1zv3tXfrveECROSJNu2beuzGszdP+ZN+tfPV3/6rEcC17v3uNa9q6jXW/gLAAAAHJTJkydn8uTJe70/ceLETJw4MZ/85CdTX1+fTZs2ZebMmamvr++DKgEAAPof4S8AAADQo772ta9l/vz5WbZsWZ577rncc889nW7vfOyxxyZJduzYsc9xtm/f3nHc3fODe8LQoUNz+umnl2z8A7Vn58GenYKUluvdu/r79a6srOy1uT6887Q35/6w/jD3kXS9+8PPV3//XdLbXO/e41r3rqPheq9evTrNzc2H1NczfwEAAIAe94UvfCHJ+7dr/stf/tKpbfjw4UmSpqam7Ny5s9sxNm/e3HFcVVVVgioBAACKRfgLAAAA9Ljjjz++47ipqalT2ymnnJIk2b17d9atW9ftGG+99dZefQAAAOie8BcAAADocRs3buw4HjZsWKe2M844o+P49ddf73aMhoaGJMngwYMzZsyYHq4QAACgeIS/AAAAQI9bsGBBkqSioiInn3xyp7aJEyd2BMLPPfdcl/1bW1vz4osvJkk++9nPZsiQISWsFgAAoBiEvwAAAMABa25uTnNz8z7PeeSRR7J8+fIkycUXX5yBAwd2ah8wYEAuv/zyJMlLL72UpUuX7jXGnDlzOp75e+WVV/ZE6QAAAIU3oK8LAAAAAHpfY2NjpxD3nXfe6TheuXJlNm3a1PF69OjRqa6uTpKsXbs211xzTSZPnpyampqMHTs2H/nIR9La2ppVq1blySef7Nj1O2LEiNx6661dzj99+vTMmzcvGzZsyE033ZQZM2bkggsuyPbt2/PTn/40jzzySJKkpqYmNTU1Pf75AQAAikj4CwAAAP3Q3XffncWLF3fZdvPNN3d6XV9fnylTpnS8bmpqylNPPZWnnnqq2/HHjBmTH/zgBxk5cmSX7VVVVfnhD3+YG264IRs3bsxdd9211znjx4/P/ffffyAfBwAAgAh/AQAAgIMwevTofP/7309DQ0NWrFiRTZs2ZevWrSkvL091dXXOOOOM1NbWZvLkyRk0aNA+xxo3blyeffbZzJkzJwsWLMj69eszcODAnHrqqamrq8sVV1yRAQP80wUAAMCBsoICAACAfmju3LmH1K+ioiKXXXZZLrvssh6po7q6OnfccUfuuOOOHhkPAACgPyvv6wIAAAAAAAAAOHzCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAAP6ugCAJJkwYUJflwAAAAAAAHBUs/MXAAAAAAAAoADs/AV63Z2zG/d6b9u2bUmSysrKks173/QxJRsbAAAAAACgr9n5CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABDOjrAkqhvb09a9asybJlyzq+Vq9enba2tiTJggULMmrUqG77P/PMM5kxY8Z+5xk7dmx++ctf7vOczZs358c//nF+85vfZP369Rk0aFBOOeWU1NXV5YorrsiAAYX8IwAAAAAAAAB6WSGTx3Xr1mXy5Ml9XUZWrFiRG264IRs3bux4r6WlJQ0NDWloaMi8efPy6KOPprKysg+rBAAAAAAAAIqgkOHvB51wwgk566yzsmXLlixZsuSg+7/66qvdth1zzDHdtm3dujU33nhjNm7cmGHDhmXGjBm54IILsn379vzsZz/Lww8/nIaGhtx+++2ZPXv2QdcFAAAAAAAA8EGFDH+rqqoya9asnH322RkxYkSS5IEHHjik8LeiouKQapg9e3Y2bNiQsrKyPPTQQ5k4cWJH22233ZYhQ4Zk5syZWbhwYRYuXJiamppDmgcAAAAAAAAgScr7uoBSGDp0aGprazuC3962c+fOPP3000mSCy+8sFPwu8e0adNSVVWVJHniiSd6tT4AAAAAAACgeAoZ/va1JUuWpKmpKUly8cUXd3nOoEGDUltbmyT53e9+l+3bt/dafQAAAAAAAEDxCH8PUGtr6wGfu3z58o7j8ePHd3venrYdO3aksbHx0IsDAAAAAAAA+r1CPvO3J1166aX505/+lLa2thx33HEZN25cJk2alMsvvzzHHXdcl33eeOONJEl5eXlOPPHEbsceNWpUpz5nnnlmzxYPAAAAAAAA9Bt2/u7HihUr0tbWliR57733smTJktTX1+eSSy7JqlWruuyzZcuWJMmwYcMycODAbseurq7uON66dWsPVg0AAAAAAAD0N3b+dmHIkCG59NJLU1tbm9NOOy0nnHBCdu3alVWrVuWJJ57I/Pnzs3bt2kybNi3PPPNMRo4c2al/S0tLkmTw4MH7nWeP9957r+c/yP/TR+dCVAAAIABJREFU3NycpUuXlmz8g3Uk1ULvmjBhQpJk27Zt3Z6zr7ae0htzmL97h/o7wO8OuuN7g33x/UF3fG8AAAAARST87cLkyZMzefLkvd6fOHFiJk6cmE9+8pOpr6/Ppk2bMnPmzNTX1/dBlQAAAAAAAAD/P+HvIfja176W+fPnZ9myZXnuuedyzz33dLq987HHHpsk2bFjxz7H2b59e8dxd88P7glDhw7N6aefXrLxD9Se3RV7dn/Sf1VWVu713p7dqF219cb8vam/z3+wvwP87qA7vjfYF98fdMf3xpFh9erVaW5u7usyAAAAoHA88/cQfeELX0jy/u2a//KXv3RqGz58eJKkqakpO3fu7HaMzZs3dxxXVVWVoEoAAAAAAACgvxD+HqLjjz++47ipqalT2ymnnJIk2b17d9atW9ftGG+99dZefQAAAAAAAAAOhfD3EG3cuLHjeNiwYZ3azjjjjI7j119/vdsxGhoakiSDBw/OmDFjerhCAAAAAAAAoD8R/h6iBQsWJEkqKipy8sknd2qbOHFiRyD83HPPddm/tbU1L774YpLks5/9bIYMGVLCagEAAAAAAICiE/5+SHNzc5qbm/d5ziOPPJLly5cnSS6++OIMHDiwU/uAAQNy+eWXJ0leeumlLF26dK8x5syZ0/HM3yuvvLInSgcAAAAAAAD6sQF9XUCpNDY2dgpx33nnnY7jlStXZtOmTR2vR48enerq6iTJ2rVrc80112Ty5MmpqanJ2LFj85GPfCStra1ZtWpVnnzyyY5dvyNGjMitt97a5fzTp0/PvHnzsmHDhtx0002ZMWNGLrjggmzfvj0//elP88gjjyRJampqUlNT0+OfHwAAAAAAAOhfChv+3n333Vm8eHGXbTfffHOn1/X19ZkyZUrH66ampjz11FN56qmnuh1/zJgx+cEPfpCRI0d22V5VVZUf/vCHueGGG7Jx48bcdddde50zfvz43H///QfycQAAAAAAAAD2qbDh76EaPXp0vv/976ehoSErVqzIpk2bsnXr1pSXl6e6ujpnnHFGamtrM3ny5AwaNGifY40bNy7PPvts5syZkwULFmT9+vUZOHBgTj311NTV1eWKK67IgAH+CAAAAAAAAIDDV9jkce7cuYfUr6KiIpdddlkuu+yyHqmjuro6d9xxR+64444eGQ8AAAAAAACgK+V9XQAAAAAAAAAAh0/4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACiAAX1dAAAAANC72tvbs2bNmixbtqzja/Xq1Wlra0uSLFiwIKNGjeq2/+bNm7NgwYL84Q9/yMqVK/P222+nra0tw4cPzxlnnJG6urp88YtfzDHHHNPtGHfddVd+/vOf77fWq666Kt/97ncP/kMCAAD0Q8JfAAAA6GfWrVuXyZMnH1LfZcuW5atf/Wp27ty5V9u7776bd999Ny+99FIef/zxzJo1K9XV1YdbLgAAAAdI+AsAAAD92AknnJCzzjorW7ZsyZIlS/Z7fktLS3bu3JmqqqrU1dWlpqYmY8eOzbHHHps1a9Zkzpw5ef755/Pqq6/mpptuypNPPpny8u6fOjVhwoTMnj272/aBAwce0ucCAADoj4S/AAAA0M9UVVVl1qxZOfvsszNixIgkyQMPPHBA4W9lZWXuvPPOXHXVVRk8eHCntnPPPTfnnntuvvOd7+Tpp59OQ0NDnnvuuX3uMj7mmGNSUVFxeB8IAACAJEn3//UWAAAAKKShQ4emtra2I/g9GOPGjct11123V/D7QbfddlvHbt9FixYdcp0AAAAcHOEvAAAA0KOqq6tz/PHHJ3n/OcAAAAD0DuEvAAAA0KPa2tryt7/9Lcn7u4wPxK5du7Jr165SlgUAAFB4nvkLAAAA9KiXX345ra2tSZJzzjlnn+f+8Y9/zKRJk/LWW2+lvb09VVVVGT9+fKZMmZJJkyalrKysN0oGAAAoBDt/AQAAgB7T2tqa+++/P0lSUVGRSy65ZJ/nb926NW+++WZ2796d9vb2bNmyJS+99FJuueWWTJs2rWMHMQAAAPtn5y8AAADQY773ve9lzZo1SZJbb7011dXVXZ730Y9+NNdff30+//nP5+Mf/3hGjBiR5ubmvPrqq3n44YezbNmy/Pa3v803vvGN/OQnP0l5een+/3pzc3OWLl1asvEP1pFUS3/geveu/na9J0yYkCTZtm1bn9Vg7v4xb1/r7Z/t/va7pK+53r3Hte5dRb3ewl8AAACgR8ydOzdPP/10kqSmpibXXnttt+d+85vf3Ou96urq1NbW5sILL8xtt92W559/Pq+88kqeffbZfPnLXy5Z3QAAAEUh/AUAAAAO269+9avce++9SZIzzzwzM2fOPOTn9Q4YMCD33HNPFi1alJaWlsybN6+k4e/QoUNz+umnl2z8A7Vn58GenYKUluvdu/r79a6srOy1uT6887Q35/6w/jD3kXS975zd2Otz3jd9TJLe+9nu779Lepvr3Xtc6951NFzv1atXp7m5+ZD6euYvAAAAcFgWLVqUb33rW9m9e3fGjh2bRx99NBUVFYc15vDhw3POOeckSVasWNETZQIAABSe8BcAAAA4ZEuWLMktt9yStra2jB49Oo899liGDx/eI2PveV5wf31+IgAAwMES/gIAAACHZPny5fn617+elpaWjBw5MnPmzMnHPvaxHht/06ZNSfr2FpoAAABHE+EvAAAAcNAaGxszbdq0NDc3Z/jw4ZkzZ05GjRrVY+P/9a9/zWuvvZYkGTduXI+NCwAAUGTCXwAAAOCgvPXWW7nuuuuyZcuWVFZW5rHHHstpp512wP03btyYXbt2ddve2tqab3/729mxY0eS5JJLLjnsmgEAAPqDAX1dAAAAAND7Ghsb09zc3PH6nXfe6TheuXJlxy2Xk2T06NEdz9/dtGlTpk6dmg0bNmTQoEG5//77c/LJJ+fvf/97l/OUl5fn2GOP7fTe/Pnz8/jjj6euri7nnXdePvGJT6SioiJNTU1ZunRpfvSjH2XVqlVJkvPOOy91dXU99rkBAACKTPgLAAAA/dDdd9+dxYsXd9l28803d3pdX1+fKVOmJEkWLlyYN998M8n7O3SnT5++z3lOOumkvPjii3u9v3bt2jz44IN58MEHu+170UUX5b777kt5uRuXAQAAHAjhLwAAANCrJk2alPb29rz22mtpbGzMli1b0tTUlMGDB2fkyJEZP358vvSlL+X888/v61IBAACOKsJfAAAA6Ifmzp17SP2mTJnSsQv4UJ100kmZOnVqpk6deljjAAAA0Jn7JgEAAAAAAAAUgJ2/AAAAAEC/cOfsxl6d777pY3p1PuiP/FwDdGbnLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIY0NcFAEB/cufsxj6Z977pY/pkXgAAAAAAeo+dvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKYEBfFwAA+zJhwoS+LgEAAAAAAI4Kdv4CAAAAAAAAFICdvwD0qjtnNx7U+du2bUuSVFZWHta8900fc0jz95Q98wMAAAAAQKnY+QsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUQCGf+dve3p41a9Zk2bJlHV+rV69OW1tbkmTBggUZNWpUt/03b96cBQsW5A9/+ENWrlyZt99+O21tbRk+fHjOOOOM1NXV5Ytf/GKOOeaYbse466678vOf/3y/tV511VX57ne/e/AfEgAAAAAAAOADChn+rlu3LpMnTz6kvsuWLctXv/rV7Ny5c6+2d999N++++25eeumlPP7445k1a1aqq6sPt1wA6DV3zm7ss7nvmz6mz+YGAAAAAOgPChn+ftAJJ5yQs846K1u2bMmSJUv2e35LS0t27tyZqqqq1NXVpaamJmPHjs2xxx6bNWvWZM6cOXn++efz6quv5qabbsqTTz6Z8vLu7549YcKEzJ49u9v2gQMHHtLnAgAAAAAAAPigQoa/VVVVmTVrVs4+++yMGDEiSfLAAw8cUPhbWVmZO++8M1dddVUGDx7cqe3cc8/Nueeem+985zt5+umn09DQkOeee26fu4yPOeaYVFRUHN4HAgAAAAAAANiP7resHsWGDh2a2trajuD3YIwbNy7XXXfdXsHvB912220du30XLVp0yHUCAAAAAAAA9JRChr+lVl1dneOPPz7J+88BBgAAAAAAAOhrwt9D0NbWlr/97W9J3t9lfCB27dqVXbt2lbIsAAAAAAAAoB8r5DN/S+3ll19Oa2trkuScc87Z57l//OMfM2nSpLz11ltpb29PVVVVxo8fnylTpmTSpEkpKyvrjZIBAAAAAOCoNmHChL4uAeCIZ+fvQWptbc3999+fJKmoqMgll1yyz/O3bt2aN998M7t37057e3u2bNmSl156KbfcckumTZvWsYMYAAAAAAAA4HDY+XuQvve972XNmjVJkltvvTXV1dVdnvfRj340119/fT7/+c/n4x//eEaMGJHm5ua8+uqrefjhh7Ns2bL89re/zTe+8Y385Cc/SXl56XL45ubmLF26tGTjH6wjqRZ6157/mbdt27Zuz9lXW0/pjTnM3/Pz91TdR+vnL8r8Sc//PeDvFfbF9wfd8b0BAAA9587Zjb0yz55/16isrMx908f0ypwARxvh70GYO3dunn766SRJTU1Nrr322m7P/eY3v7nXe9XV1amtrc2FF16Y2267Lc8//3xeeeWVPPvss/nyl79csroBAAAAAACA4hP+HqBf/epXuffee5MkZ555ZmbOnHnIz+sdMGBA7rnnnixatCgtLS2ZN29eScPfoUOH5vTTTy/Z+Adqz+4Kz2WgsrJyr/c++L/2+mL+3mT+g5u/p783jrbPX7T5k577e8DfK+yL7w+643vjyLB69eo0Nzf3dRkAAABQOJ75ewAWLVqUb33rW9m9e3fGjh2bRx99NBUVFYc15vDhw3POOeckSVasWNETZQIAAAAAAAD9mPB3P5YsWZJbbrklbW1tGT16dB577LEMHz68R8be87zgI+H5iwAAAAAAAMDRTfi7D8uXL8/Xv/71tLS0ZOTIkZkzZ04+9rGP9dj4mzZtSnJk3IITAAAAAAAAOLoJf7vR2NiYadOmpbm5OcOHD8+cOXMyatSoHhv/r3/9a1577bUkybhx43psXAAAAAAAAKB/Ev524a233sp1112XLVu2pLKyMo899lhOO+20A+6/cePG7Nq1q9v21tbWfPvb386OHTuSJJdccslh1wwAAAAAAAD0bwP6uoBSaWxsTHNzc8frd955p+N45cqVHbdcTpLRo0d3PH9306ZNmTp1ajZs2JBBgwbl/vvvz8knn5y///3vXc5TXl6eY489ttN78+fPz+OPP566urqcd955+cQnPpGKioo0NTVl6dKl+dGPfpRVq1YlSc4777zU1dX12OcGAAAAAAAA+qfChr933313Fi9e3GXbzTff3Ol1fX19pkyZkiRZuHBh3nzzzSTv79CdPn36Puc56aST8uKLL+71/tq1a/Pggw/mwQcf7LbvRRddlPvuuy/l5TZgAwAAAAAAAIensOFvX5o0aVLa29vz2muvpbGxMVu2bElTU1MGDx6ckSNHZvz48fnSl76U888/v69LBQAAAAAAAAqisOHv3LlzD6nflClTOnYBH6qTTjopU6dOzdSpUw9rHAAAAAAAAIAD5X7DAAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoAAG9HUBAAAAAAAAR5M7Zzf2+pz3TR/T63MCRx87fwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACKEn4e8011+Taa6/NunXrDrjP22+/3dEPAAAAisy6GQAAgFIYUIpBFy9enLKysrS0tBxwn5aWlo5+AAAAUGTWzQAAAJSC2z4DAAAAAAAAFMARE/62trYmSQYOHNjHlQAAAMCRx7oZAACA/Tliwt/ly5cnSaqrq/u4EgAAADjyWDcDAACwPz3yzN9f/OIXXb6/YMGC/O///u8++7a2tuaNN97Iz372s5SVleXMM8/siZIAAADgiGHdDAAAQG/okfD3rrvuSllZWaf32tvbM3PmzAMeo729PWVlZfnqV7/aEyUBAADAEcO6GQAAgN7QI+Fv8v4i9EDe685JJ52Um2++OZ/73Od6qiQAAAA4Ylg3AwAAUGo9Ev7+5Cc/6Thub2/Ptddem7Kysvz7v/97Ro0a1W2/srKyDB48OCNHjszIkSN7ohQAAAA44lg3AwAA0Bt6JPz99Kc/3eX7n/zkJzNmzJiemAIAAACOWtbNAAAA9IYeu+3zBy1YsCBJ/K9kAAAA6IJ1MwAAAKVQkvD3pJNOKsWwAAAAUAjWzQAAAJRCeV8XAAAAAAAAAMDhK8nO3w/64x//mFdeeSVr165Nc3Nzdu3atc/zy8rKcu+995a6LAAAADgi9MW6ub29PWvWrMmyZcs6vlavXp22trYk79+WetSoUfsdZ+fOnXnqqacyb968vPHGG2ltbc2JJ56Y2trafO1rX0t1dfV+x9i8eXN+/OMf5ze/+U3Wr1+fQYMG5ZRTTkldXV2uuOKKDBhQ8n+6AAAAKIySraDWrl2bb3/723nllVcOuq/wF0rrztmNfTLvfdPH9Mm8AABwJOrLdfO6desyefLkwxpj27ZtmTZtWl5//fVO7//5z3/On//85zzzzDOZPXt2/vEf/7HbMVasWJEbbrghGzdu7HivpaUlDQ0NaWhoyLx58/Loo4+msrLysGoFAADoL0py2+fNmzfn6quvziuvvJL29vaD/gIAAIAiO5LWzSeccEImTZqUiRMnHlS/22+/Pa+//nrKyspy44035oUXXsiiRYtSX1+fysrKbNy4MV//+tezdevWLvtv3bo1N954YzZu3Jhhw4alvr4+ixYtygsvvJAbb7wxZWVlaWhoyO23394THxMAAKBfKMnO34cffjgbNmxIWVlZPvOZz2Tq1Kk566yzUlVVlbKyslJMCQAAAEeNvl43V1VVZdasWTn77LMzYsSIJMkDDzyQJUuWHFD///7v/87ChQuTJP/6r/+am266qaNtypQpGT16dK6++ups2LAhjz76aL75zW/uNcbs2bM7rsFDDz3UKXy+7bbbMmTIkMycOTMLFy7MwoULU1NTczgfGQAAoF8oyc7fl19+OWVlZbngggvy2GOPpaamJsOHDxf8AgAAQPp+3Tx06NDU1tZ2BL8H64knnkiSDB8+PNOmTdurfeLEibnwwguTJP/1X/+VnTt3dmrfuXNnnn766STJhRde2OWu42nTpqWqqqrTfAAAAOxbScLft99+O0ly9dVXC3wBAADgQ47mdfP27dvz+9//Pkly0UUXZdCgQV2ed/HFFyd5//bOS5cu7dS2ZMmSNDU1dTrvwwYNGpTa2tokye9+97ts3769R+oHAAAospKEv8cdd1ySZOTIkaUYHgAAAI5qR/O6+U9/+lN27NiRJBk/fny3532wbfny5Z3aPvj6QMbYsWNHGhsbD6leAACA/qQk4e+YMWOSJO+8804phgcAAICj2tG8bn7jjTc6jkeNGtXteSeeeGLKy8v36vPB1+Xl5TnxxBO7HeOD4394DAAAAPZWkvD3K1/5Strb2/OrX/2qFMMDAADAUe1oXjdv2bKl4/j444/v9ryBAwdm2LBhSd6/9XNXYwwbNiwDBw7sdozq6uqO4w+PAQAAwN4GlGLQSy+9NPPnz8+8efPymc98Jl/+8pdLMQ0AAAAclY7mdXNLS0vH8eDBg/d57p729957r8sx9td/yJAhHccfHqMnNTc37/Vc4r50JNXSH7jevauvrveECROSJNu2beuT+ftqXnP3n3n729wfnK8//ln39u9Sf1f2Hte6dxX1epck/F2/fn1mzJiR73znO5kxY0ZefPHF1NXV5dRTT82xxx673/77uuUTAAAAHO2smwEAACiFkoS/X/jCF1JWVpYkaW9vzwsvvJAXXnjhgPqWlZVlxYoVpSgLAAAAjghH87r5g+H0jh079nnunvbjjjuuyzH213/79u0dxx8eoycNHTo0p59+esnGP1B7dh7s2aFIabnevetIud6VlZWFn/fDuxH76jP3l7ld796de8/1/uB8/eHn+sN663fpkfK7uz9wrXvX0XC9V69enebm5kPqW5LwN3l/8drVMQAAAHD0rpuHDx/ecfzXv/612/Pa2trS1NSUJKmqqupyjKampuzcuTMDBnT9zxObN2/uOP7wGAAAAOytJOHvzTffXIphAQAAoBCO5nXzKaec0nH81ltvdXve+vXrs3v37r36fPD17t27s27dupx88sldjvHB8T88BgAAAHsT/gIAAEAvO5rXzWPHjs3gwYOzY8eOvP7667nsssu6PK+hoaHj+IwzzujU9sHXr7/+erfh754xBg8enDFjxhxu6QAAAIVX3tcFAAAAAEePIUOG5DOf+UySZMGCBWltbe3yvOeeey7J+7dr/vCztCZOnJhhw4Z1Ou/DWltb8+KLLyZJPvvZz2bIkCE9Uj8AAECRCX8BAACAg3LllVcmef+ZvHPmzNmrfenSpXn55ZeTJJdddtlez/QdMGBALr/88iTJSy+9lKVLl+41xpw5czqe+btnPgAAAPatJLd9BgAAAI5sjY2NaW5u7nj9zjvvdByvXLkymzZt6ng9evToVFdXd7z+p3/6p9TU1GThwoWZOXNmWlpa8pWvfCVDhgzJ//zP/6S+vj67d+/OyJEjc/3113c5//Tp0zNv3rxs2LAhN910U2bMmJELLrgg27dvz09/+tM88sgjSZKamprU1NT09McHAAAopJKEv6+88sph9f/Upz7VQ5UAAADAkedIWDfffffdWbx4cZdtH34mcX19faZMmdLpvf/4j//I9ddfn9dffz0PPfRQHnrooU7tI0aMyMMPP5yqqqou56iqqsoPf/jD3HDDDdm4cWPuuuuuvc4ZP3587r///oP5WAAAAP1aScLff/mXf0lZWdkh9S0rK8uKFSt6uCIAAAA4chRh3Txs2LA88cQTeeqpp/Lss8/mjTfeSFtbW0488cRcdNFFmTp1aqfdwl0ZN25cnn322cyZMycLFizI+vXrM3DgwJx66qmpq6vLFVdcsdctowEAAOheyVZQ7e3tpRoaAAAAjnp9vW6eO3fuYY8xYMCAXH311bn66qsPeYzq6urccccdueOOOw67HgAAgP6uJOFvfX39fs957733smbNmvz617/Opk2bMmHChPzzP/9zKcoBAACAI4p1MwAAAKVQkvD30ksvPeBz77zzzvzbv/1bfvGLX+T888/PLbfcUoqSAAAA4Ihh3QwAAEAplPd1AYMGDcq9996b8ePH56GHHsrixYv7uiQAAAA4Ylg3AwAAcKD6PPxNkrKyslx55ZXZvXt3jzxzCAAAAIrEuhkAAIADcUSEv0ly6qmnJkkaGhr6uBIAAAA48lg3AwAAsD9HTPjb0tKSJNm6dWsfVwIAAABHHutmAAAA9ueICX9//etfJ0mGDx/ex5UAAADAkce6GQAAgP0Z0NcF/P3vf89//ud/5vHHH09ZWVk+9alP9XVJAAAAcMSwbgYAAOBAlST8veaaa/Z7Tnt7e/72t7/l//7v/9LW1pb29vYMGjQoN9xwQylKAgAAgCOGdTMAAAClUJLwd/HixSkrK9vvee3t7R3HH/nIR1JfX5/TTz+9FCUBAADAEcO6GQAAgFIoSfh74okn7vecY445JhUVFfn4xz+eT3/606mrq0tVVVUpygEAAIAjinUzAAAApVCS8PfFF18sxbAA/x97dx/kZV3vj/+56wLL/QIiSA7hiZuKyTCwOSaCsTANdEyQ6HTKjAYNz4xl2ul4mvOtKa12mpMnmun8MNHsHCdissNREMf00FEiqUY6rHNEbuSQg5jEqhxAheHZAAAgAElEQVTY4WYXdn9/OOyAsNztfnaXax+PGWbeu9f75nVdfJjPXvvk/bkAAKAQ3DcDAABQCuWdXQAAAAAAAAAAbSf8BQAAAAAAACgA4S8AAAAAAABAAZTkmb/Hqq+vz/Lly/Ob3/wmmzdvzp49e5IkVVVVefe7352rrroqc+bMSb9+/UpdCgAAAHQ57psBAABoLyUNfx9//PF84xvfyL59+5Ikzc3NLcdee+217Nq1K88880x++MMf5hvf+EZmzpxZynIAAACgS3HfDHQnEydO7OwSAAAKr2Th7y9+8Yt87WtfS/LWzWt5eXlGjRqVCy+8MElSV1eXl19+OU1NTfm///u/3HHHHTlw4ECuv/76UpUEAAAAXYb7ZgAAANpbScLfV199NXfddVeam5vTu3fvLFy4MH/913+dQYMGHdfvzTffzM9//vPce++9OXDgQL75zW/myiuvzMUXX1yKsgAAAKBLcN8MdGd3Lnmpw9f87s2jO3xNAIDOUF6KSR966KE0NDSksrIy//qv/5pbbrnlhBvYJBk0aFAWLlyYf/u3f0tlZWUaGhry0EMPlaIkAAAA6DLcNwMAAFAKJQl/f/Ob36SsrCyf/exnc9lll522//ve97589rOfTXNzc37zm9+UoiQAAADoMtw3AwAAUAolCX//9Kc/JUmuvvrqMx5ztO+rr75aipIAAACgy3DfDAAAQCmUJPw9dOhQkqSysvKMxxzt29DQUIqSAAAAoMtw3wwAAEAplCT8HTJkSJJk8+bNZzzmaN/BgweXoiQAAADoMtw3AwAAUAolCX/f//73p7m5OT/5yU/O6H8kNzQ05Cc/+UnKysry/ve/vxQlAQAAQJfhvhkAAIBSKEn4e9111yVJXnrppdx8883ZtWtXq3137dqVhQsXZuvWrUmS2bNnl6IkAAAA6DLcNwMAAFAKFaWY9MMf/nCmTp2aZ555Jr///e8zY8aMTJkyJRMmTMiFF16YJKmrq0ttbW3WrFnT8r+cp06dmmuuuaYUJQEAAECX4b4ZAACAUihJ+Jsk3//+93Prrbfm2WefTUNDQ1avXp3Vq1ef0K+5uTlJctVVV+X73/9+qcoBAACALsV9MwAAAO2tZOFvnz598uMf/zgPP/xwHnrooWzZsuWk/caNG5cbb7wxc+fOLVUpAAAA0OW4bwYAAKC9lSz8PWrevHmZN29e6urqsmXLluzZsydJUlVVlXHjxmXIkCGlLgEAAAC6LPfNAAAAtJeSh79HXXjhhS3PLQIAAACO574ZAACAtmqX8HfHjh159NFHkyTvf//7c/XVV5/x2DVr1uT5559PksydOzcXX3xxe5QEAAAAXYb7ZgAAADpCu4S///RP/5SnnnoqQ4cOzd/8zd+c1djx48fnH//xH1NXV5c//vGP+d73vtceJQEAAECX4b4ZAACAjlDe1gleeeWVPPXUU0mSv/u7vzvrZxENGTIkf//3f5/m5uY8/vjjee2119paEgAAAHQZ7psBAADoKG0Ofx9//PE0Nzdn5MiR+djHPnZOc/zVX/1VRo0alebm5jz22GNtLQkAAAC6DPfNAAAAdJQ2h7/r169PWVlZqqurz3mOsrKyTJ8+Pc3NzXnuuefaWhIAAAB0Ge6bAQAA6ChtDn+3bNmSJJk4cWKb5rn88suPmw8AAACKwH0zAAAAHaXN4e+ePXuSJEOHDm3TPEfHv/nmm20tCQAAALoM980AAAB0lDaHv0eOHGmPOko2HwAAAHQm980AAAB0lDaHv1VVVUmS119/vU3zvPHGG8fNBwAAAEXgvhkAAICO0ubw9+KLL06S/Pd//3eb5vnDH/6QJBkxYkRbSwIAAIAuw30zAAAAHaXN4e8HP/jBNDc35/HHH8/hw4fPaY7Dhw9n1apVKSsryxVXXNHWkgAAAKDLcN8MAABAR2lz+Dtt2rQkyc6dO/PAAw+c0xwPPPBAdu7cmSSprq5ua0kAAADQZbhvBgAAoKO0Ofy9/PLLW/4X8w9+8IP87Gc/O6vxS5cuzaJFi1JWVpYPfvCDmTBhQltLAgAAgC7DfTMAAAAdpc3hb5L8v//3/9KnT580NzfnrrvuyoIFC/Lss8+mqanppP2bmpqydu3aLFiwIHfffXeam5vTp0+ffO1rX2uPcgAAAKBLcd8MAABAR6hoj0nGjh2b733ve/nSl76UxsbGPPvss3n22WdTWVmZd7/73bnwwgvTp0+f7N+/P3V1ddm0aVMOHjyYJGlubk7Pnj1zzz33ZPTo0e1RDgAAAHQp7psBAADoCO0S/iZvPcPopz/9ab70pS+1PIfowIED2bBhwwl9m5ubW9rveMc7smjRorzvfe9rr1IAAACgy3HfDAAAQKm1W/ibJO973/vyy1/+Mv/xH/+Rf//3f8///M//5PDhwycuWlGR8ePH5+Mf/3hmz56dHj16tGcZAAAA0CW5bwYAAKCU2jX8Td66QZ03b17mzZuX/fv3Z8uWLXnzzTdTX1+fvn37ZtCgQRk7dmz69u3b3ku3aG5uzv/+7//m+eefb/mzefPmNDY2JklWr16dSy655LTzHD58OMuWLcvKlSuzffv2NDQ0ZMSIEZk+fXrmz5+fwYMHn3aON954Iz/5yU/yn//5n3n11VfTs2fPXHrppbn22mvzyU9+MhUV7f5XAAAAQBfWFe6bAQAAKKaSJo99+vTJhAkTSrnESe3cuTOzZs1q0xz79u3LggULUltbe9z3t23blm3btmX58uVZsmRJ3vOe97Q6x8aNG/P5z38+u3fvbvne0Y/02rBhQ1auXJn7778//fv3b1OtAAAAnJ86674ZAACAYirv7AJKbfjw4ZkxY0YmTZp0VuPuuOOO1NbWpqysLLfcckueeuqp/PrXv05NTU369++f3bt3Z+HChdmzZ89Jx+/Zsye33HJLdu/enQEDBqSmpia//vWv89RTT+WWW25JWVlZNmzYkDvuuKM9ThMAAAAAAADo5goZ/lZVVeVf/uVfsnbt2jzzzDP54Q9/mL/8y7884/HPPPNM1qxZkyS57bbbcvvtt2fkyJG56KKLcv311+fee+9NWVlZdu3alfvvv/+kcyxZsiS7du1KWVlZFi9enOuvvz4XXXRRRo4cmdtvvz233XZbkmTNmjUtawEAAAAAAACcq0KGv/369cv06dMzdOjQcxq/dOnSJMmgQYOyYMGCE45PmjQp11xzTZLk4YcfzuHDh487fvjw4fz85z9PklxzzTUn3XW8YMGCVFVVHbceAAAAAAAAwLkqZPjbFgcPHsy6deuSJNXV1enZs+dJ+82cOTPJWx/vvH79+uOOPffcc9m7d+9x/d6uZ8+emT59epLk2WefzcGDB9ulfgAAAAAAAKB7Ev6+zdatW3Po0KEkyYQJE1rtd+yxF1544bhjx359JnMcOnQoL7300jnVCwAAAAAAAJAIf0+wffv2lvYll1zSar8RI0akvLz8hDHHfl1eXp4RI0a0Osex8799DgAAAAAAAICzIfx9mzfffLOlPWTIkFb79ejRIwMGDEjy1kc/n2yOAQMGpEePHq3OMXjw4Jb22+cAAAAAAAAAOBsVnV1AV3PgwIGWdq9evU7Z9+jx/fv3n3SO042vrKxsab99jvZUX19/wnOJO1NXqqW7mThxYpJk3759nVrHqdbviNq68vlbv/3HlWoe65+79n4f8L7CqXh90BqvDQAAAKCI7PwFAAAAAAAAKAA7f9+md+/eLe1Dhw6dsu/R43369DnpHKcbf/DgwZb22+doT/369cu4ceNKNv+ZOrq74ujuUzpP//79u9z6R3cjdkRtXfH8rd+69n5tnG/nX7T1k/Z7H/C+wql4fdAar42uYfPmzamvr+/sMgAAAKBw7Px9m0GDBrW0X3/99Vb7NTY2Zu/evUmSqqqqk86xd+/eHD58uNU53njjjZb22+cAAAAAAAAAOBvC37e59NJLW9qvvPJKq/1effXVNDU1nTDm2K+bmpqyc+fOVuc4dv63zwEAAAAAAABwNoS/bzNmzJj06tUrSVJbW9tqvw0bNrS0x48ff9yxY78+kzl69eqV0aNHn1O9AAAAAAAAAInw9wSVlZW58sorkySrV69OQ0PDSfs98cQTSd76uOa3Py9s0qRJGTBgwHH93q6hoSG/+tWvkiQf+tCHUllZ2S71AwAAAAAAAN2T8PckPvWpTyV565m8Dz744AnH169fn6effjpJMm/evFRUVBx3vKKiIp/4xCeSJP/1X/+V9evXnzDHgw8+2PLM36PrAQAAAAAAAJyritN3OT+99NJLqa+vb/n6tddea2m/+OKLqaura/l65MiRGTx4cMvXU6dOzZQpU7JmzZosWrQoBw4cyNy5c1NZWZm1a9empqYmTU1NGTZsWG666aaTrn/zzTdn5cqV2bVrV/72b/82X/3qVzN58uQcPHgwv/jFL3LfffclSaZMmZIpU6a09+kDAAAAAAAA3Uxhw99vfvOb+f3vf3/SY7feeutxX9fU1OT6668/7nv33HNPbrrpptTW1mbx4sVZvHjxcceHDh2aH/3oR6mqqjrpGlVVVbn33nvz+c9/Prt3784//MM/nNBnwoQJ+ed//uezOS0AAAAAAACAkyps+NtWAwYMyNKlS7Ns2bKsWLEi27dvT2NjY0aMGJHq6up87nOfO2638Mm8973vzYoVK/Lggw9m9erVefXVV9OjR4/8xV/8Ra699tp88pOfPOEjowEAAAAAAADORWGTx4ceeqjNc1RUVOSGG27IDTfccM5zDB48OF/+8pfz5S9/uc31AAAAAAAAALSmvLMLAAAAAAAAAKDthL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACiAis4uAAAAAAAAgK7vziUvdfia3715dIevCeczO38BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKoKKzCwAAOBcTJ07s7BIAAAAAALoUO38BAAAAAAAACsDOXwCgQ9255KV2mWffvn1Jkv79+59R/+/ePLpd1gUAAAAA6Krs/AUAAAAAAAAoAOEvAAAAAAAAQAH42GcAAAAAAACOM3HixM4uATgHdv4CAAAAAAAAFICdvwAAAAAAAOeJO5e81CHr7Nu3L0nSv3//fPfm0R2yJtB2dv4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAVR0dgEAAADA+WXatGnZuXPnGfe/9dZb84UvfKHl6+XLl+erX/3qaceNGTMmjz322DnVCAAA0B3Z+QsAAACU1NixYzu7BAAAgG7Bzl8AAADgrKxatSpNTU2n7PPpT386L774YgYOHJgPf/jDrfb7wx/+0OqxCy644JxrBAAA6I6EvwAAAMBZ6d279ymPb9u2LS+++GKSZObMmenZs2erffv27duutQEAAHRnPvYZAAAAaFePPPJIS3vOnDmdWAkAAED3IvwFAAAA2k1zc3NWrlyZJBk1alQmTJjQyRUBAAB0H8JfAAAAoN389re/zZ/+9KckyXXXXXfG4xoaGkpVEgAAQLfhmb8AAABAu3n00UeTJGVlZWcU/s6ZMydbt25NY2Nj+vTpk/e+972ZMWNGPvGJT6RPnz6lLhcAAKBQ7PwFAAAA2sWBAwfyy1/+MklyxRVX5B3veMdpx2zcuDGNjY1Jkv379+e5555LTU1NPvaxj2XTpk0lrRcAAKBo7PwFAAAA2sWTTz6Z/fv3J0lmz57dar/KysrMmTMn06dPz7ve9a4MHz48R44cyaZNm7J06dKsWrUqO3bsyIIFC7J8+fIMGzaspHXX19dn/fr1JV3jbHSlWroD17vj7du3r9ut3R3Pubuu3R3PuTPWPnY9f9cdu15nnnd3eM/uDufYlRT1egt/AQAAgHaxYsWKJEnv3r3zkY98pNV+s2bNyqxZs074/qRJkzJp0qRcdtllqampSV1dXRYtWpSampqS1QwAAFAkwl8AAACgzf785z9n3bp1SZLq6ur069fvnOeaP39+Vq1aleeffz5PPPFE7rrrrvTo0aO9Sj1Bv379Mm7cuJLNf6aO7jyYOHFiJ1fSPbjeHevYnTX9+/fvtDo6a+2OXPftu/K64/XuyLVd745d++j1Pna97vDvurPW7krXOyn2e7afSzrW+XC9N2/enPr6+nMa65m/AAAAQJutWLEiR44cSZLMmTOnzfNNmzYtyVvPAX755ZfbPB8AAEB3IPwFAAAA2uzRRx9Nklx00UX50Ic+1Ob5hgwZ0tLeu3dvm+cDAADoDoS/AAAAQJts3LgxW7ZsSZJce+21KS9v+68bdu/e3dIeMGBAm+cDAADoDoS/AAAAQJsc3fWbJLNnz26XOVevXp0k6du3b975zne2y5wAAABFJ/wFAAAAztmRI0fy2GOPJUnGjx+fsWPHnrJ/fX196uvrT9nnvvvuywsvvJAkmTlzZnr06NE+xQIAABRcRWcXAAAAAJy/1q5dm7q6uiTJddddd9r+O3bsyI033phZs2ZlypQpGTNmTAYOHJiGhoZs2rQpP/vZz1p2/Q4dOjRf/OIXS1o/AABAkQh/AQAAgHP2yCOPJEkqKipy7bXXntGYvXv3ZtmyZVm2bFmrfUaPHp0f/OAHGTZsWLvUCQAA0B0IfwEAAIBzUl9fn1/96ldJkquvvjqDBw8+7ZiRI0fmW9/6VjZs2JCNGzemrq4ue/bsSXl5eQYPHpzx48dn+vTpmTVrVnr27FnqUwAAACgU4S8AAABwTvr165fa2tqzGtO3b9/Mmzcv8+bNK1FVAAAA3Vd5ZxcAAAAAAAAAQNsJfwEAAAAAAAAKwMc+AwDdyp1LXuqUdb978+hOWRcAAAAA6D7s/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUAAVnV1AVzRt2rTs3LnzjPvfeuut+cIXvtDy9fLly/PVr371tOPGjBmTxx577JxqBAAAAAAAADiWnb/tYOzYsZ1dAgAAAAAAANDN2fl7EqtWrUpTU9Mp+3z605/Oiy++mIEDB+bDH/5wq/3+8Ic/tHrsggsuOOcaAQAAAAAAAI4l/D2J3r17n/L4tm3b8uKLLyZJZs6cmZ49e7bat2/fvu1aGwAAAAAAAMDJ+Njnc/DII4+0tOfMmdOJlQAAAAAAAAC8Rfh7lpqbm7Ny5cokyahRozJhwoROrggAAAAAAABA+HvWfvvb3+ZPf/pTkuS6664743ENDQ2lKgkAAAAAAADAM3/P1qOPPpokKSsrO6Pwd86cOdm6dWsaGxvTp0+fvPe9782MGTPyiU98In369Cl1uQAAAAAAAEA3YefvWThw4EB++ctfJkmuuOKKvOMd7zjtmI0bN6axsTFJsn///jz33HOpqanJxz72sWzatKmk9QIAAAAAAADdh52/Z+HJJ5/M/v37kySzZ89utV9lZWXmzJmT6dOn513veleGDx+eI0eOZNOmTVm6dGlWrVqVHTt2ZMGCBVm+fHmGDRtW0rrr6+uzfv36kq5xNrpSLd3NxIkTkyT79u3r1DpOtX5H1NaVz9/67T+uVPNYv+vUcLbzdfY18D7YsVxvWuO1AQAAABSR8PcsrFixIknSu3fvfOQjH2m136xZszJr1qwTvj9p0qRMmjQpl112WWpqalJXV5dFixalpqamZDUDAAAAAAAA3YPw9wz9+c9/zrp165Ik1dXV6dev3znPNX/+/KxatSrPP/98nnjiidx1113p0aNHe5V6gn79+mXcuHElm/9MHd1dcXT3KZ2nf//+XW79ozvxOqK2rnj+1m9de782zrfzL9r67VnDub42OvsaeB/sGH7uoDVeG13D5s2bU19f39llAAAAQOF45u8ZWrFiRY4cOZIkmTNnTpvnmzZtWpK3ngP88ssvt3k+AAAAAAAAoHsT/p6hRx99NEly0UUX5UMf+lCb5xsyZEhLe+/evW2eDwAAAAAAAOjehL9nYOPGjdmyZUuS5Nprr015edsv2+7du1vaAwYMaPN8AAAAAAAAQPcm/D0DR3f9Jsns2bPbZc7Vq1cnSfr27Zt3vvOd7TInAAAAAAAA0H0Jf0/jyJEjeeyxx5Ik48ePz9ixY0/Zv76+PvX19afsc9999+WFF15IksycOTM9evRon2IBAAAAAACAbquiswvo6tauXZu6urokyXXXXXfa/jt27MiNN96YWbNmZcqUKRkzZkwGDhyYhoaGbNq0KT/72c9adv0OHTo0X/ziF0taPwAAAAAAANA9CH9P45FHHkmSVFRU5Nprrz2jMXv37s2yZcuybNmyVvuMHj06P/jBDzJs2LB2qRMAAAAAuqqJEyd2dgkAAN2C8PcU6uvr86tf/SpJcvXVV2fw4MGnHTNy5Mh861vfyoYNG7Jx48bU1dVlz549KS8vz+DBgzN+/PhMnz49s2bNSs+ePUt9CgAAAAAAAEA3Ifw9hX79+qW2tvasxvTt2zfz5s3LvHnzSlQVAAAAALTNnUte6tD19u3bl//vjss7dE0AgO6ovLMLAAAAAAAAAKDthL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAqjo7AIAALqTO5e81Cnrfvfm0Z2yLgAAAADQcez8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAAqgorMLAAAAAM4vr7zySqqrq8+o77p16zJ48OCTHjt8+HCWLVuWlStXZvv27WloaMiIESMyffr0zJ8/v9VxAAAAnJzwFwAAAOhw+/bty4IFC1JbW3vc97dt25Zt27Zl+fLlWbJkSd7znvd0UoUAAADnH+EvAAAAcM7uu+++TJo0qdXjffv2Pen377jjjtTW1qasrCwLFy7M3LlzU1lZmbVr1+Y73/lOdu/enYULF2bFihWpqqoqVfkAAACF4pm/AAAAwDmrrKxM3759W/1zMs8880zWrFmTJLntttty++23Z+TIkbnoooty/fXX5957701ZWVl27dqV+++/vyNPBwAA4Lwm/AUAAAA61NKlS5MkgwYNyoIFC044PmnSpFxzzTVJkocffjiHDx/uyPIAAADOW8JfAAAAoMMcPHgw69atS5JUV1enZ8+eJ+03c+bMJMmePXuyfv36DqsPAADgfCb8BQAAANqsoaHhjPpt3bo1hw4dSpJMmDCh1X7HHnvhhRfaVhwAAEA3UdHZBQAAAADnr7vvvjs7d+7M/v3707Nnz4waNSpXX311brzxxgwfPvyE/tu3b29pX3LJJa3OO2LEiJSXl6epqem4MQAAALTOzl8AAADgnG3dujX79+9P8tbu3y1btuSBBx7IzJkzs2rVqhP6v/nmmy3tIUOGtDpvjx49MmDAgCRvffQzAAAAp2fnLwAAAHBWysvLM3ny5Hz0ox/N+PHjc/HFFwaHD5kAACAASURBVKdXr155+eWXs2rVqvz4xz/O/v3785WvfCUDBw7M5MmTW8YeOHCgpd2rV69TrnP0+NFwuVTq6+u71HOFu1It3UF3u94TJ05Mkuzbt6/TauiOa3fHc+6ua3fHc+6MtY9dz991x67XmefdHd6zu8M5diVFvd7CXwAAAOCsjBgxIg888MAJ3x87dmzGjh2bqVOnZv78+Tl06FDuvvvuPP7447ngggs6oVIAAIDuRfgLAAAAtKsPfOAD+cxnPpP7778/f/zjH/P888/n8ssvT5L07t27pd+hQ4dOOc/R43369CldsUn69euXcePGlXSNM3F058HRnZmUVne/3v379+/Q9Y7dKdbRax+rs9buyHXfviuvO17vjlzb9e7YtY9e72PX6w7/rjtr7a50vZNiv2d3959LOtr5cL03b96c+vr6cxrrmb8AAABAu5s2bVpLe+PGjS3tQYMGtbRff/31Vsc3NjZm7969SZKqqqoSVAgAAFA8wl8AAACg3Q0ZMqSlfeyuqEsvvbSl/corr7Q6/tVXX01TU9MJYwAAAGid8BcAAABod3V1dS3tYz8ecMyYMenVq1eSpLa2ttXxGzZsaGmPHz++BBUCAAAUj/AXAAAAaHdPPfVUS/vY8LaysjJXXnllkmT16tVpaGg46fgnnngiyVsf+dyVn8UFAADQlVR0dgEAAADA+eW1117L8OHDWz3+u9/9LkuXLk2SjBo1Kpdddtlxxz/1qU/l6aefzhtvvJEHH3wwCxcuPO74+vXr8/TTTydJ5s2bl4oKv74AAOju7lzyUoeu992bR3foetBe3D0BAAAAZ2X27Nm54oorUl1dnfHjx+fCCy9MkuzYsSOrVq3KT3/60zQ2NqaioiJf//rXU15+/AePTZ06NVOmTMmaNWuyaNGiHDhwIHPnzk1lZWXWrl2bmpqaNDU1ZdiwYbnppps64xQBAADOS8JfAAAA4KwcPnw4Tz75ZJ588slW+wwcODDf/va3c9VVV530+D333JObbroptbW1Wbx4cRYvXnzc8aFDh+ZHP/pRqqqq2rV2AACAIhP+AgAAAGelpqYmzz33XGpra7Nr167s2bMnjY2NGThwYEaPHp3Jkyfn4x//eAYNGtTqHAMGDMjSpUuzbNmyrFixItu3b09jY2NGjBiR6urqfO5zn8vgwYM78KwAAADOf8JfAAAA4KzMmDEjM2bMaPM8FRUVueGGG3LDDTe0Q1UAAACUn74LAAAAAAAAAF2d8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACiAis4uAAAA2tvEiRM7uwQAAAAA6HDC35N45ZVXUl1dfUZ9161bl8GDB5/02OHDh7Ns2bKsXLky27dvT0NDQ0aMGJHp06dn/vz5rY4DAAAAAAAAOFvC3xLZt29fFixYkNra2uO+v23btmzbti3Lly/PkiVL8p73vKeTKgQA6Hh3LnmpQ9bZt29fkqR///5Jku/ePLpD1gUAAACAziT8PY377rsvkyZNavV43759T/r9O+64I7W1tSkrK8vChQszd+7cVFZWZu3atfnOd76T3bt3Z+HChVmxYkWqqqpKVT4AAAAAAADQTZR3dgFdXWVlZfr27dvqn5N55plnsmbNmiTJbbfdlttvvz0jR47MRRddlOuvvz733ntvysrKsmvXrtx///0deToAAAAAAABAQQl/S2Dp0qVJkkGDBmXBggUnHJ80aVKuueaaJMnDDz+cw4cPd2R5AAAAAAAAQAEJf9vZwYMHs27duiRJdXV1evbsedJ+M2fOTJLs2bMn69ev77D6AAAAAAAAgGIS/p6hhoaGM+q3devWHDp0KEkyYcKEVvsde+yFF15oW3EAAAAAAABAt1fR2QV0dXfffXd27tyZ/fv3p2fPnhk1alSuvvrq3HjjjRk+fPgJ/bdv397SvuSSS1qdd8SIESkvL09TU9NxYwAAAAAAAADOhZ2/p7F169bs378/yVu7f7ds2ZIHHnggM2fOzKpVq07o/+abb7a0hwwZ0uq8PXr0yIABA5K89dHPAAAAAAAAAG1h5+9JlJeXZ/LkyfnoRz+a8ePH5+KLL06vXr3y8ssvZ9WqVfnxj3+c/fv35ytf+UoGDhyYyZMnt4w9cOBAS7tXr16nXOfo8aPhcqnU19d3qecKd6VaupuJEycmSfbt29epdZxq/Y6orSufv/Xbf1yp5rF+16nhbOfr7GvQ2et31vtwZ70HvX09P4dwlNcCAAAAUETC35MYMWJEHnjggRO+P3bs2IwdOzZTp07N/Pnzc+jQodx99915/PHHc8EFF3RCpQAAAAAAAABvEf6egw984AP5zGc+k/vvvz9//OMf8/zzz+fyyy9PkvTu3bul36FDh045z9Hjffr0KV2xSfr165dx48aVdI0zcXR3xdGdP3Se/v37d7n1j+7M6ojauuL5W7917f3aON/Ov2jrt2cN5/ra6Oxr0Nnrd/b7cEedf2uvj84+fzqfn0m7hs2bN6e+vr6zywAAAIDC8czfczRt2rSW9saNG1vagwYNamm//vrrrY5vbGzM3r17kyRVVVUlqBAAAAAAAADoToS/52jIkCEt7WOfJXfppZe2tF955ZVWx7/66qtpamo6YQwAAAAAAADAuRD+nqO6urqW9rEfJzhmzJj06tUrSVJbW9vq+A0bNrS0x48fX4IKAQAAAAAA6OomTpzo8US0G+HvOXrqqada2seGt5WVlbnyyiuTJKtXr05DQ8NJxz/xxBNJ3vrIZ/+gAQAAAAAAgLaq6OwCuqLXXnstw4cPb/X47373uyxdujRJMmrUqFx22WXHHf/Upz6Vp59+Om+88UYefPDBLFy48Ljj69evz9NPP50kmTdvXioq/DUAAHSEO5e81Cnrfvfm0Z2yLgAAANA2HfG7hKOPFz36SbN+j0BbSB1PYvbs2bniiitSXV2d8ePH58ILL0yS7NixI6tWrcpPf/rTNDY2pqKiIl//+tdTXn78BuqpU6dmypQpWbNmTRYtWpQDBw5k7ty5qayszNq1a1NTU5OmpqYMGzYsN910U2ecIgAAAAAAAFAwwt+TOHz4cJ588sk8+eSTrfYZOHBgvv3tb+eqq6466fF77rknN910U2pra7N48eIsXrz4uONDhw7Nj370o1RVVbVr7QAAAAAAAED3JPw9iZqamjz33HOpra3Nrl27smfPnjQ2NmbgwIEZPXp0Jk+enI9//OMZNGhQq3MMGDAgS5cuzbJly7JixYps3749jY2NGTFiRKqrq/O5z30ugwcP7sCzAgAAAAAAAIpM+HsSM2bMyIwZM9o8T0VFRW644YbccMMN7VAVAAAAAAAAQOvKT98FAAAAAAAAgK5O+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoACEvwAAAAAAAAAFIPwFAAAAAAAAKADhLwAAAAAAAEABCH8BAAAAAAAACkD4CwAAAAAAAFAAwl8AAAAAAACAAhD+AgAAAAAAABSA8BcAAAAAAACgAIS/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAAAAAAAQAEIfwEAAAAAAAAKQPgLAAAAAAAAUADCXwAAAAAAAIACEP4CAAAAAAAAFIDwFwAAAAAAAKAAhL8AAAAAAAAABSD8BQAAAAAAACgA4S8AAAAAAABAAQh/AQAAAAAAAApA+AsAAAAAAABQAMJfAAAAAAAAgAIQ/gIAAAAAAAAUgPAXAAAAAAAAoAAqOrsAAAA6zp1LXuqUdb978+hOWRcAAADgfNUZv8fxO5zzn52/AAAAAAAAAAUg/AUAAAAAAAAoAOEvAAD/f3v3HmRFdScO/AvDADKggCCo+CphWB1FETTR+Ig4VpbZoLIVLDEPRcAkJmqMZtHKEgzqEk2wFI3JCmp0N4ZNSkxAXNcEMRJf4bE6EQREI6K8HN4Dwgxwf3/wm7sM82Bg7swd+n4+VVT13D59zrnnfum+p7+3uwEAAACABJD8BQAAAAAAAEgAyV8AAAAAAACABJD8BQAAAAAAAEgAyV8AAAAAAACABJD8BQAAAAAAAEgAyV8AAAAAAACABJD8BQAAAAAAAEgAyV8AAAAAAACABJD8BQAAAAAAAEgAyV8AAAAAAACABJD8BQAAAAAAAEiANtnuAAAA5Ioxk5dlpd17R/fOSrsAAAAANC9X/gIAAAAAAAAkgOQvAAAAAAAAQAJI/gIAAAAAAAAkgOQvAAAAAAAAQAJI/gIAAAAAAAAkgOQvAAAAAAAAQAJI/gIAAAAAAAAkgOQvAAAAAAAAQAJI/gIAAAAAAAAkgOQvAAAAAAAAQAJI/gIAAAAAAAAkgOQvAAAAAAAAQAJI/gIAAAAAAAAkgOQvAAAAAAAAQAJI/gIAAAAAAAAkgOQvAAAAAAAAQAJI/gIAAAAAAAAkgOQvAAAAAAAAQAJI/gIAAAAAAAAkQJtsdwBy0ZjJy7LS7r2je2elXQAAAAAAAJqeK38BAAAAAAAAEkDyFwAAAAAAACABJH8BAAAAAAAAEkDyFwAAAAAAACABJH8BAAAAAAAAEkDyFwAAAAAAACABJH8BAAAAAAAAEkDyFwAAAAAAACABJH8BAAAAAAAAEkDyFwAAAAAAACABJH8BAAAAAAAAEkDyFwAAAAAAACABJH8BAAAAAAAAEkDyFwAAAAAAACAB2mS7AwAAAACQi8ZMXtbsbd47uneztwkAQPNx5S8AAAAAAABAAkj+AgAAAAAAACSA5C8AAAAAAABAAkj+AgAAAAAAACSA5C8AAAAAAABAArTJdgcAAACAQ8+OHTtizpw58Ze//CVKS0tjxYoVsW3btujYsWP06dMnBg0aFFdeeWV07Nix1u2nTZsWd9xxx37b6dOnTzz33HOZ7j4AAEAiSf4CAAAAB+zcc8+NrVu31nh948aNMXfu3Jg7d248+eST8dBDD0W/fv2y0EMAAIDcI/kLAAAAHLCtW7dGfn5+FBcXR3FxcZx++unRuXPnWLt2bUyfPj0ef/zxWL16dYwaNSpmzJgRPXr0qLOuBQsW1LkuLy+vKboPAACQSJK/AACQI8ZMXpaVdu8d3Tsr7QJN6+qrr44bbrghunfvXu31I444Im699dYoLCyM2267LTZt2hS/+MUv4s4776yzroKCgibuLQAAQG5one0OAAAAAIeecePG1Uj87m3IkCFRWFgYERGvvPJKc3ULAAAgp0n+AgAAAE2iT58+ERGxdu3aLPcEAAAgN0j+AgAAAE2irKwsIiI6derUoPIVFRVN2R0AAIDE88xfAAAAIOPKyspiwYIFERHRv3//essOHTo03nvvvaisrIwOHTrEqaeeGpdeemlceeWV0aFDh+boLgAAQCK48hcAAADIuIkTJ0ZlZWVERAwfPrzesosWLUqX3bZtW8ybNy8mTJgQl112WSxevLjJ+woAAJAUrvwFAAAAMmr69Okxbdq0iIgYNGhQXHDBBTXKtG/fPoYOHRrFxcVx8sknR8+ePWPXrl2xePHiePrpp2PmzJmxYsWKGDlyZEybNi169OjRZP0tLy+P+fPnN1n9B6ol9SUXZGO8BwwYEBERW7Zsafa2q2g7N9rVdu60m2tt792ez7p528ul952NdvdtK5vjnQvfSZP6HiV/AQAAgIwpLS2NsWPHRkTE0UcfHffcc0+t5UpKSqKkpKTG6wMHDoyBAwdGv379YsKECVFWVhYPPPBATJgwoUn7DQAAkASSvwAAAEBGfPDBB3H99dfH9u3bo3PnzjFlypTo2rXrQdV17bXXxsyZM6O0tDReeOGFGD9+fOTn52e4x3t07Ngx+vbt2yR1H4iqKw+qrgqlabWE8e7UqVPOtL33lUu59L6z0e6+V4nl4ng3Z9vGu3nbrhrvvdvLhf/X2Wq7JY13NttujnZrG+vmarsuSf5O2hK+B+7PkiVLory8/KC29cxfAAAAoNFWrlwZ1113XWzYsCEKCgpi8uTJ0bt370bVOWjQoIjY8xzg5cuXZ6KbAAAAiSb5CwAAADRKWVlZjBgxIlatWhXt27ePX/7yl9GvX79G13vkkUemlzdv3tzo+gAAAJJO8hcAAAA4aJs2bYoRI0bEhx9+GPn5+TFp0qQ455xzMlL3p59+ml4+/PDDM1InAABAkkn+AgAAAAdl69atMWrUqFi6dGm0bt067rvvvrjooosyVv+sWbMiIqKgoCBOOOGEjNULAACQVJK/AAAAwAGrqKiIb3/721FaWhoREePHj4+SkpIGbVteXh7l5eX1lnn00Udj4cKFERExePDgyM/Pb1yHAQAAckCbbHegpdqxY0fMmTMn/vKXv0RpaWmsWLEitm3bFh07dow+ffrEoEGD4sorr4yOHTvWuv20adPijjvu2G87ffr0ieeeey7T3QcAAIAms2vXrvje974Xb775ZkRE3HTTTVFSUhJbt26tc5sOHTpEq1atIiJixYoV8Y1vfCNKSkriwgsvjD59+sQRRxwRFRUVsXjx4vjNb36Tvuq3e/fucdNNNzX9mwIAAEgAyd86nHvuubVOWjdu3Bhz586NuXPnxpNPPhkPPfRQ9OvXLws9BAAAgOxYtWpVOjkbETFp0qSYNGlSvdvMmjUrevXqlf578+bNMXXq1Jg6dWqd2/Tu3TsefPDB6NGjR+M7DQAAkAMkf+uwdevWyM/Pj+Li4iguLo7TTz89OnfuHGvXro3p06fH448/HqtXr45Ro0bFjBkz6p2ILliwoM51eXl5TdF9AAAAaLGOP/74uPvuu+Ott96KRYsWRVlZWWzcuDFat24dXbt2jaKioiguLo6SkpJo27ZttrsLAABwyJD8rcPVV18dN9xwQ3Tv3r3a60cccUTceuutUVhYGLfddlts2rQpfvGLX8Sdd95ZZ10FBQVN3FsAAABoPr169YolS5Yc9PYFBQUxbNiwGDZsWAZ7BQAAQOtsd6ClGjduXI3E796GDBkShYWFERHxyiuvNFe3AAAAAAAAAGol+dsIffr0iYiItWvXZrknAAAAAAAAQK6T/G2EsrKyiIjo1KlTg8pXVFQ0ZXcAAAAAAACAHOaZvweprKwsFixYEBER/fv3r7fs0KFD47333ovKysro0KFDnHrqqXHppZfGlVdeGR06dGiO7gIAAAAAAAAJ58rfgzRx4sSorKyMiIjhw4fXW3bRokXpstu2bYt58+bFhAkT4rLLLovFixc3eV8BAAAAAACA5HPl70GYPn16TJs2LSIiBg0aFBdccEGNMu3bt4+hQ4dGcXFxnHzyydGzZ8/YtWtXLF68OJ5++umYOXNmrFixIkaOHBnTpk2LHj16NFl/y8vLY/78+U1W/4FqSX1pbgMGDIiIiC1btmS1Hy25/eboW0t+/9rP/HZNVY/2W04fDrS+bI+B9pu3/X3by7X339Lab0nfA1tSXwAAAAAyRfL3AJWWlsbYsWMjIuLoo4+Oe+65p9ZyJSUlUVJSUuP1gQMHxsCBA6Nfv34xYcKEKCsriwceeCAmTJjQpP0GAAAAAAAAkk3y9wB88MEHcf3118f27dujc+fOMWXKlOjatetB1XXttdfGzJkzo7S0NF544YUYP3585OfnZ7jHe3Ts2DH69u3bJHUfiKqrK6qufs1lnTp10v4+qq5Eao6+tcT3r/26ZTo2DrX3n7T2M9mHg42NbI+B9pun/briI1fef0ttvyV8D/SdtGVYsmRJlJeXZ7sbAAAAkDie+dtAK1eujOuuuy42bNgQBQUFMXny5Ojdu3ej6hw0aFBE7HkO8PLlyzPRTQAAAAAAACBHSf42QFlZWYwYMSJWrVoV7du3j1/+8pfRr1+/Rtd75JFHppc3b97c6PoAAAAAAACA3CX5ux+bNm2KESNGxIcffhj5+fkxadKkOOecczJS96effppePvzwwzNSJwAAAAAAAJCbJH/rsXXr1hg1alQsXbo0WrduHffdd19cdNFFGat/1qxZERFRUFAQJ5xwQsbqBQAAAAAAAHKP5G8dKioq4tvf/naUlpZGRMT48eOjpKSkQduWl5dHeXl5vWUeffTRWLhwYUREDB48OPLz8xvXYQAAAAAAACCntcl2B1qiXbt2xfe+97148803IyLipptuipKSkti6dWud23To0CFatWoVERErVqyIb3zjG1FSUhIXXnhh9OnTJ4444oioqKiIxYsXx29+85v0Vb/du3ePm266qenfFAAAAAAAAJBokr+1WLVqVTo5GxExadKkmDRpUr3bzJo1K3r16pX+e/PmzTF16tSYOnVqndv07t07HnzwwejRo0fjOw0AAAAAAADkNMnfJnD88cfH3XffHW+99VYsWrQoysrKYuPGjdG6devo2rVrFBUVRXFxcZSUlETbtm2z3V0AAAAAAAAgASR/a9GrV69YsmTJQW9fUFAQw4YNi2HDhmWwVwAAAAAAAAB1a53tDgAAAAAAAADQeJK/AAAAAAAAAAkg+QsAAAAAAACQAJK/AAAAAAAAAAkg+QsAAAAAAACQAJK/AAAAAAAAAAkg+QsAAAAAAACQAJK/AAAAAAAAAAkg+QsAAAAAAACQAJK/AAAAAAAAAAnQJtsdAAAAcsOYycuy0u69o3tnpV0AAACA5ubKXwAAAAAAAIAEkPwFAAAAAAAASADJXwAAAAAAAIAEkPwFAAAAAAAASADJXwAAAAAAAIAEkPwFAAAAAAAASADJXwAAAAAAAIAEkPwFAAAAAAAASADJXwAAAAAAAIAEkPwFAAAAAAAASADJXwAAAAAAAIAEkPwFAAAAAAAASADJXwAAAAAAAIAEkPwFAAAAAAAASADJXwAAAAAAAIAEkPwFAAAAAAAASADJXwAAAABy0oABA7LdBQAAyCjJXwAAAAAAAIAEaJPtDgAAAABANo2ZvKxZ27t3dO9mbQ8AgNzhyl8AAAAAAACABJD8BQAAAAAAAEgAyV8AAAAAAACABJD8BQAAAAAAAEgAyV8AAAAAAACABJD8BQAAAAAAAEgAyV8AAAAAAACABJD8pVkNGDAg210AAAAAAACARJL8BQAAAAAAAEiANtnuALlpzORlWWn33tG9s9IuAAAAAAAANDVX/gIAAAAAAAAkgOQvAAAAAAAAQAJI/gIAAAAAAAAkgOQvAAAAAAAAQAJI/gIAAAAAAAAkgOQvAAAAAAAAQAJI/gIAAAAAAAAkQJtsdwAAAKC5DBgwINtdAAAAAGgyrvwFAAAAAAAASABX/gIAADlhzORlsWXLloiI6NSpU7O1e+/o3s3WFgAAAJDbXPkLAAAAAAAAkACSvwAAAAAAAAAJIPkLAAAAAAAAkACSvwAAAAAAAAAJIPkLAAAAAAAAkACSvwAAAAAAAAAJIPkLAAAAAAAAkACSvwAAAAAAAAAJIPkLAAAAAAAAkACSvwAAAAAAAAAJIPkLAAAAAAAAkACSvwAAAAAAAAAJ0CbbHQAAAAAAAABajjGTlzV7m/eO7t3sbSaRK38BAAAAAAAAEkDyFwAAAAAAACABJH8BAAAAAAAAEkDyFwAAAAAAACABJH8BAAAAAAAAEkDyFwAAAAAAACABJH8BAAAAAAAAEkDyFwAAAAAAACABJH8BAAAAWogBAwZkuwsAAMAhTPIXAAAAAAAAIAHaZLsDAAAAAFQ3ZvKyZm3v3tG9m7U9AACgabjyFwAAAAAAACABJH8BAAAAAAAAEkDyFwAAAAAAACABJH8BAAAAAAAAEkDyFwAAAAAAACABJH8BAAAAAAAAEkDyFwAAAAAAACABJH8BAAAAAAAAEkDyFwAAAAAAACABJH8BAAAAAAAAEkDyFwAAAAAAACABJH8BAAAAAAAAEkDyFwAAAAAAACABJH8BAAAAAAAAEqBNtjsA2TBm8rKstHvv6N5ZaRcAAAAAAIDkc+UvAAAAAAAAQAJI/gIAAAAAAAAkgOQvAAAAAAAAQAJI/gIAAAAAAAAkgOQvAAAAAAAAQAJI/gIAAAAAAAAkgOQvAAAAAAAAQAJI/gIAAAAAAAAkgOQvAAAAAAAAQAK0yXYHAAAAcsGYycuy0u69o3tnpV0AAACg+Un+AgAAAAAAADlhwIAB2e5Ck3LbZwAAAAAAAIAEcOUvAAAAABGRnVvUuz09AAB7a+rvpFu2bImIiE6dOkVE8r6PSv42k9mzZ8fUqVNj4cKFsWnTpujWrVuce+65cc0110Tfvn2z3T0AAADIKvNmAACAxnPb52Ywbty4+Na3vhUvv/xyfPrpp1FRURErV66MZ555Jr7yla/E73//+2x3EQAAALLGvBkAACAzJH+b2OTJk2Pq1KkREVFcXBzTpk2L119/PR577LEoLCyMioqK+OEPfxjz58/Pck8BAACg+Zk3AwAAZI7kbxNav359PPLIIxERcf7558fDDz8cRUVF0bVr1zj//PPjqaeeim7dusXOnTvj3nvvzXJvAQAAoHmZN5NNAwYMyHYXAAAg4yR/m9Czzz4b27Zti4iI73//+9GqVatq67t06RKjRo2KiIi33347Fi5c2Ox9BAAAgGwxbwYAAMisNtnuQJLNnj07IiKOP/74KCoqqrXM4MGD4yc/+UlERLz00kt1lgMAAICkMW9mb2MmL2vW9rZs2RKPfL9/s7YJAABNzZW/TajqF8lnnHFGnWV69uwZPXr0qFYeAAAAcoF5MwAAQGZJ/jaRNWvWpG9dddxxx9VbtlevXhER8fe//73J+wUAAAAtgXkzAABA5kn+NpENGzakl4888sh6y1at37hxY5P2CQAAAFoK82YAAIDMa5VKpVLZ7kQSLViwIIYPHx4REXfffXcMGzaszrK33XZbzJgxI/Lz8+Odd97JWB9KS0ujsrIyY/VlQseOHbPdMDX/7wAAHx5JREFUBQAAyEnl5eXZ7kIN+fn50a9fv2x3gywxb66deTMAAGRHUubNbZqoL7QAu3btynYXamiJ/3EAAIDsaIlzFnJLS4xB82YAAKDKwcxZJH+bSIcOHdLLO3bsqLds1fqCgoKM9qFdu3axY8eOyMvLi3bt2mW0bgAAgIO1Y8eO2LVrl3lKjjNvBgAAqF1j5s2Sv02kS5cu6eV169bVW7ZqfefOnTPah1NPPTWj9QEAAECmmDcDAABkXutsdyCpjjrqqPSvmFesWFFv2Y8//jgiIk466aQm7xcAAAC0BObNAAAAmSf520RatWoVRUVFERFRWlpaZ7nVq1fHmjVrIiLS5QEAACDpzJsBAAAyT/K3CV188cUREbF8+fJ49913ay3zwgsvpJcHDRrULP0CAACAlsC8GQAAILMkf5vQ0KFD07ewmjhxYqRSqWrrN27cGFOmTImIiDPOOMMvmAEAAMgp5s0AAACZlXfnnXfeme1OJNVhhx0WeXl58dprr8VHH30US5cujZNOOiny8vJiwYIFceutt8aKFSuiTZs2MXHixDjmmGOy3WUAAABoNubNAAAAmdUqte/Pasm4cePGxdSpU2tdl5+fH3fffXdcccUVzdwrAAAAaBnMmwEAADJD8reZzJ49O37zm9/EwoULY9OmTdG9e/f4/Oc/H9dee2307ds3290DAACArDJvBgAAaDzJXwAAAAAAAIAEaJ3tDgAAAAAAAADQeJK/AAAAAAAAAAkg+QsAAAAAAACQAJK/AAAAAAAAAAkg+QsAAAAAAACQAJK/AAAAAAAAAAkg+QsAAAAAAACQAJK/AAAAAAAAAAnQJtsdIDfMnj07pk6dGgsXLoxNmzZFt27d4txzz41rrrkm+vbtm+3usZdUKhUffPBBlJaWpv8tWbIkKisrIyJi1qxZ0atXr/3Ws3Pnzpg6dWrMmDEj/v73v0dFRUUcc8wxUVxcHNdee2107dp1v3WsX78+fvWrX8Wf/vSnWLlyZbRt2zZOOumkGDJkSFx11VXRps3+d2FLliyJJ598Ml5//fUoKyuLI444IoqKiuKqq66Kiy++eP8DQtqOHTtizpw58Ze//CVKS0tjxYoVsW3btujYsWP06dMnBg0aFFdeeWV07Nix3nrERvKsWrUqXnrppXjnnXdiyZIlsW7duli/fn3k5eVFjx49on///vGVr3wlBg4cuN+6xEduWL9+fQwePDg2btwYERFDhw6Nn/zkJ3WWFxfJ9PHHH8cll1zSoLKvv/56nZ+z+ACSwry5fo2dj0ybNi3uuOOO/bbTp0+feO655+otk4njRkuWtGN0SzZo0KD45JNPGlz+u9/9btx4443pv8V1dc5pNa/Gjvf69etj1qxZ8cYbb8S7774bq1atisrKyujSpUsUFRXFkCFD4h//8R8jLy+vzjpuv/32ePbZZ/fb169+9avxox/9qN4ySR/vlra/SPJ4H8hxtMpTTz0Vn/vc56q9livx7Zxz02iVSqVSzdYaOWncuHExderUWte1bds27rrrrrjiiiuauVfUZX8Hp4Z8Ud6yZUuMHDky3n777VrXd+/ePSZPnhynnHJKnXUsWrQorr/++vj0009rXX/mmWfGlClTolOnTnXW8eyzz8bYsWPTB+V9DR8+PO6888663wjVnHXWWbF169Z6y/Ts2TMeeuih6NevX63rxUYy/ed//mfcdddd+y03bNiw+PGPf1znxE185I7bbrstZsyYkf67vuSvuEiuTJxYFh9AUpg3719j5yOZOumdieNGS5ekY3RLd6DJ30mTJsWXvvSl9N/iujrntJpXY8a7tLQ0hg8fHjt37qy3jbPOOit+/vOf15m0yVRyLOnjHdGy9hdJH+8DTf62adMm/vznP0e3bt2qvZ4r8e2ccxNJQRN69NFHU4WFhanCwsLUDTfckHrnnXdS69atS82ZMyf15S9/OVVYWJg69dRTU/Pmzct2V/n/VqxYkf7MLrzwwtR3vvOd1NVXX51+bcWKFfutY9SoUanCwsJU3759U/fff39q+fLlqTVr1qSeeeaZ1IABA1KFhYWpCy64ILVhw4Zat9+wYUPqggsuSBUWFqYGDhyYeuaZZ1Jr1qxJLV++PHX//fen+vbtmyosLEyNGjWqzj7Mmzcvdeqpp6YKCwtTX/7yl1Nz5sxJrVu3LvXOO++kbrjhhvT7efTRRw96rHJNYWFhqqioKHXzzTenZsyYkfrwww9TGzduTC1dujT1s5/9LD3eZ599dmr16tW11iE2kum3v/1tavTo0akpU6akXnvttdSyZctS69evT73//vupGTNmpC6//PL0uP70pz+tsx7xkRvmzJmTKiwsTF1yySXp8RwzZkyd5cVFcu39nePll19OlZeX1/mvLuIDSALz5oZp7HzkmWeeSY9zfceczz77rM4+ZOK4cShIyjH6ULBt27Z6x7e8vDw9nzr77LNTO3bsqLa9uK7OOa3m1ZjxfuONN1KFhYWpc845J3XXXXel/vznP6dWrlyZ2rBhQ2r+/Pmp7373u+l6rrzyytSuXbtqrWfMmDGpwsLC1PDhw+v9P7Dv/5295cJ4p1ItZ3+RC+O9e/fu/e7bV65cmSoqKkoVFhamRo8eXWs9uRLfzjk3Dclfmsy6detSZ555ZqqwsDB13XXXpXbv3l1t/fr161PnnXdeqrCwMDVs2LAs9ZJ9bdmyJfXHP/4xtXbt2vRrkyZNavAXiZdffjld9pFHHqmxfu7cuemdZV1JoPvuuy+9s547d26N9Y888ki6jT//+c+11vGVr3wlVVhYmDrvvPNS69evr7Zu9+7dqREjRqQKCwtTZ555ZmrdunX1vif2uPPOO6vFxb6mT5+e/lzGjRtXY73YyF07duxIXXHFFanCwsLUGWeckdq2bVuNMuIjN2zbti2d9N37M68r+Ssukm3vyfQbb7xxwNuLDyAJzJsbrrHzkb1Peh+sTBw3DgVJOUYnwbJly9Lv80c/+lGN9eK6Oue0mldjxnvhwoWpxx57LLV9+/Y6y/zrv/5ruq6ZM2fWWqYqOfa1r33toN9HLox3KtVy9he5Mt778+tf/1p8/3/OOTeN1s1zfTG56Nlnn41t27ZFRMT3v//9aNWqVbX1Xbp0iVGjRkVExNtvvx0LFy5s9j5SU8eOHaO4uDi6d+9+UNs//fTTEbHn8x05cmSN9QMHDowvfvGLERHxu9/9rsbtXXbu3Bm//e1vIyLii1/8Yq3PCB05cmR07ty5Wnt7+9vf/halpaURETFq1Kjo0qVLtfWtWrWKW2+9NSIitm3bFn/4wx8O5C3mrHHjxtUbF0OGDInCwsKIiHjllVdqrBcbuatt27Zx2WWXRUTEZ599Fu+//36NMuIjNzz00EOxYsWK+NKXvhQXXXTRfsuLC+ojPoAkMG9uuMbORxorE8eNXNESjtFJ8fvf/z69PHTo0IzXn7Sxdk6reTVmvE899dS47rrrol27dnWWueWWW6J16z3pizlz5hx0P+uTK+OdCeI7s6reW6dOnQ74+cANdaiMt3POTUPylyYze/bsiIg4/vjjo6ioqNYygwcPTi+/9NJLzdIvms727dvj9ddfj4iISy65JNq2bVtruarPfePGjTF//vxq6+bNmxebN2+uVm5fbdu2jeLi4oiIeO2112L79u3V1lfFXn11FBUVxfHHHx8RYi+T+vTpExERa9eurfa62KBNmzbp5X0/f/GRG95999148skno6CgIH74wx/ut7y4oD7iA0gK8+bMqms+kgmZOG7kgpZyjE6CVCoVM2bMiIiIE088Mc4888yMt2Gs/09LiV3fL/9P165d48gjj4yIptmvRxjvAyG+M2f58uXx1ltvRcSecajvRxCNkaTxds75wEn+0mSqfpF8xhln1FmmZ8+e0aNHj2rlOXS99957sWPHjoiIeicle6/b93Pf+++G1LFjx45YtmxZrXX06NEjevbsWWcdVbEp9jKnrKwsIqLGg+/FRm7bvXt3/M///E9ERBx++OFx4oknVlsvPpJv9+7dMXbs2Ni5c2fcfPPN6WN/fcRFbqqoqGhQOfEBJIV5c2bVNR+pS0OPOxGZOW4cyg61Y3QSvPHGG7Fq1aqIiLj88ssbvJ24PjgtJXZ9v/w/lZWVsWnTpojYcxVmQ+zatSt27drV4DZyfbybe3+R6+NdZe+7OhzI/j2X49s55wMn+UuTWLNmTfrWVccdd1y9ZXv16hUREX//+9+bvF80rb0/w6rPtTbHHHNM+rYt+37uVX+3bt06jjnmmDrr2Lv+uupoaOxt3bo11qxZU29Z9q+srCwWLFgQERH9+/evtk5s5J5UKhVlZWXx6quvxsiRI2Pu3LkREXHTTTfV+BWe+Ei+p556Kv72t79FUVFRfO1rX2vQNuIit9x1113Rv3//OP300+P000+PIUOGxH333RerV6+utbz4AJLAvDmz6puP7Gvo0KFx2mmnxemnnx79+/ePr371q/GrX/0q/XnUJhPHjUPRoXqMToKqW0K2atWqQckBcd04LSV2fb/8Py+//HI6Obm//frSpUvj0ksvjdNOOy2Kiori85//fHzrW9+KF198MVKpVJ3b5ep4Z2t/kavjvbdUKhXTp0+PiD3jUNsthveV6/HtnPPBkfylSWzYsCG9XHV7jrpUrd+4cWOT9omm19DPPT8/Pw4//PCIqPm5V9Vx+OGHR35+fp11dO3aNb1cVx0Njb3a6uDATZw4MSorKyMiYvjw4dXWiY3ccdNNN0Xfvn3jH/7hH+ILX/hCXHfddfHaa6/FkUceGT/+8Y/j61//eo1txEeyrVy5Mh588MFo3bp13HnnnZGXl9eg7cRFbnnvvffSJxoqKipi6dKl8dhjj8XgwYNj5syZNcqLDyAJzJszq775yL4WLVqULrtt27aYN29eTJgwIS677LJYvHhxrdtk4rhxKDpUj9GHus8++yx996Szzz47jj322P1uI64bp6XEru+Xe1RUVMT9998fEREFBQVx2WWX1Vt+48aN8dFHH8Xu3bsjlUrFhg0bYvbs2XHjjTfGyJEj01cQ7ytXxztb+4tcHe+9zZs3Lz7++OOIiLjiiisatE2ux7dzzgenzf6LwIHb+1dC+7tnfdX6rVu3NmmfaHqfffZZermhn/u+vyirqmN/27dv3z69XFcddd3jvyF1cGCmT58e06ZNi4iIQYMGxQUXXFBtvdjIbW3bto3hw4fHxRdfXOt68ZFs48ePj23btsXVV18d/fr1a/B24iL5WrduHeeff3780z/9UxQVFcXRRx8d7dq1i+XLl8fMmTPj8ccfj23btsUPfvCDOOKII+L8889Pbys+gCQwb86c/c1HIvbsi4cOHRrFxcVx8sknR8+ePWPXrl2xePHiePrpp2PmzJmxYsWKGDlyZEybNq3GYyoycdw4VCThGH2oe/HFF9Pvqb7kgLjOnJYSu75f7nHXXXfFBx98EBF7fmS+d9Jlb926dYtRo0bFBRdcEMcdd1x07949ysvLY8GCBfHv//7vUVpaGq+++mp85zvfiaeeeip95V+VXBrvlrC/yKXxrkvVLZ8bclcH8e2cc2NI/gLQKKWlpTF27NiIiDj66KPjnnvuyXKPyKaf/vSnMWHChEilUrFx48aYP39+PProo/Hwww/Hr3/963jkkUfirLPOynY3aSbPP/98zJ49O7p37x7f//73s90dWphjjjkmHnvssRqvFxYWRmFhYVx00UVx7bXXxo4dO+Kuu+6K559/vsFXjgOQOxo6HykpKYmSkpIarw8cODAGDhwY/fr1iwkTJkRZWVk88MADMWHChCbtd0vmGJ19VbcEPeyww+JLX/pSneXENUn0H//xH/Hb3/42IiIuvPDCuOaaa+ose9ttt9V4rWvXrlFcXBxf/OIX45ZbbokXX3wx5s6dG9OnT2/wlZZJZH+RfTt27Ejf1eGss87a7y2Ccz2+nXNuHLd9pkl06NAhvVz1wO26VK0vKCho0j7R9A477LD0ckM/971jZe869rf99u3b08t11VH1XJCDqYOG+eCDD+L666+P7du3R+fOnWPKlCm1/hpTbOSOdu3aRUFBQXTs2DF69eoVl19+eTzzzDNxxhlnxIYNG+KGG26IzZs3V9tGfCTT5s2b49/+7d8iIuL222+PTp06HdD24oKzzjorfav4Dz/8MEpLS9PrxAeQBObNjdfQ+UhDXHvttem7lLzwwgvp2wtWycRxIykOhWP0oWzt2rXx+uuvR0TEJZdcEh07djzousR1w7WU2M3175f//d//nZ5HnnbaafHAAw9Eq1atDqquNm3axPjx49NjOmPGjBplcn2899Yc+4tcH+9Zs2bFli1bIqLht3yuS9Lj2znnxpP8pUl06dIlvbxu3bp6y1at79y5c5P2iabX0M+9srIynfzZ93OvqmPz5s2xc+fOOutYv359ermuOhoae7XVwf6tXLkyrrvuutiwYUMUFBTE5MmTo3fv3rWWFRu5rX379nHrrbdGxJ5nYDz//PPV1ouPZHr44Yfj008/jS984Qvx5S9/+YC3FxdE7LmtU5VFixall8UHkATmzY1zIPORhqo67mzbti2WL19ebV0mjhtJ0tKP0Yey6dOnx65duyIiYujQoY2uT1w3TEuJ3Vz+fjlnzpz4wQ9+ELt3744+ffrElClTGv2jpy5dukT//v0jovq+au/1Ebk53rVp6v1Fro931S2f27VrF4MHD250fUmNb+ecM0PylyZx1FFHpX+5sGLFinrLVj3g/KSTTmryftG09v4Mqz7X2qxcuTJ2795dY5u9/969e3d88sknddaxd/111dHQ2CsoKKjxHAvqV1ZWFiNGjIhVq1ZF+/bt45e//GW9z/IUG5xxxhnp5SVLllRbJz6SqWqcXn311ejbt2+t/6o8++yz6df+9Kc/RYS4YI8jjzwyvVz1C+kI8QEkg3nzwTvQ+UhD7X3c2fduNZk4biRJSz9GH8r+8Ic/RMSefcR5553X6PrEdcO0lNjN1e+X8+bNixtvvDEqKyvj+OOPj8cff7xaUqcxqq4W3HtfVSVXx7suTb2/yOXxLisri1dffTUi9tzV4UDvjlaXpMW3c86ZI/lLk2jVqlUUFRVFRFS7/c++Vq9eHWvWrImISJfn0NWnT5/0g9HffvvtOsu99dZb6eV9P/e9/25IHe3atavxy5+qOtasWZOOr9pU1S/2DsymTZtixIgR8eGHH0Z+fn5MmjQpzjnnnHq3ERvs/cu5fW/ZJD6ojbggYs/Er8rek2PxASSBefPBOZj5SEN9+umn6eXDDz+82rpMHDeSpKUfow9VixYtiqVLl0ZExJAhQ6J168afuhXXDdNSYjcXv18uXLgwvvnNb8Znn30WPXr0iCeeeCKOOuqojNVftb+qLdmWi+Ndn6beX+TyeD/33HPpc2OZfDZvkuLbOefMkvylyVx88cUREbF8+fJ49913ay3zwgsvpJf3vmUQh6b27dvHueeeGxF7nmFQ1z3uqz73zp07x4ABA6qtGzhwYPrLxd7xsbeKiop46aWXIiLivPPOi/bt21dbXxV7EXueFVKbRYsWxUcffRQRYu9AbN26NUaNGhVLly6N1q1bx3333RcXXXTRfrcTG8ybNy+9fPzxx1dbJz6S6Y477ojf//739f6rcvHFF6df+9znPhcR4oI9/vjHP6aX954ciQ8gKcybD8zBzkcaatasWRGx52qME044odq6TBw3kqSlH6MPVVVX/UZkLjkgrhumpcRurn2/XLZsWYwcOTLKy8ujS5cu8cQTT0SvXr0yVv+6devif//3fyMi4tRTT62xPtfGe3+aen+Ry+NdtX/v1q1bnH/++RmpM0nx7Zxz5kn+0mSGDh2avoXVxIkTI5VKVVu/cePGmDJlSkTsuR1otn9ZQmZcffXVEbHnHvhPPPFEjfXz58+Pl19+OSIihg0bFm3atKm2vk2bNnHllVdGRMTs2bNj/vz5Nep44okn0vfYr2pvb6effnr6dhBTpkyJjRs3VlufSqVi4sSJEbHnweqXX375gbzFnFVRURHf/va301cljB8/PkpKShq8vdhIrvfff7/e9Zs2bYqf/exnERGRl5dX6xcc8ZE8xx13XJxyyin1/qvSuXPn9Gt7/1pVXCTb6tWr613/5ptvxtNPPx0RESeeeGKNWz2JDyAJzJsbrjHzkfLy8igvL6+3zKOPPhoLFy6MiIjBgwdHfn5+tfWZOG4cKpJwjD4U7dq1K5577rmI2JNQLywsrLe8uM68lhC7ufT98uOPP04/17NTp07x+OOPx8knn9zg7T/99NP087FrU1FRET/84Q9jx44dERFx2WWX1SiTK+PdUvYXuTLe+3rvvffSz+QdMmRI5OXl7XebXIpv55ybRt6dd955Z5O3Qk467LDDIi8vL1577bX46KOPYunSpXHSSSdFXl5eLFiwIG699dZYsWJFtGnTJiZOnBjHHHNMtrvM/7ds2bL46KOPYvXq1bF69er461//mj5AnXPOObFly5b0urZt28Zhhx2W3vbEE0+M0tLSWL58ebz55puxc+fOOPbYY6OioiJefPHFuP3222P79u3Ro0eP+OlPf1rrL0aLiopixowZUV5eHn/605+iW7du0a1bt1i/fn08/vjj8fOf/zxSqVRceOGFceONN9b6Hk4++eT4wx/+EOXl5fHKK6/ECSecEB07dowPP/wwxo8fH7Nnz46IiJtvvjljv7ZKsl27dsXNN98cc+bMiYiIm266KYYNGxaVlZV1/svPz692e1+xkVznn39+LFq0KCorKyMvLy9atWoVO3bsiI8++ihmzpwZY8aMieXLl0dExKhRo2Lw4ME16hAfuenhhx+OiIhTTjkliouLa6wXF8lWXFwcb7/9dlRUVEReXl60bt06tm/fHu+99148/vjjcffdd0dlZWW0adMmfvazn9X45bn4AJLAvLlhGjsfef/99+OKK66ITz75JHbv3p0+6bdly5ZYsGBB3HvvvfHrX/86IiK6d+8e999/f3Ts2LFGPzJx3DgUJOUYfaiZM2dO/Nd//VdERIwePTrOPPPMesuL69o5p9W8Dna8y8rK4utf/3qsXLky2rZtG5MmTYpTTjmlzn36rl27aiQjf/e738W//Mu/xIYNGyJiTwInlUpFWVlZvPzyy3HHHXek70L2uc99LsaMGVPjMVQRuTHeLWl/kQvjva/HHnssfYXuj3/84+jWrdt+286V+HbOuem0Su37s1LIsHHjxsXUqVNrXZefnx933313Ru9zT+N9/etfj7/+9a8NKjthwoT453/+52qvbd68OUaNGlXnPfK7d+8ekydPrnbV174WLVoU119/fbVnTeztzDPPjClTptT6PIMqzz77bIwdOzYqKytrXX/VVVfFj3/84zq35/98/PHHcckllxzQNrNmzapxqx6xkUx9+/bdb5m8vLwYNWpU3HLLLbV+GY0QH7moKnaGDh0aP/nJT2otIy6Sa+DAgbFly5Z6yxxxxBFxzz33xKWXXlrrevEBJIV5c/0aOx959913GzR+vXv3jgcffLDeZ5pm4rjR0iXpGH0oueWWW+L555+PNm3axJw5c6Jr1671lhfXtXNOq3kd7HhPmzYt7rjjjga3c+yxx6ZvuVrlV7/6VUyYMGG/215yySVx77335vR4t7T9RdLHe2+7d++Oiy66KNauXRt9+/aN6dOnN6i+XIlv55ybjit/aXIXX3xxnHbaabFly5bYunVrVFZWRs+ePePSSy+NCRMmZP0XPNT07LPPxieffNKgssXFxTV2mu3atYuhQ4fGkUceGZs2bYrPPvssWrduHSeccEIMGzYs7rvvvhrP/NxX9+7d44orroi8vLzYuHFjbN++PTp06BCnnHJKjB49OsaNG1fnr6mqnHLKKXHJJZfEjh07YtOmTbF9+/bo2rVrnH322XHHHXfEiBEjGvQe2XMAfeqppw5om2uuuSb9vIQqYiOZzj333Dj22GPTVwXs3LkzIvacEDrllFPisssui7vvvjtKSkrqTPxGiI9ctL8rfyPERZKddNJJcdRRR0WrVq2idevW6Vtade3aNfr16xdXXXVVTJgwod5bnIoPICnMm+vX2PlIhw4d4rjjjksn01q1apW+cuSoo46Kz3/+8/HNb34zxo4dG927d6+33kwcN1q6JB2jDxXl5eUxduzY2LlzZ1x00UUxbNiw/W4jrmvnnFbzOtjxfvfdd9PPl22Iww8/PK655ppqr3Xv3j2OPvroKCgoiIj/+z9w2GGHxXHHHRcXX3xx3H777fHNb34z2rVrV2/9SR/vlra/SPp47+21115LPyph1KhR0b9//wbVlyvx7Zxz03HlLwAAAAAAAEACtM52BwAAAAAAAABoPMlfAAAAAAAAgASQ/AUAAAAAAABIAMlfAAAAAAAAgASQ/AUAAAAAAABIAMlfAAAAAAAAgASQ/AUAAAAAAABIAMlfAAAAAAAAgASQ/AUAAAAAAABIAMlfAAAAAAAAgASQ/AUAAAAAAABIAMlfAAAAAAAAgASQ/AUAAAAAAABIAMlfAAAAAAAAgASQ/AUAAAAAAABIAMlfAAAAAAAAgASQ/AUAAAAAAABIAMlfAAAAAAAAgASQ/AUAAAAAAABIgP8H75PDfWc7tSYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1152x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 959,
              "height": 597
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf55a387"
      },
      "source": [
        "N_EPOCHS = 2\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "data_module = FinancialSummaryDataModule(train_df, val_df, test_df, tokenizer, batch_size=BATCH_SIZE)"
      ],
      "id": "cf55a387",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45ae438e"
      },
      "source": [
        "#### 모델 "
      ],
      "id": "45ae438e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c7b5ec2"
      },
      "source": [
        "class FinancialSummaryModel(pl.LightningModule):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-bigpatent\", return_dict=True)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, decoder_attention_mask, labels=None):\n",
        "\n",
        "    output = self.model(\n",
        "      input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      labels=labels,\n",
        "      decoder_attention_mask=decoder_attention_mask\n",
        "    )\n",
        "\n",
        "    return output.loss, output.logits\n",
        "\n",
        "  def training_step(self, batch, betch_idx_):\n",
        "    input_ids = batch[\"text_input_ids\"]\n",
        "    attention_mask = batch[\"text_attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "    loss, outputs = self(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      decoder_attention_mask=labels_attention_mask,\n",
        "      labels=labels\n",
        "    )\n",
        "\n",
        "    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, betch_idx_):\n",
        "    input_ids = batch[\"text_input_ids\"]\n",
        "    attention_mask = batch[\"text_attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "    loss, outputs = self(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      decoder_attention_mask=labels_attention_mask,\n",
        "      labels=labels\n",
        "    )\n",
        "\n",
        "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def test_step(self, batch, betch_idx_):\n",
        "    input_ids = batch[\"text_input_ids\"]\n",
        "    attention_mask = batch[\"text_attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "    loss, outputs = self(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      decoder_attention_mask=labels_attention_mask,\n",
        "      labels=labels\n",
        "    )\n",
        "\n",
        "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return AdamW(self.parameters(), lr=0.0001)"
      ],
      "id": "8c7b5ec2",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efbcb950"
      },
      "source": [
        "model = FinancialSummaryModel()"
      ],
      "id": "efbcb950",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25dde85b",
        "outputId": "6a026b38-93c7-4d55-cac1-39a59d2a2d9d"
      },
      "source": [
        "dirpath = \"/content/drive/MyDrive/Colab Notebooks/Aiffel_Hackathon/BigBird\"\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=dirpath,\n",
        "    filename='{epoch}-{val_loss:.2f}-{other_metric:.2f}',\n",
        "    save_top_k=1,\n",
        "    verbose=True,\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\"\n",
        ")\n",
        "\n",
        "logger = TensorBoardLogger(\"lightning_logs\", name=\"financial-summary\")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    logger=logger,\n",
        "    callbacks=[checkpoint_callback], \n",
        "    max_epochs=N_EPOCHS,\n",
        "    gpus=-1,\n",
        "    auto_select_gpus=True,\n",
        "    progress_bar_refresh_rate=30\n",
        ")"
      ],
      "id": "25dde85b",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=30)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
            "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-9C3qbfD9wl",
        "outputId": "ebc2d05f-375f-449a-a329-28f8ba308ac6"
      },
      "source": [
        "gc.collect()"
      ],
      "id": "8-9C3qbfD9wl",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "499"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989,
          "referenced_widgets": [
            "900741d70a064519a5fa583c7bde49d5",
            "0fc508ab15a14f26a3c078de0b8fd2f4",
            "367040265e5e45649ace96766933e8f7",
            "6b02e5a3f71246abaf006c7a659af99f",
            "e18195e7075e4e12a4ec4ec044d0eba9",
            "869029232476464a97be7b1783c022f4",
            "d199c7371ffd4c5488fd6afe7279d9ea",
            "04e0aa90c8db41229a7b55915de2f558",
            "38378ae989484203b1ebce2dc7f22353",
            "696952ce36714c3381abcd157230fdf0",
            "1d05e0eb9e944ce9b1e767d026ff05a2",
            "8354c8f4a408403f8d4fef23dd6271b6",
            "8303c6fd6ff3496d889983a88acd2e43",
            "92d7400aa453479da772b93f876fdf53",
            "e032b02c31ae473dad9e70250744fb22",
            "5f62ec10e00d4bc6b337b4c06dead7f6",
            "d19121155a2e429095c887cc1a2e72d0",
            "d23dd575dc084601856ec7256617d9c9",
            "afda38ab60cd414ab173fd36e0769102",
            "2cc1d2cdb1ee415eab5a0468e045396a",
            "e135db516ab447febd2353f5451629bb",
            "74b31331bf3e4b2480c53fe4f87933e0"
          ]
        },
        "id": "5d0b0600",
        "outputId": "35b78c36-5f9e-4dc0-bfd7-1d024fba0825"
      },
      "source": [
        "trainer.fit(model, data_module)"
      ],
      "id": "5d0b0600",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=e7e6030ab5d2e5bc524cad800486fa80dd953782b889e8be6292b6c84b1ebc73\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:470: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type                                   | Params\n",
            "-----------------------------------------------------------------\n",
            "0 | model | BigBirdPegasusForConditionalGeneration | 576 M \n",
            "-----------------------------------------------------------------\n",
            "576 M     Trainable params\n",
            "0         Non-trainable params\n",
            "576 M     Total params\n",
            "2,307.568 Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /content/drive/.shortcut-targets-by-id/1w4WyhAQ16CIFKNbtXntCgKMZoYxIpzws/Aiffel_Hackathon/BigBird exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "900741d70a064519a5fa583c7bde49d5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:111: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:792: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  * num_indices_to_pick_from\n",
            "Global seed set to 42\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:111: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8354c8f4a408403f8d4fef23dd6271b6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-9d0bcc1dbb9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install GPUtil'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPUtil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mtrain_dataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m         self._call_and_handle_interrupt(\n\u001b[0;32m--> 738\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m         )\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \"\"\"\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m         \u001b[0;31m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;31m# TODO: ckpt_path only in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt_path\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1312\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_EVALUATE_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;31m# the global step is manually decreased here due to backwards compatibility with existing loggers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0moptimizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_active_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_frequencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, batch, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_position\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         )\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_run_optimization\u001b[0;34m(self, split_batch, batch_idx, optimizer, opt_idx)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# gradient update with accumulated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsume_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mon_tpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDeviceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_TPU_AVAILABLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0musing_native_amp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp_backend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp_backend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mAMPType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNATIVE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0musing_lbfgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_lbfgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         )\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m         \"\"\"\n\u001b[0;32m-> 1664\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiler_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \"\"\"\n\u001b[1;32m    335\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, model, optimizer, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mclosure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_track_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/precision/precision_plugin.py\u001b[0m in \u001b[0;36m_wrap_closure\u001b[0;34m(self, model, optimizer, optimizer_idx, closure)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mconsistent\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mPrecisionPlugin\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0msubclasses\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdirectly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \"\"\"\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mclosure_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclosure_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mClosureResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step_and_backward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\u001b[0m in \u001b[0;36m_training_step\u001b[0;34m(self, split_batch, batch_idx, opt_idx)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, step_kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \"\"\"\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-b6aa5da2567e>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, betch_idx_)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-b6aa5da2567e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_attention_mask, labels)\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2525\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m         )\n\u001b[1;32m   2529\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2388\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2389\u001b[0m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2390\u001b[0;31m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2391\u001b[0m             )\n\u001b[1;32m   2392\u001b[0m         \u001b[0;31m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1933\u001b[0m                         \u001b[0mfrom_blocked_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocked_encoder_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m                         \u001b[0mto_blocked_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocked_encoder_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1935\u001b[0;31m                         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1936\u001b[0m                     )\n\u001b[1;32m   1937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, band_mask, from_mask, to_mask, from_blocked_mask, to_blocked_mask, output_attentions)\u001b[0m\n\u001b[1;32m   1385\u001b[0m             \u001b[0mto_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m             \u001b[0mfrom_blocked_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_blocked_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m             \u001b[0mto_blocked_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_blocked_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1388\u001b[0m         )\n\u001b[1;32m   1389\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, past_key_value, output_attentions, band_mask, from_mask, to_mask, from_blocked_mask, to_blocked_mask)\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             self_outputs = self.self(\n\u001b[0;32m-> 1191\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_blocked_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_blocked_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m             )\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, band_mask, from_mask, to_mask, from_blocked_mask, to_blocked_mask, output_attentions)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 15.90 GiB total capacity; 14.46 GiB already allocated; 39.75 MiB free; 14.76 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    }
  ]
}