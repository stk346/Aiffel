{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BigBird_RoBERTa.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq6kBZSAYNUz",
        "outputId": "d6fe40ef-c435-4795-9fa5-fb1fad67e1c8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJUwXP8Y1Aij",
        "outputId": "e577b211-88b9-4dda-b2a8-8dcd12db6fe0"
      },
      "source": [
        "# colab pro 더 빠른 GPU 사용\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 24 10:09:37 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyJrPm_8PqX-",
        "outputId": "5189555a-ed67-4ea5-b750-d2f881ac191d"
      },
      "source": [
        "! pip install transformers\n",
        "! pip install torchmetrics\n",
        "! pip install torchtext"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.6)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.10.0+cu111)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchtext) (3.10.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMA96V8qP0ge",
        "outputId": "7aaa9771-12c3-419e-c9a2-f9c20b03bc73"
      },
      "source": [
        "! pip install Datasets"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Datasets in /usr/local/lib/python3.7/dist-packages (1.15.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from Datasets) (0.1.2)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from Datasets) (2021.11.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from Datasets) (3.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from Datasets) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from Datasets) (4.62.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from Datasets) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from Datasets) (3.8.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from Datasets) (4.8.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from Datasets) (0.70.12.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from Datasets) (2.0.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from Datasets) (1.19.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from Datasets) (0.3.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from Datasets) (1.1.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->Datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->Datasets) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->Datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->Datasets) (3.0.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->Datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->Datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->Datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->Datasets) (3.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->Datasets) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->Datasets) (1.7.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->Datasets) (0.13.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->Datasets) (5.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->Datasets) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->Datasets) (2.0.7)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->Datasets) (4.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->Datasets) (21.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->Datasets) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->Datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->Datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->Datasets) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNHrTUaMUZvL",
        "outputId": "204af63d-0bc8-404a-f0e3-25b766cbdf38"
      },
      "source": [
        "! pip install sentencepiece"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeL4xe0ZVYUb",
        "outputId": "af493d5a-a268-4aba-a906-4d47b54284ad"
      },
      "source": [
        "# BirBird requirements 설치\n",
        "! git clone https://github.com/google-research/bigbird.git\n",
        "! cd bigbird\n",
        "! pip3 install -e .\n",
        "! mkdir -p bigbird/ckpt\n",
        "# ! gsutil cp -r gs://bigbird-transformer/ bigbird/ckpt/"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'bigbird' already exists and is not an empty directory.\n",
            "\u001b[31mERROR: File \"setup.py\" or \"setup.cfg\" not found. Directory cannot be installed in editable mode: /content\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QwOxWjRYOHX",
        "outputId": "c4578e3a-6604-4c88-c323-58dc7df47d02"
      },
      "source": [
        "# colab pro 추가 메모리\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VxJfyNm19UI"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import (\n",
        "    BigBirdModel,\n",
        "    BigBirdTokenizer,\n",
        "    BigBirdForPreTraining,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from datasets import Dataset\n",
        "from datasets import load_metric"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFlMYYOkPg3F"
      },
      "source": [
        "train_path = '/content/drive/MyDrive/Colab Notebooks/Aiffel_Hackathon/Data/Training_Data_Clean.csv'\n",
        "test_path = '/content/drive/MyDrive/Colab Notebooks/Aiffel_Hackathon/Data/Test_Data_Clean.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path, encoding=\"latin-1\") # 데이터를 더 잘 읽어올 수 있도록 인코딩 지정\n",
        "test_df = pd.read_csv(test_path, encoding=\"latin-1\")"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "3WrDlA7FQos7",
        "outputId": "602a697a-dc43-42d9-8bc0-14cff60f3f7f"
      },
      "source": [
        "train_data = train_data.rename(columns={'Full_Text': 'text', \"Summary_Text\": \"summary\" })\n",
        "train_data = train_data.drop('Unnamed: 0', axis=1)\n",
        "train_data.head()"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Original_Filename_x</th>\n",
              "      <th>Gold_Filename</th>\n",
              "      <th>Document</th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15786_819157_2</td>\n",
              "      <td>15786_819156_1</td>\n",
              "      <td>15786</td>\n",
              "      <td>6 chief executive officerâs review the bero...</td>\n",
              "      <td>3 chairmanâs statement in the 18 months sin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15783_819108_2</td>\n",
              "      <td>15783_819107_1</td>\n",
              "      <td>15783</td>\n",
              "      <td>chief executive officerâs statement the ber...</td>\n",
              "      <td>chairman s statement it has always been your ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15782_819091_2</td>\n",
              "      <td>15782_819090_1</td>\n",
              "      <td>15782</td>\n",
              "      <td>chief executive officerâs statement the com...</td>\n",
              "      <td>chairmanâs statement the celestial ipilan o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15787_819176_2</td>\n",
              "      <td>15787_819175_1</td>\n",
              "      <td>15787</td>\n",
              "      <td>page 6 toledo mining corporation plc annual r...</td>\n",
              "      <td>page 5 i should like to begin my message with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15816_820156_2</td>\n",
              "      <td>15816_820155_1</td>\n",
              "      <td>15816</td>\n",
              "      <td>3 chief executiveâs statement tomkins plc r...</td>\n",
              "      <td>2 tomkins plc report accounts 2003 chairmanâ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Original_Filename_x  ...                                            summary\n",
              "0      15786_819157_2  ...   3 chairmanâs statement in the 18 months sin...\n",
              "1      15783_819108_2  ...   chairman s statement it has always been your ...\n",
              "2      15782_819091_2  ...   chairmanâs statement the celestial ipilan o...\n",
              "3      15787_819176_2  ...   page 5 i should like to begin my message with...\n",
              "4      15816_820156_2  ...   2 tomkins plc report accounts 2003 chairmanâ...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZWlXu0qRv59",
        "outputId": "4f799762-8375-417b-966c-553660c9a2de"
      },
      "source": [
        "train_df, val_df = train_test_split(train_data, test_size=0.1)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2167, 5), (241, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "cM4KflImQ6ok",
        "outputId": "58e7a1a4-6b28-47a2-9638-d3d7a78e6a45"
      },
      "source": [
        "test_df = test_df[[\"Full_Text\", \"Summary_Text\"]]\n",
        "test_df = test_df.rename(columns={'Full_Text': 'text', \"Summary_Text\": \"summary\" })\n",
        "test_df.head()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25695 19 march 2018 3 29 pm proof 7 02 s . c ...</td>\n",
              "      <td>25695 19 march 2018 3 29 pm proof 7 a . c . q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10 staffline group plc annual report 2017 chi...</td>\n",
              "      <td>6 staffline group plc annual report 2017 a ye...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>results corero revenue for the year ended 31 ...</td>\n",
              "      <td>corero network security plc annual report acc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>strategic report chief executiveâs statemen...</td>\n",
              "      <td>summary fy17 was a landmark year in alphaâs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017 has been a year of significant change fo...</td>\n",
              "      <td>sir richard lapthorne chairman 2017 has been ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                                            summary\n",
              "0   25695 19 march 2018 3 29 pm proof 7 02 s . c ...   25695 19 march 2018 3 29 pm proof 7 a . c . q...\n",
              "1   10 staffline group plc annual report 2017 chi...   6 staffline group plc annual report 2017 a ye...\n",
              "2   results corero revenue for the year ended 31 ...   corero network security plc annual report acc...\n",
              "3   strategic report chief executiveâs statemen...   summary fy17 was a landmark year in alphaâs...\n",
              "4   2017 has been a year of significant change fo...   sir richard lapthorne chairman 2017 has been ..."
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Niexb_8ARcLy",
        "outputId": "b26fa04c-d224-4a8e-db04-caf80383ca4b"
      },
      "source": [
        "print(train_df.shape), print(val_df.shape), print(test_df.shape)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2167, 5)\n",
            "(241, 5)\n",
            "(280, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhO7MgosS32k"
      },
      "source": [
        "# 모델\n",
        "model = BigBirdForPreTraining.from_pretrained('google/bigbird-roberta-base')"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "MGwTRMGCSJW8",
        "outputId": "f75b97c4-5682-4e44-cc98-f06bf7070a63"
      },
      "source": [
        "test_sen = train_df['text'][0]\n",
        "test_sen"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' 6 chief executive officerâ\\x80\\x99s review the berong nickel mine , in which toledo has a 56.1 percent economic interest , successfully recommenced operations in may 2011.this became possible due to favourable market conditions for high grade saprolite nickel ores and strong nickel prices which have stayed above usdollar 20,000 tonne since august 2010. prior to reopening the berong mine , toledo developed a new strategy with its jv partners in berong nickel corporation bnc to target production of nickel ore containing 1.8 percent nickel , which is currently being implemented . the 1.8 percent plan was developed consistent with growing market demands for this ore type . the recent significant changes in market demand for high grade saprolite nickel ore have opened up sound prospects for our deposits . historically , the development of exports of high grade saprolite nickel ore began from new caledonia during the 1950 s by japanese ferronickel producers . later , they extended their ore source market to indonesia and the philippines . the requirement for nickel content in the ore in 2001 was very high at 2.45 percent , which is why only a few nickel ore producers in the philippines could compete in this market . from 2003, the european manufacturers of ferronickel also started using high grade saprolite ore from asia in their electric arc furnace eaf production , thereby competing with japanese consumers . by the end of 2006, the typical nickel content of high grade saprolite ores exported from new caledonia , indonesia and the philippines had fallen to 2.2 percent nickel due to a general decline in the grade of existing deposits and also due to the increased demand for ore . the most significant changes in the market began in 2006, when china began to use nickel ore for the production of nickel pig iron npi in blast furnaces , which were previously used for iron production . as the technology for production of pig iron in blast furnaces requires high iron content in raw materials , the chinese manufacturers mainly used limonitic nickel ores with high iron content 45- 55 percent and low nickel content 0.9-1 percent . the proportion of high grade saprolitic ore in the blast furnaces production of npi was relatively small . at the time of the crash in nickel prices at the end of 2008, china did not yet have substantial numbers of eaf plants for ferronickel production , and had not yet created competition in the market for high grade ores . however , it rapidly became clear to the chinese ferronickel and npi producers that the use of eaf for ferronickel production using high grade ores was much more competitive compared to npi production in blast furnaces . by early 2011, china had already built significant numbers of eaf plants for the production of ferronickel . this dramatically increased the demand for high grade saprolitic ore , resulting in a decrease in the average available grade from 2.2 percent to 1.8 percent nickel content . all of this has led to the berong deposit , with its substantial reserves of 1.8 percent nickel ore grade , becoming very competitive against the previous market leaders in high grade ore production from new caledonia , indonesia and the philippines . the restart of the berong mine by bnc was facilitated by the sale of the existing stockpile of low grade ore , produced in 2008, the proceeds of which are being used as working capital to support mining operations . currently , 103,530 wet metric tonnes wmt of nickel ore with an average grade of 1.54 percent nickel has been shipped from the existing stockpile , yielding a revenue of usdollar 2.57 million to bnc . to date , a further 160,569 wmt of ore with a nickel content of 1.8 percent has been mined and delivered to the stockpile . we anticipate producing a total of 450,000 wmt of ore containing 1.8 percent nickel by the end of this year , from which we expect to ship 200,000-250,000 wmt in this shipping season . because berong uses barges to load ships offshore , sea conditions typically limit shipments to between march and october . it is planned that shipments will be resumed at the beginning of march 2012, when sea conditions again become conducive to barge ship loading . we have revised our projected shipping target for bnc , as announced on 27 may 2011, downwards by 50,000 tonnes . the berong mine is targeting production of 750,000 wmt of 1.8 percent nickel ore during 2012. to address the constraints of the limited shipping window , bnc has recently engaged an engineering 7 company to look into the possibility of increasing the shipping period , the successful outcome of which would increase the capacity of the berong port to 1,000,000 wmt per year . among the range of possible measures being considered in the engineering study are the extension of the pier to accommodate bigger barges and the construction of a protective sea wall . the jorc-compliant resource for berong was prepared by snowden mining industry consultants in june 2007. the total resource over the area drilled was stated at 9.92 million dry tonnes averaging 1.55 percent ni at a 1 percent cut-off grade . this resource included a subset of high grade resource of 4.88 million dry tonnes grading 1.88 percent ni at a 1.5 percent cut-off grade . currently , following the 2006 to 2008 direct shipping ore operation , the balance of this high grade resource is approximately 4.68 million dry tonnes equivalent to approximately 6.98 million wet tonnes of ore which will support a 9-year life of mine at the present rate of production of 750,000 wmt of 1.8 percent nickel grade per annum . for every tonne of high-grade ore produced , approximately two tonnes of low grade ore with nickel content averaging 1.3 percent will be produced alongside . this will be stored at the mine site area in anticipation of future value added processing operations or for sale should favourable market conditions prevail . a mining project feasibility study for ipilan , in which toledo holds a 52 percent economic interest , was carried out in august 2010 and the relevant documents were compiled and submitted to the mines and geosciences bureau for review and approval in november 2010. these included a declaration of project mining feasibility dmf , environmental protection and enhancement program , final mine rehabilitation and decommissioning plan , social development and management plan and a health and safety plan . clearance of the all-important strategic environmental plan sep has been received from the palawan council for sustainable development pcsd . a comprehensive sintering test has been undertaken on ipilanâ\\x80\\x99s ore , which has highlighted an opportunity to upgrade the ore , especially its limonitic part . this study has opened up the possibility of upgrading the iron and nickel content of ipilanâ\\x80\\x99s limonitic ore to make it more suitable for npi blast furnace production . as berongâ\\x80\\x99s ore is similar to ipilanâ\\x80\\x99s , the results of the study could also be extended to berongâ\\x80\\x99s low grade limonitic ore . capital and operating costs of the process are being evaluated . mine experience gained in the development and operation of berong will be applied to ipilan once full permitting for mine development has been secured . past works have confirmed the possibility of using all the available leaching technologies such as high pressure acid leaching hpal , atmospheric leaching al and heap leaching hl for processing the ores of our deposits . we continue to assess the viability of these technologies in line with changing market conditions . we are also expanding our study on pyro-metallurgical technologies , such as looking into regional eaf production of ferronickel to evaluate which is the most viable and sustainable value added process for our ore . berong continues to set the benchmark in best practice for its environmental work within the community . the mine rehabilitation area is now home to 4.5 hectares of rubber trees , which should provide the community with a sustainable source of income for years to come . alongside this , toledo is dedicated to preserving its relationships with the local government units lgus and schools in support of the national greening project to deliver our commitment to plant 50 new trees for every one tree cut . in this regard , numerous species of value added trees , fruit trees and grasses continue to be planted . funds from royalty payments made to the indigenous peoples continue to provide essential services to the community as well as establishing livelihood projects , which aim to empower the local community in generating its own income . we are consistently investing more time and money into corporate social responsibility csr projects than is our obligation , as mandated by law , and continue to strive to contribute positively to the local environment and communities amongst which we operate . 8 finally , it would not have been possible to resume operations at berong at such short notice , or indeed at all , without the continued support and hard work of all of our stakeholders including the local community , the lgus , the provincial and national government and of course our staff and management both locally in the philippines and in the uk . i would like to take this opportunity to congratulate them all and look ahead to continued success in the months and years to come . victor kolesnikov chief executive officer 24 august 2011 competent person statement the resource information in this statement is based on information reviewed by mr pierre charlent , chief operating officer of toledo mining corporation , who is a member of the australasian institute of mining metallurgy . mr charlent has sufficient experience , which is relevant to the style of mineralisation and type of deposit under consideration and to the activities undertaken , to qualify as a competent person as defined in the 2004 edition of the australasian code for reporting of exploration results , mineral resources and ore reserves the jorc code . mr charlent consents to the inclusion in this statement of the matters based on this information , in the form and context in which they appear . 9 in the community toledo is very mindful of its duty to manage the environmental and social impact of its mining operations in a responsible and sensitive manner . all businesses are part of the wider society , and we believe they have both the responsibility and the capability to make a positive contribution to the communities in which they operate . berong nickel corporation bnc recognises that the efficient operation of its business depends on the support of the local authorities and of the community as a whole , and seeks to provide significant and sustainable benefits through its presence . bncâ\\x80\\x99s community relations officer , joy asignacion , ensures that everyone within the local community has a say in identifying and participating in projects backed by the company . there are currently two main focus areas for these projects the social development and management programme and community programmes . bncâ\\x80\\x99s social development and management programme sdmp was launched in 2007, following extensive consultation with the community and local government to ensure that the programme would be fully aligned with their interests and aspirations . since then , the sdmp has funded a number of very successful initiatives , including a scholarship scheme , a para-teachers programme , improved medical services , and a potable water system . the community programmes are wide ranging , and are selected and run with the active involvement of members of the community . recent programmes include livelihood backyard gardening scheme tilapia festival manufacture of coco-based products buying station for recyclable materials . education read-along scheme berong elementary extension school science month celebration at berong national high school . health cooking contest supplemental feeding personal hygiene demonstration community garden and beautification dumi mo , linis mo construction of comfort rooms new mothersâ\\x80\\x99 classes school garden . adopt-a-mountain bnc devised its adopt-a-mountain programme as a proactive and imaginative response to a directive issued by the environmental management bureau of the philippine department of environment and natural resources denr relating to the rehabilitation by mining operators of denuded forests or mountains outside of currently approved mining areas . along with restoration and conservation , the programme also aims to provide livelihoods to local people by planting tree species that can generate sustainable income in the future . the barangay district of berong is home to indigenous peoples called tagbanua and migrants from the visayan islands . the tagbanua are the aborigines of quezon and have inhabited the land for centuries . slash and burn farming known locally as kaingin and fishing are the main sources of livelihood of the nomadic tagbanua , and this has had a detrimental effect on the environment within the district . bncâ\\x80\\x99s community relations team faced a real challenge in finding denuded areas to adopt , since most of them are still being used as kaingin by the tagbanua who understandably do not want to leave unless they can sell the land at a very high price to bnc . however , following a series of negotiations conducted with the helpful guidance of the denr , the first tree planting event under the adopt-a-mountain programme was able to take place on 11 september 2010. hundreds of people from the community , including schoolchildren along with their teachers and mothers , government officials and local civic groups , converged and planted around 6,000 seedlings . 10 the adopt-a-mountain initiative is not only helping to rehabilitate the local environment , but also to promote better understanding and relationships throughout the community . bnc will continue to fund and extend this initiative , and the barangay of berong has declared that 11 september will from now on be designated adopt-a-mountain day . '"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJtwDA7a77NN",
        "outputId": "1ae55ade-179a-4bc9-cbb3-ac47278122cc"
      },
      "source": [
        "# 토크나이저\n",
        "\n",
        "# Import generic wrappers\n",
        "from transformers import AutoModel, AutoTokenizer \n",
        "\n",
        "\n",
        "# Define the model repo\n",
        "model_name = \"google/bigbird-roberta-base\" \n",
        "\n",
        "\n",
        "# Download pytorch model\n",
        "tokenizing_model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWj9Lhv077Ph",
        "outputId": "33077260-da93-43b4-9ea7-52c78514e053"
      },
      "source": [
        "# Transform input tokens \n",
        "inputs = tokenizer(test_sen, return_tensors=\"pt\")\n",
        "\n",
        "# Model apply\n",
        "outputs = model(**inputs)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/big_bird/modeling_big_bird.py:978: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  * num_indices_to_pick_from\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STkgrJopG405"
      },
      "source": [
        "bigbird 기법는 tokenizer 구현이 안돼있었던 것 같다. 따라서 AutoTokenizer를 이용해 pretrain된 tokenizer와 모델을 불러왔다. setup.py 또한 코랩에서 설치가 안되는 것 같은데 해결책을 찾아봐야겠다."
      ]
    }
  ]
}