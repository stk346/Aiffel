{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "basic-defense",
   "metadata": {},
   "source": [
    "지난 시간 우리는 transformer 기반의 pretrained model의 발전사를 살펴보고, 어떻게 이 모델들이 맥락 기반의 word representation을 구성할 수 있으며 또한 Transfer learning을 통해 다양한 자연어 처리 문제를 쉽게 해결할 수 있는지 살펴보았습니다.  \n",
    "  \n",
    "이런 모델들을 만들어 내기 위해서는 아주 큰 사이즈의 모델이 필요합니다. 가장 대표적인 BERT만 하더라도 정식 모델은 340M나 되는 파라미터 사이즈를 자랑합니다. 이들을 수십 GB나 되는 코퍼스를 토대로 학습시키는 것은 최고 성능의 GPU를 가지고도 수일 내지 수 주일의 시간이 걸립니다. 아마도 여러분 대부분의 학습환경에서 이를 수행하는 것은 가능한 일이 아닐 것입니다.  \n",
    "  \n",
    "그래서 오늘은 일반적인 10M 정도의 작은 파라미터 사이즈의 BERT 모델을 만들어, 수백 MB 수준의 코퍼스 기반으로 pretrain 을 진행해 보도록 하겠습니다. 하지만 진행되는 과정은 정식 BERT와 동일할 테니 이를 토대로 pretrained model이 어떻게 만들어지는지를 경험해 보도록 합시다. 모델을 만들고 학습시키는 것 이상으로 코퍼스 데이터를 가공해서 학습시켜야 할 task에 적합한 형태의 데이터셋으로 만들어가는 것이 큰 비중을 차지한다는 것을 알게 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-steal",
   "metadata": {},
   "source": [
    "## Tokenizer 준비\n",
    "BERT등의 pretrained model이 나오게 되었을 즈음 자연어처리 분야의 또 다른 중요한 흐름 중 하나는 BPE 등의 subword 기반의 토크나이징 기법이 주요한 방법론으로 굳어졌다는 점입니다. GPT의 BPE, BERT의 WordPiece 모델 등의 성공이 더욱 사람들에게 subword 기반의 토크나이저에 대한 확신을 주었습니다.  \n",
    "  \n",
    "오늘 우리는 SentencePiece 기반의 토크나이저를 준비하는 것으로 BERT pretrain 과정을 시작할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "specified-origin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import collections\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sentencepiece as spm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# tf version 및 gpu 확인\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-judge",
   "metadata": {},
   "source": [
    "준비해 둔 한글 나무위키 코퍼스로부터 32000의 vocab_size를 갖는 sentencepiece 모델을 생성해 보겠습니다. BERT에 사용되는 [MASK], [SEP], [CLS] 등의 주요 특수문자가 vocab에 포함되어야 함에 주의해 주세요. (시간이 오래 걸리니 파일을 내려 받아 사용하겠습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cloudy-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "prefix = 'ko_32000'\n",
    "vocab_size = 32000\n",
    "\n",
    "# spm.SentencePieceTrainer.train(\n",
    "#     f\"--input={corpus_file} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \n",
    "#     \" --model_type=bpe\" +\n",
    "#     \" --max_sentence_length=999999\" + # 문장 최대 길이\n",
    "#     \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
    "#     \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
    "#     \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
    "#     \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
    "#     \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰\n",
    "\n",
    "# print(\"완료=3\")   # 완료메시지가 출력될 때까지 아무 출력내용이 없더라도 기다려 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "engaged-smooth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/bert_pretrain/data'\n",
    "model_dir = os.getenv('HOME')+'/aiffel/bert_pretrain/models'\n",
    "\n",
    "# vocab loading\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(f\"{model_dir}/ko_32000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bridal-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ln -s ~/data/ko_32000.model ~/aiffel/bert_pretrain/models/ko_32000.model\n",
    "# ln -s ~/data/ko_32000.vocab ~/aiffel/bert_pretrain/models/ko_32000.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-market",
   "metadata": {},
   "source": [
    "어떤 토큰이 만들어졌는지, 토크나이징 결과가 어떻게 나오는지 살펴볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "analyzed-payday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁1', '▁이', '으로', '에서', '▁있', '▁2', '▁그', '▁대', '▁사', '이다', '었다', '▁지', '▁수', '▁19', '▁가', '▁시', '▁20', '▁기', '▁전', '▁아', '▁하', '▁있다', '▁다', '▁제', '했다', '하였', '▁일', '▁한', '▁중', '▁정', '▁주', '하는', '▁것', '▁자', '▁공', '▁인', '되었다', '▁경', '▁위', '▁유', '▁보', '하고', '▁3', '▁등', '▁부', '하였다', '▁조', '하여', '▁미', '▁동', '▁선', '▁나', '으며', '▁모', '▁연', '▁영', '▁의', '▁오', '▁마', '에는', '▁발', '▁소', '한다', '▁고', '▁개', '▁201', '▁구', '▁세', '▁도', '▁상', '▁비', '▁스', '▁국', '▁서', '▁후', '▁여', '▁200', '▁때', '▁4', '▁성', '▁해', '▁관', '▁있는', '▁신', '▁프', '▁대한', '부터', '▁5', '▁방', '▁또', '지만', '▁(', '▁역', '되어', '▁않', '▁만', '▁\"', '▁장', '▁바', '까지']\n"
     ]
    }
   ],
   "source": [
    "# 특수 token 7개를 제외한 나머지 tokens\n",
    "vocab_list = []\n",
    "for id in range(7, len(vocab)):\n",
    "    if not vocab.is_unknown(id):\n",
    "        vocab_list.append(vocab.id_to_piece(id))\n",
    "print(vocab_list[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "elegant-yield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "civilian-attendance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어', '▁그날', '은', '▁', '왠', '지', '▁손', '님이', '▁많아', '▁첫', '▁번에', '▁삼', '십', '▁전', '▁둘째', '번', '▁오', '십', '▁전', '▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러', '▁컬', '컬', '한', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내', '▁생각에', '▁그', '토록', '▁먹고', '▁싶다', '던', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# [CLS], tokens a [SEP], tokens b, [SEP] 형태의 token 생성\n",
    "string_a = \"추적추적 비가 내리는 날이었어 그날은 왠지 손님이 많아 첫 번에 삼십 전 둘째번 오십 전 오랜만에 받아보는 십 전짜리 백통화 서푼에\"\n",
    "string_b = \"손바닥 위엔 기쁨의 눈물이 흘러 컬컬한 목에 모주 한잔을 적셔 몇 달 포 전부터 콜록거리는 아내 생각에 그토록 먹고 싶다던\"\n",
    "tokens_org = [\"[CLS]\"] + vocab.encode_as_pieces(string_a) + [\"[SEP]\"] + vocab.encode_as_pieces(string_b) + [\"[SEP]\"]\n",
    "print(tokens_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-message",
   "metadata": {},
   "source": [
    "방금 우리는 SentencePiece 모델을 이용해 간단한 BERT의 Masked Language Model 학습용 데이터를 하나 생성해 보았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-heather",
   "metadata": {},
   "source": [
    "## 데이터 전처리 (1) MASK 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-atlanta",
   "metadata": {},
   "source": [
    "BERT의 Masked Language Model은 GPT의 Next Token Prediction 태스크처럼 `다음에 이어질 단어는?` 을 맞추는 게 아니라 `마스킹 된 다음 빈칸에 알맞은 단어는?` 문제를 푸는 형식으로 구성됩니다. 이런 빈칸은 전체 토큰의 15% 정도가 적당하다고 합니다.  \n",
    "  \n",
    "이전 스텝의 Masked LM 데이터셋 예시에서 출발해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "seeing-eight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어', '▁그날', '은', '▁', '왠', '지', '▁손', '님이', '▁많아', '▁첫', '▁번에', '▁삼', '십', '▁전', '▁둘째', '번', '▁오', '십', '▁전', '▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러', '▁컬', '컬', '한', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내', '▁생각에', '▁그', '토록', '▁먹고', '▁싶다', '던', '[SEP]']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokens_org)\n",
    "\n",
    "# 전체 token의 15% mask\n",
    "mask_cnt = int((len(tokens_org) - 3) * 0.15) # 추가해준 token 세개를 뺀 후 15퍼센트 추출\n",
    "mask_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-planet",
   "metadata": {},
   "source": [
    "15%를 마스킹 한다고 해도 생각해 볼 것이 더 있습니다. Subword 기반으로 토크나이징을 했을 때 `_대, [MASK], 민국`이라고 가운데를 마스킹 했을 경우 해당 `[MASK]`가 '한'일 거라는 건 너무 쉽게 맞출 수 있습니다. '대한민국'이라는 패턴을 아주 자주 보게 될 테니까요.  \n",
    "  \n",
    "그래서 Masked LM 태스크를 구성할 땐 **띄어쓰기 단위로 한꺼번에 마스킹**해 주는 것이 좋습니다. 다음과 같이 처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "expressed-feelings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3] ['▁추적', '추', '적']\n",
      "[4] ['▁비가']\n",
      "[5] ['▁내리는']\n",
      "[6, 7, 8] ['▁날', '이었', '어']\n",
      "[9, 10] ['▁그날', '은']\n",
      "[11, 12, 13] ['▁', '왠', '지']\n",
      "[14, 15] ['▁손', '님이']\n",
      "[16] ['▁많아']\n",
      "[17] ['▁첫']\n",
      "[18] ['▁번에']\n",
      "[19, 20] ['▁삼', '십']\n",
      "[21] ['▁전']\n",
      "[22, 23] ['▁둘째', '번']\n",
      "[24, 25] ['▁오', '십']\n",
      "[26] ['▁전']\n",
      "[27, 28] ['▁오랜', '만에']\n",
      "[29, 30] ['▁받아', '보는']\n",
      "[31] ['▁십']\n",
      "[32, 33] ['▁전', '짜리']\n",
      "[34, 35, 36] ['▁백', '통', '화']\n",
      "[37, 38, 39] ['▁서', '푼', '에']\n",
      "[41] ['▁손바닥']\n",
      "[42, 43] ['▁위', '엔']\n",
      "[44, 45] ['▁기쁨', '의']\n",
      "[46, 47] ['▁눈', '물이']\n",
      "[48] ['▁흘러']\n",
      "[49, 50, 51] ['▁컬', '컬', '한']\n",
      "[52] ['▁목에']\n",
      "[53, 54] ['▁모', '주']\n",
      "[55, 56, 57] ['▁한', '잔', '을']\n",
      "[58, 59] ['▁적', '셔']\n",
      "[60] ['▁몇']\n",
      "[61] ['▁달']\n",
      "[62] ['▁포']\n",
      "[63] ['▁전부터']\n",
      "[64, 65, 66] ['▁콜', '록', '거리는']\n",
      "[67] ['▁아내']\n",
      "[68] ['▁생각에']\n",
      "[69, 70] ['▁그', '토록']\n",
      "[71] ['▁먹고']\n",
      "[72, 73] ['▁싶다', '던']\n"
     ]
    }
   ],
   "source": [
    "# 띄어쓰기 단위로 mask 하기 위해서 index 분할\n",
    "cand_idx = [] # word 단위의 index array\n",
    "for (i, token) in enumerate(tokens_org):\n",
    "    if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "        continue\n",
    "    if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"): # cnad_idx의 길이가 0보다 크고 _로 시작하지 않는 경우 마지막 list에 append\n",
    "        cand_idx[-1].append(i)\n",
    "    else:\n",
    "        cand_idx.append([i]) # 길이가 0인 상태에서 _로 시작하는 리스트를 처음으로 넣어줌\n",
    "        \n",
    "# 결과 확인\n",
    "for cand in cand_idx:\n",
    "    print(cand, [tokens_org[i] for i in cand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "extended-billy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[18],\n",
       " [44, 45],\n",
       " [24, 25],\n",
       " [49, 50, 51],\n",
       " [31],\n",
       " [63],\n",
       " [41],\n",
       " [52],\n",
       " [22, 23],\n",
       " [71],\n",
       " [17],\n",
       " [19, 20],\n",
       " [60],\n",
       " [32, 33],\n",
       " [62],\n",
       " [46, 47],\n",
       " [29, 30],\n",
       " [72, 73],\n",
       " [6, 7, 8],\n",
       " [64, 65, 66],\n",
       " [67],\n",
       " [9, 10],\n",
       " [26],\n",
       " [55, 56, 57],\n",
       " [61],\n",
       " [34, 35, 36],\n",
       " [37, 38, 39],\n",
       " [21],\n",
       " [58, 59],\n",
       " [48],\n",
       " [69, 70],\n",
       " [4],\n",
       " [27, 28],\n",
       " [42, 43],\n",
       " [14, 15],\n",
       " [68],\n",
       " [5],\n",
       " [11, 12, 13],\n",
       " [1, 2, 3],\n",
       " [16],\n",
       " [53, 54]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random mask를 위해서 순서를 섞음\n",
    "random.shuffle(cand_idx)\n",
    "cand_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-ocean",
   "metadata": {},
   "source": [
    "개선된 Masking 로직을 다음과 같이 구현해 보았습니다. 마스킹 된 결과를 이전과 비교해 보시죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prospective-cartridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_org\n",
      "['[CLS]', '▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어', '▁그날', '은', '▁', '왠', '지', '▁손', '님이', '▁많아', '▁첫', '▁번에', '▁삼', '십', '▁전', '▁둘째', '번', '▁오', '십', '▁전', '▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러', '▁컬', '컬', '한', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내', '▁생각에', '▁그', '토록', '▁먹고', '▁싶다', '던', '[SEP]'] \n",
      "\n",
      "tokens\n",
      "['[CLS]', '▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어', '▁그날', '은', '▁', '왠', '지', '▁손', '님이', '▁많아', '▁첫', '[MASK]', '▁삼', '십', '▁전', '▁둘째', '번', '[MASK]', '[MASK]', '▁전', '▁오랜', '만에', '▁받아', '보는', None, '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손바닥', '▁위', '엔', '[MASK]', '[MASK]', '▁눈', '물이', '▁흘러', '[MASK]', '[MASK]', '[MASK]', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '[MASK]', '▁콜', '록', '거리는', '▁아내', '▁생각에', '▁그', '토록', '▁먹고', '▁싶다', '던', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# tokens가 mask되므로 재 실행을 위해서 넣어줌 (테스트용)\n",
    "tokens = copy.deepcopy(tokens_org)\n",
    "\n",
    "mask_lms = [] # mask된 값\n",
    "for index_set in cand_idx: #[1, 2, 3]\n",
    "    if len(mask_lms) >= mask_cnt: # 현재 mask된 개수가 15%를 넘으면 중지\n",
    "        break\n",
    "    if len(mask_lms) + len(index_set) > mask_cnt: # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
    "        continue\n",
    "    dice = random.random() # 0~1 사이의 확률 값\n",
    "    \n",
    "    for index in index_set: # 1, 2, 3\n",
    "        masked_token = None\n",
    "        if dice < 0.8: # 80% replace with [MASK]\n",
    "            masked_token = \"[MASK]\"\n",
    "        elif dice < 0.9: # 10% keep original\n",
    "            masked_token = random.choice(vocab_list) # 10% 단어를 랜덤하게 바꿈?\n",
    "            \n",
    "        mask_lms.append({\"index\":index, \"label\":tokens[index]})\n",
    "        tokens[index] = masked_token\n",
    "        \n",
    "print(\"tokens_org\")\n",
    "print(tokens_org, \"\\n\")\n",
    "print(\"tokens\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-coordinator",
   "metadata": {},
   "source": [
    "Masked LM의 라벨 데이터도 아래와 같이 생성하여 정리해 둡니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "excessive-powder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 18, 'label': '▁번에'},\n",
       " {'index': 44, 'label': '▁기쁨'},\n",
       " {'index': 45, 'label': '의'},\n",
       " {'index': 24, 'label': '▁오'},\n",
       " {'index': 25, 'label': '십'},\n",
       " {'index': 49, 'label': '▁컬'},\n",
       " {'index': 50, 'label': '컬'},\n",
       " {'index': 51, 'label': '한'},\n",
       " {'index': 31, 'label': '▁십'},\n",
       " {'index': 63, 'label': '▁전부터'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_lms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "behavioral-harrison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_idx : [18, 24, 25, 31, 44, 45, 49, 50, 51, 63]\n",
      "mask_label: ['▁번에', '▁오', '십', '▁십', '▁기쁨', '의', '▁컬', '컬', '한', '▁전부터']\n"
     ]
    }
   ],
   "source": [
    "# 순서 정렬 및 mask_idx, mask_label 생성\n",
    "mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"]) # index 순으로 정렬\n",
    "mask_idx = [p[\"index\"] for p in mask_lms]\n",
    "mask_label = [p[\"label\"] for p in mask_lms]\n",
    "\n",
    "print(\"mask_idx :\", mask_idx)\n",
    "print(\"mask_label:\", mask_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-astrology",
   "metadata": {},
   "source": [
    "### create_pretrain_mask() : Masked LM을 위한 코퍼스 생성 메소드\n",
    "구현할 최종 메소드는 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "champion-raleigh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', '▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어', '▁그날']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "french-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
    "    \"\"\"\n",
    "    마스크 생성\n",
    "    :param tokens: tokens\n",
    "    :param mask_cnt: mask 개수 (전체 tokens의 15%)\n",
    "    :param vocab_list: vocab list (random token 용)\n",
    "    :return tokens: mask된 tokens\n",
    "    :return mask_idx: mask된 token의 index\n",
    "    :return mask_label: mask된 token의 원래 값\n",
    "    \"\"\"\n",
    "    # 단어 단위로 mask 하기 위해서 index 분할\n",
    "    cand_idx = []  # word 단위의 index array\n",
    "    for (i, token) in enumerate(tokens):\n",
    "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "            continue\n",
    "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
    "            cand_idx[-1].append(i)\n",
    "        else:\n",
    "            cand_idx.append([i])\n",
    "    # random mask를 위해서 순서를 섞음\n",
    "    random.shuffle(cand_idx)\n",
    "\n",
    "    mask_lms = []  # mask 된 값\n",
    "    for index_set in cand_idx:  #['_추적추적', '_비가', '_내리는', '날이었어' ,..]\n",
    "        if len(mask_lms) >= mask_cnt:  # 핸재 mask된 개수가 15%를 넘으면 중지\n",
    "            break\n",
    "        if len(mask_lms) + len(index_set) > mask_cnt:  # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
    "            continue\n",
    "        dice = random.random()  # 0..1 사이의 확률 값\n",
    "        for index in index_set: # '_추', '적', '추', '적', '_비', '가',...\n",
    "            masked_token = None\n",
    "            if dice < 0.8:  # 80% replace with [MASK]\n",
    "                masked_token = \"[MASK]\"\n",
    "            elif dice < 0.9: # 10% keep original\n",
    "                masked_token = tokens[index]\n",
    "            else:  # 10% random word\n",
    "                masked_token = random.choice(vocab_list)\n",
    "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "            tokens[index] = masked_token\n",
    "    # mask_lms 정렬 후 mask_idx, mask_label 추출\n",
    "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "    mask_idx = [p[\"index\"] for p in mask_lms]  # mask된 token의 index\n",
    "    mask_label = [p[\"label\"] for p in mask_lms]  # mask된 token의 원래 값\n",
    "\n",
    "    return tokens, mask_idx, mask_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-strap",
   "metadata": {},
   "source": [
    "`create_pretrain_mask()` 수행 결과를 다시 한번 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "broke-negotiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_org\n",
      "['[CLS]', '▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어', '▁그날', '은', '▁', '왠', '지', '▁손', '님이', '▁많아', '▁첫', '▁번에', '▁삼', '십', '▁전', '▁둘째', '번', '▁오', '십', '▁전', '▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러', '▁컬', '컬', '한', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내', '▁생각에', '▁그', '토록', '▁먹고', '▁싶다', '던', '[SEP]'] \n",
      "\n",
      "tokens\n",
      "['[CLS]', '▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어', '▁그날', '은', '▁', '왠', '지', '▁손', '님이', '[MASK]', '[MASK]', '▁번에', '▁삼', '십', '▁전', '▁둘째', '번', '[MASK]', '[MASK]', '▁전', '▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '[MASK]', '[MASK]', '[MASK]', '[SEP]', '▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러', '[MASK]', '[MASK]', '[MASK]', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내', '▁생각에', '▁그', '토록', '▁먹고', '▁싶다', '던', '[SEP]'] \n",
      "\n",
      "mask_idx : [16, 17, 24, 25, 37, 38, 39, 49, 50, 51]\n",
      "mask_label : ['▁많아', '▁첫', '▁오', '십', '▁서', '푼', '에', '▁컬', '컬', '한']\n"
     ]
    }
   ],
   "source": [
    "# tokens가 mask되므로 재 실행을 위해서 넣어줌(테스트용)\n",
    "tokens = copy.deepcopy(tokens_org)\n",
    "\n",
    "tokens, mask_idx, mask_label = create_pretrain_mask(tokens, mask_cnt, vocab_list)\n",
    "\n",
    "print(\"tokens_org\")\n",
    "print(tokens_org, \"\\n\")\n",
    "print(\"tokens\")\n",
    "print(tokens, \"\\n\")\n",
    "\n",
    "print(\"mask_idx :\", mask_idx)\n",
    "print(\"mask_label :\", mask_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-america",
   "metadata": {},
   "source": [
    "## 데이터 전처리 (2) NSP pair 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-voice",
   "metadata": {},
   "source": [
    "BERT의 pretrain task로 Next Sentence Prediction이 있습니다. 문장 2개를 붙여 놓고 두 문장이 이어지는 것인지 아닌지 문장 호응관계를 맞출 수 있게 하는 것입니다.  \n",
    "아래 문장을 예시로 진행해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "necessary-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"\"\"추적추적 비가 내리는 날이었어\n",
    "그날은 왠지 손님이 많아\n",
    "첫 번에 삼십 전 둘째 번 오십 전\n",
    "오랜만에 받아보는 십 전짜리 백통화 서푼에\n",
    "손바닥 위엔 기쁨의 눈물이 흘러\n",
    "컬컬한 목에 모주 한잔을 적셔\n",
    "몇 달 포 전부터 콜록거리는 아내\n",
    "생각에 그토록 먹고 싶다던\n",
    "설렁탕 한 그릇을 이제는 살 수 있어\n",
    "집으로 돌아가는 길 난 문득 떠올라\n",
    "아내의 목소리가 거칠어만 가는 희박한 숨소리가\n",
    "오늘은 왠지 나가지 말라던 내 옆에 있어 달라던\n",
    "그리도 나가고 싶으면 일찍이라도 들어와 달라던\n",
    "아내의 간절한 목소리가 들려와\n",
    "나를 원망하듯 비는 점점 거세져\n",
    "싸늘히 식어가는 아내가 떠올라 걱정은 더해져\n",
    "난 몰라 오늘은 운수 좋은 날\n",
    "난 맨날 이렇게 살 수 있으면 얼마나 좋을까\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mighty-financing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어'],\n",
       " ['▁그날', '은', '▁', '왠', '지', '▁손', '님이', '▁많아'],\n",
       " ['▁첫', '▁번에', '▁삼', '십', '▁전', '▁둘째', '▁번', '▁오', '십', '▁전']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 줄 단위로 tokenize\n",
    "doc = [vocab.encode_as_pieces(line) for line in string.split(\"\\n\")]\n",
    "doc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-injury",
   "metadata": {},
   "source": [
    "우선 원문에서 이어진 두 문장씩 짝지어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "blond-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이\n",
    "n_test_seq = 64\n",
    "# 최소 길이\n",
    "min_seq = 8\n",
    "# [CLS], tokens_a, [SEB], tokens_b, [SEP]\n",
    "max_seq = n_test_seq - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "valid-programmer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_chunk: 7 66 [['▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어'], ['▁그날', '은', '▁', '왠', '지', '▁손', '님이', '▁많아'], ['▁첫', '▁번에', '▁삼', '십', '▁전', '▁둘째', '▁번', '▁오', '십', '▁전'], ['▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에'], ['▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러'], ['▁컬', '컬', '한', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔'], ['▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내']]\n",
      "tokens_a: 39 ['▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어', '▁그날', '은', '▁', '왠', '지', '▁손', '님이', '▁많아', '▁첫', '▁번에', '▁삼', '십', '▁전', '▁둘째', '▁번', '▁오', '십', '▁전', '▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에']\n",
      "tokens_b: 27 ['▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러', '▁컬', '컬', '한', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내']\n",
      "\n",
      "current_chunk: 7 65 [['▁생각에', '▁그', '토록', '▁먹고', '▁싶다', '던'], ['▁설', '렁', '탕', '▁한', '▁그릇', '을', '▁이제는', '▁살', '▁수', '▁있어'], ['▁집으로', '▁돌아가는', '▁길', '▁난', '▁문', '득', '▁떠올', '라'], ['▁아내의', '▁목소리가', '▁거칠', '어', '만', '▁가는', '▁희', '박한', '▁숨', '소', '리가'], ['▁오늘', '은', '▁', '왠', '지', '▁나가지', '▁말라', '던', '▁내', '▁옆에', '▁있어', '▁달라', '던'], ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일찍', '이라도', '▁들어와', '▁달라', '던'], ['▁아내의', '▁간', '절한', '▁목소리가', '▁들려', '와']]\n",
      "tokens_a: 48 ['▁생각에', '▁그', '토록', '▁먹고', '▁싶다', '던', '▁설', '렁', '탕', '▁한', '▁그릇', '을', '▁이제는', '▁살', '▁수', '▁있어', '▁집으로', '▁돌아가는', '▁길', '▁난', '▁문', '득', '▁떠올', '라', '▁아내의', '▁목소리가', '▁거칠', '어', '만', '▁가는', '▁희', '박한', '▁숨', '소', '리가', '▁오늘', '은', '▁', '왠', '지', '▁나가지', '▁말라', '던', '▁내', '▁옆에', '▁있어', '▁달라', '던']\n",
      "tokens_b: 17 ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일찍', '이라도', '▁들어와', '▁달라', '던', '▁아내의', '▁간', '절한', '▁목소리가', '▁들려', '와']\n",
      "\n",
      "current_chunk: 4 41 [['▁나를', '▁원', '망', '하', '듯', '▁비는', '▁점점', '▁거세', '져'], ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내가', '▁떠올', '라', '▁걱', '정은', '▁더', '해져'], ['▁난', '▁몰', '라', '▁오늘', '은', '▁운수', '▁좋은', '▁날'], ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있으면', '▁얼마나', '▁좋', '을', '까']]\n",
      "tokens_a: 9 ['▁나를', '▁원', '망', '하', '듯', '▁비는', '▁점점', '▁거세', '져']\n",
      "tokens_b: 32 ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내가', '▁떠올', '라', '▁걱', '정은', '▁더', '해져', '▁난', '▁몰', '라', '▁오늘', '은', '▁운수', '▁좋은', '▁날', '▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있으면', '▁얼마나', '▁좋', '을', '까']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_chunk = [] # line 단위 tokens\n",
    "current_length = 0\n",
    "for i in range(len(doc)): # doc 전체를 loop\n",
    "    current_chunk.append(doc[i]) # line 단위로 추가\n",
    "    current_length += len(doc[i]) # current_chunk의 token 수\n",
    "    if 1 < len(current_chunk) and (i == len(doc) -1 or current_length >= max_seq): # 마지막 줄 이거나 길이가 max_seq 이상인 경우\n",
    "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "        ## if = True 만족해야 print하고 넘어갈 수 있음\n",
    "        \n",
    "        ############################\n",
    "        # token a\n",
    "        a_and = 1\n",
    "        if 1 < len(current_chunk):\n",
    "            a_end = random.randrange(1, len(current_chunk)) # ex) 0~8중 하나 선택\n",
    "        tokens_a = []\n",
    "        for j in range(a_end):\n",
    "            tokens_a.extend(current_chunk[j]) # 만약 a_end=4이면 0~3까지\n",
    "        # token b\n",
    "        tokens_b = []\n",
    "        for j in range(a_end, len(current_chunk)): # 3~7까지\n",
    "            tokens_b.extend(current_chunk[j])\n",
    "            \n",
    "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "        ###############################\n",
    "        print()\n",
    "        \n",
    "        current_chunk = []\n",
    "        current_length = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-bullet",
   "metadata": {},
   "source": [
    "짝지은 두 문장을 그대로 두면 NSP task의 true label 케이스가 되고, 둘의 순서를 뒤바꾸면 false label 케이스가 되겠죠? 두 문장의 최대 길이를 유지하도록 trim을 적용한 후 50%의 확률로 true/false 케이스를 생성해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "based-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
    "    \"\"\"\n",
    "    tokens_a, tokens_b의 길이를 줄임 최대 길이: max_seq\n",
    "    : param tokens_a: tokens A\n",
    "    : param tokens_b: tokens B\n",
    "    : param max_seq: 두 tokens 길이의 최대 값\n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_seq:\n",
    "            break\n",
    "\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            del tokens_a[0]\n",
    "        else:\n",
    "            tokens_b.pop() # 마지막 요소를 반환 후 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "rental-airport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_chunk: 7 66 [['▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어'], ['▁그날', '은', '▁', '왠', '지', '▁손', '님이', '▁많아'], ['▁첫', '▁번에', '▁삼', '십', '▁전', '▁둘째', '▁번', '▁오', '십', '▁전'], ['▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에'], ['▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러'], ['▁컬', '컬', '한', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔'], ['▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내']]\n",
      "is_next: 1\n",
      "tokens_a: 34 ['▁날', '이었', '어', '▁그날', '은', '▁', '왠', '지', '▁손', '님이', '▁많아', '▁첫', '▁번에', '▁삼', '십', '▁전', '▁둘째', '▁번', '▁오', '십', '▁전', '▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에']\n",
      "tokens_b: 27 ['▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러', '▁컬', '컬', '한', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내']\n",
      "\n",
      "current_chunk: 7 65 [['▁생각에', '▁그', '토록', '▁먹고', '▁싶다', '던'], ['▁설', '렁', '탕', '▁한', '▁그릇', '을', '▁이제는', '▁살', '▁수', '▁있어'], ['▁집으로', '▁돌아가는', '▁길', '▁난', '▁문', '득', '▁떠올', '라'], ['▁아내의', '▁목소리가', '▁거칠', '어', '만', '▁가는', '▁희', '박한', '▁숨', '소', '리가'], ['▁오늘', '은', '▁', '왠', '지', '▁나가지', '▁말라', '던', '▁내', '▁옆에', '▁있어', '▁달라', '던'], ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일찍', '이라도', '▁들어와', '▁달라', '던'], ['▁아내의', '▁간', '절한', '▁목소리가', '▁들려', '와']]\n",
      "is_next: 1\n",
      "tokens_a: 44 ['▁싶다', '던', '▁설', '렁', '탕', '▁한', '▁그릇', '을', '▁이제는', '▁살', '▁수', '▁있어', '▁집으로', '▁돌아가는', '▁길', '▁난', '▁문', '득', '▁떠올', '라', '▁아내의', '▁목소리가', '▁거칠', '어', '만', '▁가는', '▁희', '박한', '▁숨', '소', '리가', '▁오늘', '은', '▁', '왠', '지', '▁나가지', '▁말라', '던', '▁내', '▁옆에', '▁있어', '▁달라', '던']\n",
      "tokens_b: 17 ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일찍', '이라도', '▁들어와', '▁달라', '던', '▁아내의', '▁간', '절한', '▁목소리가', '▁들려', '와']\n",
      "\n",
      "current_chunk: 4 41 [['▁나를', '▁원', '망', '하', '듯', '▁비는', '▁점점', '▁거세', '져'], ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내가', '▁떠올', '라', '▁걱', '정은', '▁더', '해져'], ['▁난', '▁몰', '라', '▁오늘', '은', '▁운수', '▁좋은', '▁날'], ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있으면', '▁얼마나', '▁좋', '을', '까']]\n",
      "is_next: 0\n",
      "tokens_a: 19 ['▁난', '▁몰', '라', '▁오늘', '은', '▁운수', '▁좋은', '▁날', '▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있으면', '▁얼마나', '▁좋', '을', '까']\n",
      "tokens_b: 22 ['▁나를', '▁원', '망', '하', '듯', '▁비는', '▁점점', '▁거세', '져', '▁싸', '늘', '히', '▁식', '어', '가는', '▁아내가', '▁떠올', '라', '▁걱', '정은', '▁더', '해져']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_chunk = [] # line 단위 tokens\n",
    "current_length = 0\n",
    "for i in range(len(doc)): # doc 전체를 loop\n",
    "    current_chunk.append(doc[i]) # line 단위로 추가\n",
    "    current_length += len(doc[i]) # current_chunk의 token 수\n",
    "    if 1 < len(current_chunk) and (i == len(doc) -1 or current_length >= max_seq):\n",
    "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "        \n",
    "        # token a\n",
    "        a_end = 1\n",
    "        if 1 < len(current_chunk):\n",
    "            a_end = random.randrange(1, len(current_chunk))\n",
    "        tokens_a = []\n",
    "        for j in range(a_end):\n",
    "            tokens_a.extend(current_chunk[j])\n",
    "        # token b\n",
    "        tokens_b = []\n",
    "        for j in range(a_end, len(current_chunk)):\n",
    "            tokens_b.extend(current_chunk[j])\n",
    "            \n",
    "        #####################################\n",
    "        if random.random() < 0.5: # 50% 확률로 swap\n",
    "            is_next = 0\n",
    "            tokens_t = tokens_a\n",
    "            tokens_a = tokens_b\n",
    "            tokens_b = tokens_t\n",
    "        else:\n",
    "            is_next = 1\n",
    "        # max_seq 보다 큰 경우 길이 조절\n",
    "        trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "        assert 0 < len(tokens_a)\n",
    "        assert 0 < len(tokens_b)\n",
    "        \n",
    "        print(\"is_next:\", is_next)\n",
    "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "        ###################################\n",
    "        print()\n",
    "        \n",
    "        current_chunk = []\n",
    "        current_length = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-sellers",
   "metadata": {},
   "source": [
    "이제 두 문장 사이에 segment 처리를 해주어야 합니다. 첫 번째 문장의 segment는 모두 0으로, 두 번째 문장은 1로 채워준 후 둘 사이에 구분자인 [SEP] 등을 넣어주는 것으로 마무리됩니다.  \n",
    "  \n",
    "이전 스텝의 `create_pretrain_mask()`까지 함께 호출되어 Mask LM용 데이터셋과 NSP용 데이터셋이 결합된 하나의 데이터셋으로 완성될 것입니다. BERT의 pretrain 은 두 가지 task가 동시에 수행되니까요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "neural-express",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_chunk: 7 66 [['▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어'], ['▁그날', '은', '▁', '왠', '지', '▁손', '님이', '▁많아'], ['▁첫', '▁번에', '▁삼', '십', '▁전', '▁둘째', '▁번', '▁오', '십', '▁전'], ['▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에'], ['▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러'], ['▁컬', '컬', '한', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔'], ['▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내']]\n",
      "is_next: 0\n",
      "tokens_a: 45 ['▁둘째', '▁번', '▁오', '십', '▁전', '▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에', '▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러', '▁컬', '컬', '한', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내']\n",
      "tokens_b: 16 ['▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어', '▁그날', '은', '▁', '왠', '지', '▁손', '님이', '▁많아']\n",
      "tokens: 64 ['[CLS]', '▁둘째', '▁번', '▁오', '십', '▁전', '▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에', '▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러', '▁컬', '컬', '한', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내', '[SEP]', '▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어', '▁그날', '은', '▁', '왠', '지', '▁손', '님이', '▁많아', '[SEP]']\n",
      "segment: 64 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "masked tokens: 64 ['[CLS]', '▁둘째', '▁번', '▁오', '십', '▁전', '▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에', '▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러', '▁컬', '컬', '한', '▁목에', '▁방식으로', '▁없어서', '▁한', '잔', '을', '[MASK]', '[MASK]', '▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내', '[SEP]', '▁추적', '추', '적', '[MASK]', '▁내리는', '▁날', '이었', '어', '▁그날', '은', '▁', '왠', '지', '▁손', '님이', '[MASK]', '[SEP]']\n",
      "masked index: 9 [16, 17, 18, 31, 32, 36, 37, 50, 62]\n",
      "masked label: 10 ['▁많아', '▁첫', '▁오', '십', '▁서', '푼', '에', '▁컬', '컬', '한']\n",
      "\n",
      "current_chunk: 7 65 [['▁생각에', '▁그', '토록', '▁먹고', '▁싶다', '던'], ['▁설', '렁', '탕', '▁한', '▁그릇', '을', '▁이제는', '▁살', '▁수', '▁있어'], ['▁집으로', '▁돌아가는', '▁길', '▁난', '▁문', '득', '▁떠올', '라'], ['▁아내의', '▁목소리가', '▁거칠', '어', '만', '▁가는', '▁희', '박한', '▁숨', '소', '리가'], ['▁오늘', '은', '▁', '왠', '지', '▁나가지', '▁말라', '던', '▁내', '▁옆에', '▁있어', '▁달라', '던'], ['▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일찍', '이라도', '▁들어와', '▁달라', '던'], ['▁아내의', '▁간', '절한', '▁목소리가', '▁들려', '와']]\n",
      "is_next: 1\n",
      "tokens_a: 31 ['▁싶다', '던', '▁설', '렁', '탕', '▁한', '▁그릇', '을', '▁이제는', '▁살', '▁수', '▁있어', '▁집으로', '▁돌아가는', '▁길', '▁난', '▁문', '득', '▁떠올', '라', '▁아내의', '▁목소리가', '▁거칠', '어', '만', '▁가는', '▁희', '박한', '▁숨', '소', '리가']\n",
      "tokens_b: 30 ['▁오늘', '은', '▁', '왠', '지', '▁나가지', '▁말라', '던', '▁내', '▁옆에', '▁있어', '▁달라', '던', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일찍', '이라도', '▁들어와', '▁달라', '던', '▁아내의', '▁간', '절한', '▁목소리가', '▁들려', '와']\n",
      "tokens: 64 ['[CLS]', '▁싶다', '던', '▁설', '렁', '탕', '▁한', '▁그릇', '을', '▁이제는', '▁살', '▁수', '▁있어', '▁집으로', '▁돌아가는', '▁길', '▁난', '▁문', '득', '▁떠올', '라', '▁아내의', '▁목소리가', '▁거칠', '어', '만', '▁가는', '▁희', '박한', '▁숨', '소', '리가', '[SEP]', '▁오늘', '은', '▁', '왠', '지', '▁나가지', '▁말라', '던', '▁내', '▁옆에', '▁있어', '▁달라', '던', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일찍', '이라도', '▁들어와', '▁달라', '던', '▁아내의', '▁간', '절한', '▁목소리가', '▁들려', '와', '[SEP]']\n",
      "segment: 64 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "masked tokens: 64 ['[CLS]', '▁싶다', '던', '▁설', '렁', '탕', '▁한', '▁어머니와', '▁이와테', '▁이제는', '▁살', '▁수', '[MASK]', '▁집으로', '▁돌아가는', '▁길', '▁난', '▁문', '득', '▁떠올', '라', '▁아내의', '▁목소리가', '▁거칠', '어', '만', '▁가는', '▁희', '박한', '▁숨', '소', '리가', '[SEP]', '▁오늘', '은', '▁', '왠', '지', '▁나가지', '▁말라', '던', '▁내', '▁옆에', '▁있어', '▁달라', '던', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일찍', '이라도', '▁들어와', '▁달라', '던', '▁아내의', '[MASK]', '[MASK]', '▁목소리가', '▁들려', '와', '[SEP]']\n",
      "masked index: 9 [7, 8, 11, 12, 23, 24, 25, 58, 59]\n",
      "masked label: 10 ['▁많아', '▁첫', '▁오', '십', '▁서', '푼', '에', '▁컬', '컬', '한']\n",
      "\n",
      "current_chunk: 4 41 [['▁나를', '▁원', '망', '하', '듯', '▁비는', '▁점점', '▁거세', '져'], ['▁싸', '늘', '히', '▁식', '어', '가는', '▁아내가', '▁떠올', '라', '▁걱', '정은', '▁더', '해져'], ['▁난', '▁몰', '라', '▁오늘', '은', '▁운수', '▁좋은', '▁날'], ['▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있으면', '▁얼마나', '▁좋', '을', '까']]\n",
      "is_next: 0\n",
      "tokens_a: 19 ['▁난', '▁몰', '라', '▁오늘', '은', '▁운수', '▁좋은', '▁날', '▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있으면', '▁얼마나', '▁좋', '을', '까']\n",
      "tokens_b: 22 ['▁나를', '▁원', '망', '하', '듯', '▁비는', '▁점점', '▁거세', '져', '▁싸', '늘', '히', '▁식', '어', '가는', '▁아내가', '▁떠올', '라', '▁걱', '정은', '▁더', '해져']\n",
      "tokens: 44 ['[CLS]', '▁난', '▁몰', '라', '▁오늘', '은', '▁운수', '▁좋은', '▁날', '▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있으면', '▁얼마나', '▁좋', '을', '까', '[SEP]', '▁나를', '▁원', '망', '하', '듯', '▁비는', '▁점점', '▁거세', '져', '▁싸', '늘', '히', '▁식', '어', '가는', '▁아내가', '▁떠올', '라', '▁걱', '정은', '▁더', '해져', '[SEP]']\n",
      "segment: 44 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "masked tokens: 44 ['[CLS]', '▁난', '▁몰', '라', '▁오늘', '은', '▁운수', '▁좋은', '[MASK]', '▁난', '[MASK]', '[MASK]', '▁이렇게', '▁살', '▁수', '▁있으면', '▁얼마나', '▁좋', '을', '까', '[SEP]', '[MASK]', '▁원', '망', '하', '듯', '▁비는', '▁점점', '▁거세', '져', '▁싸', '늘', '히', '▁식', '어', '가는', '▁아내가', '▁떠올', '라', '▁걱', '정은', '[MASK]', '[MASK]', '[SEP]']\n",
      "masked index: 6 [8, 10, 11, 21, 41, 42]\n",
      "masked label: 10 ['▁많아', '▁첫', '▁오', '십', '▁서', '푼', '에', '▁컬', '컬', '한']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instances = []\n",
    "current_chunk = []  # line 단위 tokens\n",
    "current_length = 0\n",
    "for i in range(len(doc)):  # doc 전체를 loop\n",
    "    current_chunk.append(doc[i])  # line 단위로 추가\n",
    "    current_length += len(doc[i])  # current_chunk의 token 수\n",
    "    if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  # 마지막 줄 이거나 길이가 max_seq 이상 인 경우\n",
    "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "\n",
    "        # token a\n",
    "        a_end = 1\n",
    "        if 1 < len(current_chunk):\n",
    "            a_end = random.randrange(1, len(current_chunk))\n",
    "        tokens_a = []\n",
    "        for j in range(a_end):\n",
    "            tokens_a.extend(current_chunk[j])\n",
    "        # token b\n",
    "        tokens_b = []\n",
    "        for j in range(a_end, len(current_chunk)):\n",
    "            tokens_b.extend(current_chunk[j])\n",
    "\n",
    "        if random.random() < 0.5:  # 50% 확률로 swap\n",
    "            is_next = 0\n",
    "            tokens_t = tokens_a\n",
    "            tokens_a = tokens_b\n",
    "            tokens_b = tokens_t\n",
    "        else:\n",
    "            is_next = 1\n",
    "        # max_seq 보다 큰 경우 길이 조절\n",
    "        trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "        assert 0 < len(tokens_a)\n",
    "        assert 0 < len(tokens_b)\n",
    "\n",
    "        print(\"is_next:\", is_next)\n",
    "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "        #################################################\n",
    "        # tokens & aegment 생성\n",
    "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "        segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "        print(\"tokens:\", len(tokens), tokens)\n",
    "        print(\"segment:\", len(segment), segment)\n",
    "        # mask\n",
    "        tokens, mask_idx, mask_table = create_pretrain_mask(tokens, int((len(tokens) - 3) * 0.15), vocab_list)\n",
    "        print(\"masked tokens:\", len(tokens), tokens)\n",
    "        print(\"masked index:\", len(mask_idx), mask_idx)\n",
    "        print(\"masked label:\", len(mask_label), mask_label)\n",
    "        \n",
    "        instance = {\n",
    "            \"tokens\": tokens,\n",
    "            \"segment\": segment,\n",
    "            \"is_next\": is_next,\n",
    "            \"mask_idx\": mask_idx,\n",
    "            \"mask_label\": mask_label\n",
    "        }\n",
    "        instances.append(instance)\n",
    "        ################################################\n",
    "        print()\n",
    "        \n",
    "        current_chunk = []\n",
    "        current_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "concerned-individual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['[CLS]', '▁둘째', '▁번', '▁오', '십', '▁전', '▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에', '▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러', '▁컬', '컬', '한', '▁목에', '▁방식으로', '▁없어서', '▁한', '잔', '을', '[MASK]', '[MASK]', '▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내', '[SEP]', '▁추적', '추', '적', '[MASK]', '▁내리는', '▁날', '이었', '어', '▁그날', '은', '▁', '왠', '지', '▁손', '님이', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [16, 17, 18, 31, 32, 36, 37, 50, 62], 'mask_label': ['▁많아', '▁첫', '▁오', '십', '▁서', '푼', '에', '▁컬', '컬', '한']}\n",
      "{'tokens': ['[CLS]', '▁싶다', '던', '▁설', '렁', '탕', '▁한', '▁어머니와', '▁이와테', '▁이제는', '▁살', '▁수', '[MASK]', '▁집으로', '▁돌아가는', '▁길', '▁난', '▁문', '득', '▁떠올', '라', '▁아내의', '▁목소리가', '▁거칠', '어', '만', '▁가는', '▁희', '박한', '▁숨', '소', '리가', '[SEP]', '▁오늘', '은', '▁', '왠', '지', '▁나가지', '▁말라', '던', '▁내', '▁옆에', '▁있어', '▁달라', '던', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일찍', '이라도', '▁들어와', '▁달라', '던', '▁아내의', '[MASK]', '[MASK]', '▁목소리가', '▁들려', '와', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [7, 8, 11, 12, 23, 24, 25, 58, 59], 'mask_label': ['▁많아', '▁첫', '▁오', '십', '▁서', '푼', '에', '▁컬', '컬', '한']}\n",
      "{'tokens': ['[CLS]', '▁난', '▁몰', '라', '▁오늘', '은', '▁운수', '▁좋은', '[MASK]', '▁난', '[MASK]', '[MASK]', '▁이렇게', '▁살', '▁수', '▁있으면', '▁얼마나', '▁좋', '을', '까', '[SEP]', '[MASK]', '▁원', '망', '하', '듯', '▁비는', '▁점점', '▁거세', '져', '▁싸', '늘', '히', '▁식', '어', '가는', '▁아내가', '▁떠올', '라', '▁걱', '정은', '[MASK]', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [8, 10, 11, 21, 41, 42], 'mask_label': ['▁많아', '▁첫', '▁오', '십', '▁서', '푼', '에', '▁컬', '컬', '한']}\n"
     ]
    }
   ],
   "source": [
    "# 최종 데이터셋 결과 확인\n",
    "for instance in instances:\n",
    "    print(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-buffer",
   "metadata": {},
   "source": [
    "### create_pretrain_instances() : Next Sentence Prediction을 위한 코퍼스 생성 메소드\n",
    "이번 스텝에서 구현할 최종 메소드는 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "intended-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list):\n",
    "    \"\"\"\n",
    "    doc별 pretrain 데이터 생성\n",
    "    \"\"\"\n",
    "    # for CLS], [SEP], [SEP]\n",
    "    max_seq = n_seq - 3\n",
    "\n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for i in range(len(doc)):\n",
    "        current_chunk.append(doc[i])  # line\n",
    "        current_length += len(doc[i])\n",
    "        if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):\n",
    "            # token a\n",
    "            a_end = 1\n",
    "            if 1 < len(current_chunk):\n",
    "                a_end = random.randrange(1, len(current_chunk))\n",
    "            tokens_a = []\n",
    "            for j in range(a_end):\n",
    "                tokens_a.extend(current_chunk[j])\n",
    "            # token b\n",
    "            tokens_b = []\n",
    "            for j in range(a_end, len(current_chunk)):\n",
    "                tokens_b.extend(current_chunk[j])\n",
    "\n",
    "            if random.random() < 0.5:  # 50% 확률로 swap\n",
    "                is_next = 0\n",
    "                tokens_t = tokens_a\n",
    "                tokens_a = tokens_b\n",
    "                tokens_b = tokens_t\n",
    "            else:\n",
    "                is_next = 1\n",
    "            # max_seq 보다 큰 경우 길이 조절\n",
    "            trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "            assert 0 < len(tokens_a)\n",
    "            assert 0 < len(tokens_b)\n",
    "            # tokens & aegment 생성\n",
    "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "            segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "            # mask\n",
    "            tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob), vocab_list)\n",
    "\n",
    "            instance = {\n",
    "                \"tokens\": tokens,\n",
    "                \"segment\": segment,\n",
    "                \"is_next\": is_next,\n",
    "                \"mask_idx\": mask_idx,\n",
    "                \"mask_label\": mask_label\n",
    "            }\n",
    "            instances.append(instance)\n",
    "\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-actress",
   "metadata": {},
   "source": [
    "`create_pretrain_instances()` 수행 결과를 다시 한번 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "buried-graphic",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['[CLS]', '▁날', '이었', '어', '▁그날', '은', '▁', '왠', '지', '▁손', '님이', '[MASK]', '▁첫', '▁번에', '▁삼', '십', '▁전', '▁둘째', '▁번', '▁오', '십', '▁전', '▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에', '▁손바닥', '▁위', '엔', '▁기쁨', '의', '[MASK]', '[MASK]', '▁흘러', '▁컬', '컬', '한', '▁목에', '[MASK]', '[MASK]', '▁한', '잔', '을', '▁적', '셔', '[SEP]', '▁몇', '▁달', '[MASK]', '▁전부터', '[MASK]', '[MASK]', '[MASK]', '▁아내', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [11, 40, 41, 47, 48, 57, 59, 60, 61], 'mask_label': ['▁많아', '▁눈', '물이', '▁모', '주', '▁포', '▁콜', '록', '거리는']}\n",
      "{'tokens': ['[CLS]', '▁문', '득', '▁떠올', '라', '▁아내의', '[MASK]', '▁거칠', '어', '만', '▁가는', '▁희', '박한', '▁숨', '소', '리가', '▁오늘', '은', '[MASK]', '[MASK]', '[MASK]', '▁나가지', '▁말라', '던', '▁내', '▁옆에', '▁있어', '꾹', '▁대기', '▁그리', '도', '▁나가', '고', '▁싶', '으면', '▁일찍', '이라도', '▁들어와', '▁달라', '던', '▁아내의', '▁간', '절한', '[MASK]', '▁들려', '와', '[SEP]', '▁생각에', '▁그', '토록', '▁먹고', '▁싶다', '던', '▁설', '렁', '탕', '▁한', '▁그릇', '을', '▁이제는', '▁살', '[MASK]', '▁있어', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [5, 6, 18, 19, 20, 27, 28, 43, 61], 'mask_label': ['▁아내의', '▁목소리가', '▁', '왠', '지', '▁달라', '던', '▁목소리가', '▁수']}\n",
      "{'tokens': ['[CLS]', '▁나를', '▁원', '망', '하', '듯', '▁비는', '[MASK]', '▁거세', '져', '▁싸', '늘', '히', '▁식', '어', '가는', '▁아내가', '▁떠올', '라', '[MASK]', '[MASK]', '▁더', '해져', '▁난', '▁몰', '라', '▁오늘', '은', '▁운수', '▁좋은', '▁날', '[SEP]', '▁난', '▁맨', '날', '▁이렇게', '▁살', '▁수', '▁있으면', '▁얼마나', '나는', '▁세기', '01', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [7, 19, 20, 40, 41, 42], 'mask_label': ['▁점점', '▁걱', '정은', '▁좋', '을', '까']}\n"
     ]
    }
   ],
   "source": [
    "instances = create_pretrain_instances(vocab, doc, n_test_seq, 0.15, vocab_list)\n",
    "\n",
    "# 최종 데이터셋 결과 확인\n",
    "for instance in instances:\n",
    "    print(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-argentina",
   "metadata": {},
   "source": [
    "## 데이터 전처리 (3) 데이터셋 완성\n",
    "이제 우리가 다루어야 할 kowiki.txt에 대해 본격적으로 들여다보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "buried-messenger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3957761"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_file = os.getenv('HOME') + '/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "\n",
    "# line count 확인\n",
    "total = 0\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    for line in in_f:\n",
    "        total += 1\n",
    "        \n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-orientation",
   "metadata": {},
   "source": [
    "전체 라인 수가 확인되시나요? 거의 400만 개에 육박하는 수치입니다.  \n",
    "  \n",
    "위키 문서는 하나의 도큐먼트가 주제 키워드에 대해 상세 내용이 설명으로 따라붙어 있는 형태로 구성되어 있지요? 도큐먼트 주제별로 잘 나눠지는지도 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fiscal-springer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 지미 카터\n",
      "\n",
      "29 제임스 얼 \"지미\" 카터 주니어(, 1924년 10월 1일 ~ )는 민주당 출신 미국 39번째 대통령 (1977년 ~ 1981년)이다.\n",
      "\n",
      "28 지미 카터는 조지아주 섬터 카운티 플레인스 마을에서 태어났다. 조지아 공과대학교를 졸업하였다. 그 후 해군에 들어가 전함·원자력·잠수함의 승무원으로 일하였다. 1953년 미국 해군 대위로 예편하였고 이후 땅콩·면화 등을 가꿔 많은 돈을 벌었다. 그의 별명이 \"땅콩 농부\" (Peanut Farmer)로 알려졌다.\n",
      "\n",
      "27 1962년 조지아 주 상원 의원 선거에서 낙선하나 그 선거가 부정선거 였음을 입증하게 되어 당선되고, 1966년 조지아 주 지사 선거에 낙선하지만 1970년 조지아 주 지사를 역임했다. 대통령이 되기 전 조지아주 상원의원을 두번 연임했으며, 1971년부터 1975년까지 조지아 지사로 근무했다. 조지아 주지사로 지내면서, 미국에 사는 흑인 등용법을 내세웠다.\n",
      "\n",
      "26 1976년 대통령 선거에 민주당 후보로 출마하여 도덕주의 정책으로 내세워, 포드를 누르고 당선되었다.\n",
      "\n",
      "25 카터 대통령은 에너지 개발을 촉구했으나 공화당의 반대로 무산되었다.\n",
      "\n",
      "24 카터는 이집트와 이스라엘을 조정하여, 캠프 데이비드에서 안와르 사다트 대통령과 메나헴 베긴 수상과 함께 중동 평화를 위한 캠프데이비드 협정을 체결했다.\n",
      "\n",
      "23 그러나 이것은 공화당과 미국의 유대인 단체의 반발을 일으켰다. 1979년 백악관에서 양국 간의 평화조약으로 이끌어졌다. 또한 소련과 제2차 전략 무기 제한 협상에 조인했다.\n",
      "\n",
      "22 카터는 1970년대 후반 당시 대한민국 등 인권 후진국의 국민들의 인권을 지키기 위해 노력했으며, 취임 이후 계속해서 도덕정치를 내세웠다.\n",
      "\n",
      "21 그러나 주 이란 미국 대사관 인질 사건에서 인질 구출 실패를 이유로 1980년 대통령 선거에서 공화당의 로널드 레이건 후보에게 져 결국 재선에 실패했다. 또한 임기 말기에 터진 소련의 아프가니스탄 침공 사건으로 인해 1980년 하계 올림픽에 반공국가들의 보이콧을 내세웠다.\n",
      "\n",
      "20 지미 카터는 대한민국과의 관계에서도 중요한 영향을 미쳤던 대통령 중 하나다. 인권 문제와 주한미군 철수 문제로 한때 한미 관계가 불편하기도 했다. 1978년 대한민국에 대한 북한의 위협에 대비해 한미연합사를 창설하면서, 1982년까지 3단계에 걸쳐 주한미군을 철수하기로 했다. 그러나 주한미군사령부와 정보기관·의회의 반대에 부딪혀 주한미군은 완전철수 대신 6,000명을 감축하는 데 그쳤다. 또한 박정희 정권의 인권 문제 등과의 논란으로 불협화음을 냈으나, 1979년 6월 하순, 대한민국을 방문하여 관계가 다소 회복되었다.\n",
      "\n",
      "19 1979년 ~ 1980년 대한민국의 정치적 격변기 당시의 대통령이었던 그는 이에 대해 애매한 태도를 보였고, 이는 후에 대한민국 내에서 고조되는 반미 운동의 한 원인이 됐다. 10월 26일, 박정희 대통령이 김재규 중앙정보부장에 의해 살해된 것에 대해 그는 이 사건으로 큰 충격을 받았으며, 사이러스 밴스 국무장관을 조문사절로 파견했다. 12·12 군사 반란과 5.17 쿠데타에 대해 초기에는 강하게 비난했으나, 미국 정부가 신군부를 설득하는데, 한계가 있었고 결국 묵인하는 듯한 태도를 보이게 됐다.\n",
      "\n",
      "18 퇴임 이후 민간 자원을 적극 활용한 비영리 기구인 카터 재단을 설립한 뒤 민주주의 실현을 위해 제 3세계의 선거 감시 활동 및 기니 벌레에 의한 드라쿤쿠르스 질병 방재를 위해 힘썼다. 미국의 빈곤층 지원 활동, 사랑의 집짓기 운동, 국제 분쟁 중재 등의 활동도 했다.\n",
      "\n",
      "17 카터는 카터 행정부 이후 미국이 북핵 위기, 코소보 전쟁, 이라크 전쟁과 같이 미국이 군사적 행동을 최후로 선택하는 전통적 사고를 버리고 군사적 행동을 선행하는 행위에 대해 깊은 유감을 표시 하며 미국의 군사적 활동에 강한 반대 입장을 보이고 있다.\n",
      "\n",
      "16 특히 국제 분쟁 조정을 위해 북한의 김일성, 아이티의 세드라스 장군, 팔레인스타인의 하마스, 보스니아의 세르비아계 정권 같이 미국 정부에 대해 협상을 거부하면서 사태의 위기를 초래한 인물 및 단체를 직접 만나 분쟁의 원인을 근본적으로 해결하기 위해 힘썼다. 이 과정에서 미국 행정부와 갈등을 보이기도 했지만, 전직 대통령의 권한과 재야 유명 인사들의 활약으로 해결해 나갔다.\n",
      "\n",
      "15 1978년에 채결된 캠프데이비드 협정의 이행이 지지부진 하자 중동 분쟁 분제를 해결하기 위해 1993년 퇴임 후 직접 이스라엘과 팔레인스타인의 오슬로 협정을 이끌어 내는 데도 성공했다.\n",
      "\n",
      "14 1993년 1차 북핵 위기 당시 북한에 대한 미국의 군사적 행동이 임박했으나, 미국 전직 대통령으로는 처음으로 북한을 방문하고 미국과 북 양국의 중재에 큰 기여를 해 위기를 해결했다는 평가를 받았다. 또한 이 때 김영삼 대통령과 김일성 주석의 만남을 주선했다. 하지만 그로부터 수주일 후 김일성이 갑자기 사망하여 김일성과 김영삼의 정상회담은 이루어지지 못했다.\n",
      "\n",
      "13 미국의 관타나모 수용소 문제, 세계의 인권문제에서도 관심이 깊어 유엔에 유엔인권고등판무관의 제도를 시행하도록 노력하여 독재자들의 인권 유린에 대해 제약을 하고, 국제형사재판소를 만드는 데 기여하여 독재자들 같은 인권유린범죄자를 재판소로 회부하여 국제적인 처벌을 받게 하는 등 인권 신장에 크나 큰 기여를 했다.\n",
      "\n",
      "12 2011년 4월 26일부터 29일까지 북한을 3일간 방문했다.\n",
      "\n",
      "11 경제문제를 해결하지 못하고 주 이란 미국 대사관 인질 사건에 발목이 잡혀 실패한 대통령으로 평가를 받지만 이란 사태는 미국 내 이란 재산을 풀어주겠다는 조건을 내세워서 사실상 카터가 해결한 것이었고, 사랑의 집짓기 운동 등으로 퇴임 후에 훨씬 더 존경받는 미국 대통령 중에 특이한 인물로 남았다.\n",
      "\n",
      "10 그는 2002년 말 인권과 중재 역할에 대한 공로를 인정받아 노벨 평화상을 받게 되었다.\n",
      "\n",
      "9 \n",
      "\n",
      "8 \n",
      "\n",
      "7 \n",
      "\n",
      "6 수학\n",
      "\n",
      "5 수학(數學, )은 양, 구조, 공간, 변화, 미적분 등의 개념을 다루는 학문이다. 현대 수학은 형식 논리를 이용해서 공리로 구성된 추상적 구조를 연구하는 학문으로 여겨지기도 한다. 수학은 그 구조와 발전 과정에서는 자연과학에 속하는 물리학을 비롯한 다른 학문들과 깊은 연관을 맺고 있다. 하지만, 어느 과학의 분야들과는 달리, 자연계에서 관측되지 않는 개념들에 대해서까지 이론을 일반화 및 추상화시킬 수 있다는 차이가 있다고 한다. 수학자들은 그러한 개념들에 대해서 추측을 하고, 적절하게 선택된 정의와 공리로부터의 엄밀한 연역을 통해서 추측들의 진위를 파악한다.\n",
      "\n",
      "4 수학은 숫자 세기, 계산, 측정 및 물리적 대상의 모양과 움직임을 추상화하고, 이에 논리적 추론을 적용하여 나타났다. 이런 기본 개념들은 고대 이집트, 메소포타미아, 고대 인도, 고대 중국 및 고대 그리스의 수학책에서 찾아볼 수 있다. 그리고, 유클리드의 원론에서는 엄밀한 논증이 발견된다. 이런 발전은 그 뒤로도 계속되어, 16세기의 르네상스에 이르러서는 수학적 발전과 과학적 방법들의 상호 작용이 일어나, 혁명적인 연구들이 진행되며 인류 문명에 큰 영향을 미치게 되었다. 그리고, 이는 현재까지도 계속되고 있다.\n",
      "\n",
      "3 오늘날 수학은 자연과학, 공학, 의학뿐만 아니라, 경제학 등의 사회과학에서도 중요한 도구로서도 사용된다. 수학을 이런 분야들에 적용한 응용수학은 그 결과로써 수학 자체의 발전을 이끌고 새로운 분야들을 낳았다. 응용이 아닌 수학 자체의 아름다움과 재미를 추구하며 연구하는 것을 순수수학이라 하는데, 긴 시간이 지난 뒤에 순수수학적 연구를 다른 분야에 응용할 방법이 발견된 경우도 많았다고 한다.\n",
      "\n",
      "2 수학 mathematics는 '배우는 모든 것'라는 뜻의 고대 그리스어 mathematikos에서 유래되었다. 줄여서 math라고 표현하기도 한다.\n",
      "\n",
      "1 수학은 기원전 600년 경에 살았던 탈레스로부터 시작됐다. 하지만 탈레스가 태어나기 전에도 수학을 연구한 사람이 있을 수도 있기 때문에 인류의 역사와 더불어 시작되었다고 할 수 있다. 교역•분배•과세 등의 인류의 사회 생활에 필요한 모든 계산을 수학이 담당해 왔고, 농경 생활에 필수적인 천문 관측과 달력의 제정, 토지의 측량 또한 수학이 직접적으로 관여한 분야이다. 고대 수학을 크게 발전시킨 나라로는 이집트, 인도, 그리스, 중국 등이 있다. 그 중에서도 그리스는 처음으로 수학의 방정식에서 변수를 문자로 쓴 나라이다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(corpus_file, 'r') as in_f:\n",
    "    count = 30\n",
    "    for line in in_f:\n",
    "        print(count, line)\n",
    "        count -= 1\n",
    "        if count == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "exclusive-praise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de40ab54f6ca479cbbf5e92c1be9e927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3957761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 lines: ['▁지미', '▁카터']\n",
      "['▁제임스', '▁얼', '▁\"', '지', '미', '\"', '▁카터', '▁주니어', '(,', '▁1924', '년', '▁10', '월', '▁1', '일', '▁~', '▁)', '는', '▁민주당', '▁출신', '▁미국', '▁39', '번째', '▁대통령', '▁(19', '77', '년', '▁~', '▁1981', '년', ')', '이다', '.']\n",
      "['▁그는', '▁2002', '년', '▁말', '▁인권', '과', '▁중재', '▁역할에', '▁대한', '▁공로를', '▁인정받아', '▁노벨', '▁평화', '상을', '▁받게', '▁되었다', '.']\n",
      "\n",
      "14 lines: ['▁수학']\n",
      "['▁수학', '(', '數', '學', ',', '▁)', '은', '▁양', ',', '▁구조', ',', '▁공간', ',', '▁변화', ',', '▁미', '적', '분', '▁등의', '▁개념을', '▁다루는', '▁학문이다', '.', '▁현대', '▁수학', '은', '▁형식', '▁논', '리를', '▁이용해서', '▁공', '리로', '▁구성된', '▁추상', '적', '▁구조를', '▁연구하는', '▁학문', '으로', '▁여겨', '지기도', '▁한다', '.', '▁수학', '은', '▁그', '▁구조와', '▁발전', '▁과정', '에서는', '▁자연', '과학', '에', '▁속하는', '▁물리', '학을', '▁비롯한', '▁다른', '▁학문', '들과', '▁깊은', '▁연', '관을', '▁맺고', '▁있다', '.', '▁하지만', ',', '▁어느', '▁과학의', '▁분야', '들과는', '▁달리', ',', '▁자연', '계에서', '▁관측', '되지', '▁않는', '▁개념', '들에', '▁대해서', '까지', '▁이론을', '▁일반화', '▁및', '▁추상', '화', '시킬', '▁수', '▁있다는', '▁차이가', '▁있다고', '▁한다', '.', '▁수', '학자들은', '▁그러한', '▁개념', '들에', '▁대해서', '▁추측', '을', '▁하고', ',', '▁적절', '하게', '▁선택', '된', '▁정의', '와', '▁공리', '로부터의', '▁엄', '밀한', '▁연', '역을', '▁통해서', '▁추측', '들의', '▁진', '위를', '▁파악', '한다', '.']\n",
      "['▁수', '학의', '▁기초를', '▁확실히', '▁세우', '기', '▁위해', ',', '▁수리', '논', '리', '학과', '▁집합', '론이', '▁발전', '하였고', ',', '▁이와', '▁더불어', '▁범주', '론이', '▁최근', '에도', '▁발전', '되고', '▁있다', '.', '▁“', '근', '본', '▁위기', '”', '라는', '▁말은', '▁대략', '▁1900', '년에서', '▁1930', '년', '▁사이에', '▁일어난', ',', '▁수', '학의', '▁엄', '밀한', '▁기초', '에', '▁대한', '▁탐', '구를', '▁상징', '적으로', '▁보여주는', '▁말이다', '.', '▁수', '학의', '▁엄', '밀한', '▁기초', '에', '▁대한', '▁몇', '▁가지', '▁의견', '▁불', '일', '치는', '▁오늘날에도', '▁계속되고', '▁있다', '.', '▁수', '학의', '▁기초', '에', '▁대한', '▁위', '기는', '▁그', '▁당시', '▁수많은', '▁논쟁', '에', '▁의해', '▁촉발', '되었으며', ',', '▁그', '▁논쟁', '에는', '▁칸', '토', '어의', '▁집합', '론과', '▁브라우', '어', '-', '힐', '베르트', '▁논쟁이', '▁포함되었다', '.']\n",
      "\n",
      "4 lines: ['▁수학', '▁상수']\n",
      "['▁수학에서', '▁상수', '란', '▁그', '▁값이', '▁변하지', '▁않는', '▁불변', '량으로', ',', '▁변', '수의', '▁반대', '말', '이다', '.', '▁물리', '▁상수', '와는', '▁달리', ',', '▁수학', '▁상', '수는', '▁물리적', '▁측정', '과는', '▁상관없이', '▁정의된다', '.']\n",
      "['▁특정', '▁수학', '▁상수', ',', '▁예를', '▁들면', '▁골', '롬', '-', '딕', '맨', '▁상수', ',', '▁프랑', '세', '즈', '-', '로', '빈', '슨', '▁상수', ',', '▁formula', '_1', ',', '▁레', '비', '▁상수', '같은', '▁상', '수는', '▁다른', '▁수학', '상수', '▁또는', '▁함수', '와', '▁약한', '▁상관', '관계', '▁또는', '▁강한', '▁상관', '관계를', '▁갖는다', '.']\n",
      "\n",
      "10 lines: ['▁문학']\n",
      "['▁문학', '(', '文', '學', ')', '은', '▁언어를', '▁예술적', '▁표현의', '▁제', '재로', '▁삼아', '▁새로운', '▁의미를', '▁창출', '하여', ',', '▁인간과', '▁사회를', '▁진실', '되게', '▁묘사', '하는', '▁예술의', '▁하위', '분야', '이다', '.', '▁간단하게', '▁설명', '하면', ',', '▁언어를', '▁통해', '▁인간의', '▁삶을', '▁미', '적', '(', '美', '的', ')', '으로', '▁형상', '화한', '▁것이라고', '▁볼', '▁수', '▁있다', '.', '▁문학', '은', '▁원래', '▁문예', '(', '文', '藝', ')', '라고', '▁부르는', '▁것이', '▁옳', '으며', ',', '▁문학을', '▁학문의', '▁대상', '으로서', '▁탐구', '하는', '▁학문의', '▁명칭', '▁역시', '▁문예', '학', '이다', '.', '▁문예', '학은', '▁음악', '사', '학', ',', '▁미술', '사', '학', '▁등과', '▁함께', '▁예술', '학의', '▁핵심', '분야', '로서', '▁인문', '학의', '▁하위', '범', '주에', '▁포함된다', '.']\n",
      "['▁반영', '론적', '▁관', '점에', '▁의한', '▁감', '상은', '▁작품을', '▁창작', '된', '▁당시', '▁시대', '▁정', '황', '과', '▁연결', '시켜', '▁감상', '하는', '▁입장', '이고', ',', '▁내재', '적', '▁관', '점의', '▁감', '상은', '▁작품의', '▁형식', ',', '▁내용에', '▁국한', '하여', '▁감상', '하는', '▁것이다', '.', '▁표현', '론적', '▁관', '점의', '▁감', '상은', '▁작가의', '▁전기', '적', '▁사실과', '▁작품을', '▁연결', '시켜', '▁감상', '하는', '▁것이고', ',', '▁수용', '론적', '▁관', '점의', '▁감', '상은', '▁독', '자와', '▁작품을', '▁연결', '시켜', '▁감상', '하는', '▁것을', '▁말한다', '.']\n",
      "\n",
      "10 lines: ['▁나라', '▁목록']\n",
      "['▁이', '▁문서는', '▁나라', '▁목록', '이며', ',', '▁전', '▁세계', '▁20', '6', '개', '▁나라의', '▁각', '▁현황', '과', '▁주권', '▁승인', '▁정보를', '▁개', '요', '▁형태로', '▁나열', '하고', '▁있다', '.']\n",
      "['▁위', '▁목록에', '▁포함되지', '▁않은', '▁다음', '▁국가는', '▁몬테', '비', '데오', '▁협약', '의', '▁모든', '▁조건을', '▁만족', '하지', '▁못', '하거나', ',', '▁자주', '적이고', '▁독립', '적', '임을', '▁주장', '하지', '▁않는', '▁국가이다', '.']\n",
      "\n",
      "['▁화학']\n",
      "['▁화학', '(', '化', '學', ',', '▁)', '은', '▁물질의', '▁성질', ',', '▁조성', ',', '▁구조', ',', '▁변화', '▁및', '▁그에', '▁수반', '하는', '▁에너지의', '▁변화를', '▁연구하는', '▁자연과', '학의', '▁한', '▁분야이다', '.', '▁물리학', '도', '▁역시', '▁물질을', '▁다루는', '▁학문', '이지만', ',', '▁물리학', '이', '▁원', '소와', '▁화합', '물을', '▁모두', '▁포함한', '▁물체의', '▁운동과', '▁에너지', ',', '▁열', '적', '·', '전기', '적', '·', '광', '학적', '·', '기계', '적', '▁속', '성을', '▁다루고', '▁이러한', '▁현상', '으로부터', '▁통일된', '▁이론을', '▁구축', '하려는', '▁것과는', '▁달리', '▁화학', '에서는', '▁물질', '▁자체를', '▁연구', '▁대상으로', '▁한다', '.', '▁화학', '은', '▁이미', '▁존재하는', '▁물질을', '▁이용하여', '▁특정한', '▁목적에', '▁맞는', '▁새로운', '▁물질을', '▁합성', '하는', '▁길을', '▁제공하며', ',', '▁이는', '▁농작', '물의', '▁증', '산', ',', '▁질병의', '▁치료', '▁및', '▁예방', ',', '▁에너지', '▁효율', '▁증대', ',', '▁환경', '오', '염', '▁감소', '▁등', '▁여러', '▁가지', '▁이', '점을', '▁제공한다', '.']\n",
      "['▁유기', '화', '학은', '▁탄', '소로', '▁이루어진', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '▁원래', '▁유기', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '▁지금은', '▁유기', '▁화합', '물의', '▁범위가', '▁크게', '▁넓', '어져', '▁탄소', '▁사슬', '▁또는', '▁탄소', '▁고', '리를', '▁가진', '▁모든', '▁화합', '물을', '▁뜻한다', '.', '▁유기', '화', '학의', '▁오랜', '▁관심', '사는', '▁유기', '▁화합', '물의', '▁합성', '▁메커니즘', '이다', '.', '▁현대에', '▁들어서', '▁핵', '자기', '▁공명', '법과', '▁X', '선', '▁결정', '학', '▁등이', '▁개발되어', '▁유기', '▁화합물', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.']\n"
     ]
    }
   ],
   "source": [
    "# 위키가 주제별로 잘 나눠지는지 여부 확인\n",
    "count = 5\n",
    "\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    doc = [] # 단락 단위로 문서 저장\n",
    "    for line in tqdm(in_f, total=total):\n",
    "        line = line.strip() # line 양쪽에 있는 공백을 제거            ## 1\n",
    "        if line == \"\": # line이 빈 줄인 경우 (새로운 단락을 의미 함)\n",
    "            if 0 < len(doc):                                          ## 3\n",
    "                if 0 < count:                                         ## 4\n",
    "                    count -= 1                                        \n",
    "                    print(len(doc), \"lines:\", doc[0])\n",
    "                    print(doc[1])\n",
    "                    print(doc[-1])\n",
    "                    print()\n",
    "                else:\n",
    "                    break\n",
    "                doc = []\n",
    "        else: # doc에 저장                                            ## 2\n",
    "            pieces = vocab.encode_as_pieces(line)\n",
    "            if 0 < len(pieces):\n",
    "                doc.append(pieces)\n",
    "    if 0 < len(doc): # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "        print(doc[0])\n",
    "        print(doc[1])\n",
    "        print(doc[-1])\n",
    "        doc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-emerald",
   "metadata": {},
   "source": [
    "`create_pretrain_instances()`를 코퍼스에 적용할 수 있는지 몇 라인에 대해서만 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "latest-reliance",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168869d2d59a48debaf6a55e6523a31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3957761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc: 21 instances: 10\n",
      "{'tokens': ['[CLS]', '▁X', '선', '[MASK]', '[MASK]', '▁등이', '▁개발되어', '[MASK]', '▁화합물', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '[MASK]', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '[MASK]', '[MASK]', '▁이루어진', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '▁원래', '▁유기', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [3, 4, 7, 25, 26, 27, 28, 36, 37], 'mask_label': ['▁결정', '학', '▁유기', '▁등도', '▁유기', '화', '학에서', '▁탄', '소로']}\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '▁개발되어', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁있어서', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '[MASK]', '[MASK]', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '▁이루어진', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '▁원래', '▁유기', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [7, 8, 9, 10, 17, 18, 26, 27, 28], 'mask_label': ['▁유기', '▁화합물', '▁분석', '에', '▁플라스틱', ',', '▁유기', '화', '학에서']}\n",
      "\n",
      "doc: 14 instances: 7\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '▁개발되어', '▁유기', '▁화합물', '▁분석', '에', '[MASK]', '[MASK]', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '▁이루어진', '▁화합', '물을', '[MASK]', '▁분', '과', '이다', '.', '▁원래', '▁유기', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '[MASK]', '[MASK]', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [11, 12, 25, 26, 27, 28, 41, 59, 60], 'mask_label': ['▁있어서', '▁매우', '▁등도', '▁유기', '화', '학에서', '▁연구하는', '▁뜻', '하였으나']}\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '[MASK]', '▁달린다', '▁화합물', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '[MASK]', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '▁이루어진', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '▁원래', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '▁지금은', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [6, 7, 14, 47, 48, 49, 50, 51, 62], 'mask_label': ['▁개발되어', '▁유기', '▁방법으로', '▁유기', '▁화합', '물은', '▁식물', '이나', '▁유기']}\n",
      "\n",
      "doc: 4 instances: 2\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '[MASK]', '[MASK]', '▁유기', '[MASK]', '▁분석', '에', '[MASK]', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '[MASK]', '[MASK]', '[MASK]', '▁탄', '소로', '▁이루어진', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '▁원래', '▁유기', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '[MASK]', '[MASK]', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [5, 6, 8, 11, 33, 34, 35, 59, 60], 'mask_label': ['▁등이', '▁개발되어', '▁화합물', '▁있어서', '▁유기', '화', '학은', '▁뜻', '하였으나']}\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '▁개발되어', '▁유기', '▁화합물', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '▁방법으로', '[MASK]', '[MASK]', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '▁이루어진', '▁화합', '물을', '▁연구하는', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁원래', '[MASK]', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '▁지금은', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [15, 16, 25, 42, 43, 44, 45, 47, 62], 'mask_label': ['▁자리잡았다', '.', '▁등도', '▁분', '과', '이다', '.', '▁유기', '▁유기']}\n",
      "\n",
      "doc: 10 instances: 5\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '▁개발되어', '[MASK]', '[MASK]', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '▁이루어진', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '▁원래', '▁유기', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '[MASK]', '[MASK]', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [7, 8, 39, 40, 52, 53, 59, 60, 62], 'mask_label': ['▁유기', '▁화합물', '▁화합', '물을', '▁동물', '로부터', '▁뜻', '하였으나', '▁유기']}\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '▁개발되어', '▁유기', '[MASK]', '[MASK]', '[MASK]', '▁있어서', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '[MASK]', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '[MASK]', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '▁원래', '▁유기', '[MASK]', '[MASK]', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '[MASK]', '[MASK]', '▁뜻', '하였으나', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [8, 9, 10, 25, 38, 48, 49, 57, 58], 'mask_label': ['▁화합물', '▁분석', '에', '▁등도', '▁이루어진', '▁화합', '물은', '▁화합', '물을']}\n",
      "\n",
      "doc: 10 instances: 5\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '▁개발되어', '▁유기', '▁화합물', '▁분석', '에', '▁있어서', '▁매우', '[MASK]', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '[MASK]', '[MASK]', '[MASK]', '▁고분', '자', '물질', '[MASK]', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '▁이루어진', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '▁원래', '▁유기', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '[MASK]', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [13, 19, 20, 21, 22, 23, 24, 25, 61], 'mask_label': ['▁중요한', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '▁지금은']}\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '▁개발되어', '▁유기', '▁화합물', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '▁이루어진', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '[MASK]', '▁유기', '[MASK]', '[MASK]', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [15, 16, 42, 43, 44, 45, 46, 48, 49], 'mask_label': ['▁자리잡았다', '.', '▁분', '과', '이다', '.', '▁원래', '▁화합', '물은']}\n",
      "\n",
      "doc: 31 instances: 15\n",
      "{'tokens': ['[CLS]', '[MASK]', '[MASK]', '▁결정', '학', '▁등이', '▁개발되어', '▁유기', '▁화합물', '▁분석', '에', '▁있어서', '▁매우', '[MASK]', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '[MASK]', '[MASK]', '[MASK]', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '▁이루어진', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '▁원래', '▁유기', '▁화합', '물은', '▁식물', '이나', '[MASK]', '[MASK]', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [1, 2, 11, 13, 26, 27, 28, 52, 53], 'mask_label': ['▁X', '선', '▁있어서', '▁중요한', '▁유기', '화', '학에서', '▁동물', '로부터']}\n",
      "{'tokens': ['[CLS]', '▁X', '선', '[MASK]', '[MASK]', '▁등이', '▁개발되어', '▁유기', '▁화합물', '▁분석', '에', '▁있어서', '[MASK]', '[MASK]', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '[MASK]', '[MASK]', '▁이루어진', '▁화합', '물을', '[MASK]', '▁분', '과', '이다', '.', '▁원래', '▁유기', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [3, 4, 12, 13, 36, 37, 41, 48, 49], 'mask_label': ['▁결정', '학', '▁매우', '▁중요한', '▁탄', '소로', '▁연구하는', '▁화합', '물은']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instance 생성 기능 확인\n",
    "count = 5\n",
    "\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    doc = [] # 단락 단위로 문서 저장\n",
    "    for line in tqdm(in_f, total=total):\n",
    "        line = line.strip()\n",
    "        if line == \"\": # line이 빈줄 일 경우 (새로운 단락을 의미함)\n",
    "            if 0 < len(doc):\n",
    "                instances = create_pretrain_instances(vocab, doc, n_test_seq, 0.15, vocab_list)\n",
    "                # save\n",
    "                print(\"doc:\", len(doc), \"instances:\", len(instances))\n",
    "                print(instances[0])\n",
    "                print(instances[-1])\n",
    "                print()\n",
    "                doc = []\n",
    "                if 0 < count: # 테스트를 위해서 부분 처리 함\n",
    "                    count -= 1\n",
    "                else:\n",
    "                    break\n",
    "        else: # doc에 저장\n",
    "            if 0 < len(pieces):\n",
    "                doc.append(pieces)\n",
    "    if 0 < len(doc): # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "        instances = create_pretrain_instances(doc, 128)\n",
    "\n",
    "        # save\n",
    "        print(\"doc:\", len(doc), \"instances:\", len(instances))\n",
    "        print(instances[0])\n",
    "        print(instances[-1])\n",
    "        print()\n",
    "        doc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-christmas",
   "metadata": {},
   "source": [
    "## make_pretrain_data() : BERT pretrain 데이터셋 생성 메소드\n",
    "전체 전처리 과정을 거쳐 최종적으로 만들어지는 BERT pretrain 데이터셋 생성 메소드는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "valid-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pretrain_data(vocab, in_file, out_file, n_seq, mask_prob=0.15):\n",
    "    \"\"\" pretrain 데이터 생성 \"\"\"\n",
    "    def save_pretrain_instances(out_f, doc):\n",
    "        instances = create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list)\n",
    "        for instance in instances:\n",
    "            out_f.write(json.dumps(instance, ensure_ascii=False))\n",
    "            out_f.write(\"\\n\")\n",
    "            \n",
    "    # 특수문자 7개를 제외한 vocab_list 생성\n",
    "    vocab_list = []\n",
    "    for id in range(7, len(vocab)):\n",
    "        if not vocab.is_unknown(id):\n",
    "            vocab_list.append(vocab.id_to_piece(id))\n",
    "            \n",
    "    # line count 확인\n",
    "    line_cnt = 0\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            line_cnt += 1\n",
    "            \n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        with open(out_file, \"w\") as out_f:\n",
    "            doc = []\n",
    "            for line in tqdm(in_f, total=line_cnt):\n",
    "                line = line.strip()\n",
    "                if line == \"\": # line이 빈줄일 경우 (새로운 단락을 의미함)\n",
    "                    if 0 < len(doc):\n",
    "                        save_pretrain_instances(out_f, doc)\n",
    "                        doc = []\n",
    "                else: # line이 빈줄이 아닐 경우 tokenize 해서 doc에 저장\n",
    "                    pieces = vocab.encode_as_pieces(line)\n",
    "                    if 0 < len(pieces):\n",
    "                        doc.append(pieces)\n",
    "            if 0 < len(doc): # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "                save_pretrain_instances(out_f, doc)\n",
    "                doc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-pizza",
   "metadata": {},
   "source": [
    "이제 약 400만 라인에 해당하는 전체 코퍼스에 대해 `make_pretrain_data()`를 구동해 봅시다. 10여 분 가량 시간이 소요될 수 있습니다.  \n",
    "최종적으로 생성된 데이터셋은 json 포맷으로 저장될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "imported-watts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3bc64b4578400ab1263054957939dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3957761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrain_json_path = os.getenv('HOME')+'/aiffel/bert_pretrain/data/bert_pre_train.json'\n",
    "\n",
    "make_pretrain_data(vocab, corpus_file, pretrain_json_path, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bearing-evidence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "862285"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라인 수\n",
    "total = 0\n",
    "with open(pretrain_json_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        total += 1\n",
    "        \n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-flashing",
   "metadata": {},
   "source": [
    "데이터셋 파일을 만드는 것까지 수행되었습니다. 우리가 다루어야 할 데이터셋은 사이즈가 큽니다. 만들어질 json 데이터파일의 크기가 1.4GB 정도 됩니다. 실제 BERT 학습용의 백 분의 일 사이즈 정도밖에 안 되겠지만 그럼에도 불구하고 이렇게 큰 파일을 로딩하는 함수를 만들 때는 메모리 사용량과 관련해 고려해야 할 점이 있습니다.  \n",
    "  \n",
    "그래서 우리는 `np.memmap`을 사용해서 메모리 사용량을 최소화하는 방법을 시도해 볼 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "athletic-globe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 0,\n",
       " 0,\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_seq = 128\n",
    "# [CLS], tokens_a, [SEP], tokens_b, [SEP]\n",
    "max_seq = n_seq - 3 # special token 개수 제외\n",
    "\n",
    "# 만약 일반적인 Numpy Array에 데이터를 로딩한다면 이렇게 됩니다.\n",
    "# enc_tokens = np.zeros((total, n_seq), np.int32)\n",
    "# dec_tokens = np.zeros((total, n_seq), np.int32)\n",
    "# labels_nsp = np.zeros((total,), np.int32)\n",
    "# labels_mim = np.zeros((total, n_seq), np.int32)\n",
    "\n",
    "# np.memmap을 사용하면 적은 메모리에서도 대용량 처리가 가능합니다.\n",
    "enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "labels_mim = np.memmap(filename='labels_mim.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "enc_tokens[0], enc_tokens[-1], segments[0], segments[-1], labels_nsp[0], labels_nsp[-1], labels_mim[0], labels_mim[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-karma",
   "metadata": {},
   "source": [
    "만들어진 json 파일을 라인 단위로 읽어 들여 `np.memmap`에 로딩해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "foreign-volleyball",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d966af13504bb4b49291c36ed9eb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/862285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['[CLS]', '▁태어났다', '.', '▁조지아', '▁공과', '대학교를', '▁졸업하였다', '.', '▁그', '[MASK]', '▁해군에', '▁들어가', '▁전함', '·', '원자', '력', '·', '잠', '수', '함의', '▁승무', '원으로', '▁일하였다', '.', '▁1953', '년', '▁미국', '▁해군', '▁대', '위로', '▁예편', '하였고', '▁이후', '▁땅', '콩', '·', '면', '화', '▁등을', '▁가', '꿔', '▁많은', '▁돈을', '▁벌', '었다', '.', '▁그의', '▁별명이', '[MASK]', '[MASK]', '[MASK]', '▁농부', '\"', '▁(', 'P', 'ean', 'ut', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁알려졌다', '.', '[SEP]', '▁늦', '되면서', '[MASK]', '▁주', '▁상원', '▁의원', '▁선거에서', '▁낙선', '하나', '▁그', '▁선거가', '▁부정', '선거', '▁', '였', '음을', '▁입증', '하게', '▁되어', '▁당선', '되고', ',', '▁1966', '년', '▁조지아', '▁주', '▁지사', '▁선거에', '▁낙선', '하지만', '[MASK]', '[MASK]', '▁조지아', '▁주', '▁지', '사를', '▁역임했다', '.', '[MASK]', '▁되기', '▁전', '▁조지아', '주', '▁상원의', '원을', '▁두', '번', '▁연', '임', '했으며', ',', '▁1971', '년부터', '[MASK]', '[MASK]', '▁조지아', '▁지', '사로', '▁근무했다', '.', '▁조지아', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [9, 48, 49, 50, 57, 58, 59, 60, 61, 65, 66, 67, 95, 96, 103, 118, 119, 126], 'mask_label': ['▁후', '▁\"', '땅', '콩', '▁F', 'ar', 'mer', ')', '로', '▁1962', '년', '▁조지아', '▁1970', '년', '▁대통령이', '▁1975', '년까지', '▁주지']}\n",
      "enc_token: [5, 1605, 27599, 5551, 14146, 15991, 8637, 27599, 13, 6, 25987, 2247, 15033, 27873, 14475, 27813, 27873, 28196, 27636, 10185, 16285, 1232, 22935, 27599, 4777, 27625, 243, 2780, 14, 1509, 22095, 414, 165, 1697, 28290, 27873, 27703, 27683, 593, 21, 29007, 399, 5540, 813, 17, 27599, 307, 16905, 6, 6, 6, 19041, 27718, 98, 27878, 15784, 2543, 6, 6, 6, 6, 6, 4578, 27599, 4, 4427, 1239, 6, 37, 11234, 2378, 5249, 9858, 3294, 13, 20590, 2386, 2163, 27596, 27671, 969, 8047, 173, 607, 2387, 317, 27604, 3926, 27625, 5551, 37, 18995, 8198, 9858, 1447, 6, 6, 5551, 37, 18, 451, 4267, 27599, 6, 6436, 25, 5551, 27646, 18205, 928, 157, 27821, 61, 27773, 530, 27604, 3372, 523, 6, 6, 5551, 18, 982, 13264, 27599, 5551, 6, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 1\n",
      "label_mim: [    0     0     0     0     0     0     0     0     0    81     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "   103 28313 28290     0     0     0     0     0     0   309   337  5771\n",
      " 27616 27603     0     0     0  3715 27625  5551     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0  1921\n",
      " 27625     0     0     0     0     0     0  4864     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0  3409   673\n",
      "     0     0     0     0     0     0  5053     0]\n",
      "\n",
      "{'tokens': ['[CLS]', '▁1976', '년', '▁대통령', '▁선거에', '▁민주당', '▁후보로', '▁출마하여', '▁도덕', '주의', '▁정책으로', '▁내세워', ',', '[MASK]', '[MASK]', '▁누르고', '▁당선되었다', '.', '▁카터', '▁대통령은', '▁에너지', '▁개발을', '▁촉구', '했으나', '▁공화', '당의', '▁반대로', '▁무산되었다', '.', '[SEP]', '▁카', '터는', '▁이집', '트와', '▁이스라엘', '을', '▁조정', '하여', ',', '▁캠프', '▁데이비', '드에서', '▁안', '와', '르', '[MASK]', '[MASK]', '▁대통령과', '▁메', '나', '헴', '▁베', '긴', '▁수상', '과', '▁함께', '▁중동', '[MASK]', '▁위한', '▁캠프', '데이', '비', '드', '▁협정을', '▁체결했다', '.', '▁그러나', '▁이것은', '▁공화', '당과', '▁미국의', '▁유대인', '[MASK]', '▁반발을', '▁일으켰다', '.', '▁1979', '년', '▁백악', '관에서', '▁양국', '▁간의', '▁평화', '조약', '으로', '[MASK]', '[MASK]', '[MASK]', '▁또한', '▁소련과', '▁제', '2', '차', '▁전략', '▁무기', '[MASK]', '▁협', '상에', '▁조인', '했다', '.', '▁카', '터는', '[MASK]', '[MASK]', '[MASK]', '▁당시', '[MASK]', '▁등', '▁인권', '▁후진', '국의', '▁국민들의', '▁인', '권을', '▁지키기', '▁위해', '▁노력', '했으며', ',', '[MASK]', '▁이후', '▁계속해서', '▁도덕', '정', '치를', '▁내세', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [13, 14, 45, 46, 51, 52, 57, 72, 73, 85, 86, 87, 95, 103, 104, 105, 107, 120], 'mask_label': ['▁포', '드를', '▁사다', '트', '▁베', '긴', '▁평화를', '▁단체의', '▁반발을', '▁이끌', '어졌다', '.', '▁제한', '▁1970', '년대', '▁후반', '▁대한민국', '▁취임']}\n",
      "enc_token: [5, 3306, 27625, 663, 8198, 4867, 4896, 19160, 6244, 238, 22033, 19990, 27604, 6, 6, 10071, 7965, 27599, 25250, 5906, 3634, 8085, 9747, 1003, 4460, 1547, 4771, 18474, 27599, 4, 207, 4612, 2703, 3604, 3426, 27607, 3358, 54, 27604, 10251, 3640, 3552, 172, 27665, 27699, 6, 6, 13799, 334, 27637, 29887, 271, 28099, 1011, 27644, 280, 8021, 6, 521, 10251, 4282, 27694, 27681, 15990, 19102, 27599, 330, 1487, 4460, 4040, 679, 7455, 6, 21408, 6564, 27599, 2995, 27625, 10312, 6749, 13195, 2714, 2793, 8993, 9, 6, 6, 6, 276, 23197, 30, 27619, 27751, 2835, 3841, 6, 617, 1824, 15876, 31, 27599, 207, 4612, 6, 6, 6, 316, 6, 50, 5636, 17092, 137, 18896, 42, 917, 15177, 231, 3375, 530, 27604, 6, 165, 6357, 6244, 27642, 1233, 5890, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 1\n",
      "label_mim: [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0   119  1486     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0  7025 27677     0\n",
      "     0     0     0   271 28099     0     0     0     0 14237     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      " 15747 21408     0     0     0     0     0     0     0     0     0     0\n",
      "     0  1435  2521 27599     0     0     0     0     0     0     0  1956\n",
      "     0     0     0     0     0     0     0  1921   596  1840     0   410\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "  2659     0     0     0     0     0     0     0]\n",
      "\n",
      "{'tokens': ['[CLS]', ',', '▁1982', '년까지', '▁3', '단', '계에', '▁걸쳐', '▁주한미', '군을', '▁철수', '하기로', '▁했다', '.', '▁그러나', '▁주한미', '군', '사령', '부와', '▁정보', '기관', '·', '의', '회의', '[MASK]', '[MASK]', '▁부딪', '혀', '▁주한미', '군은', '▁완전', '철', '수', '▁대신', '▁6,000', '명을', '▁감축', '하는', '▁데', '▁그쳤다', '.', '▁또한', '▁박정희', '▁정권의', '▁인권', '▁문제', '▁등', '과의', '▁논란', '으로', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁냈', '으나', ',', '▁1979', '년', '▁6', '월', '▁하', '순', ',', '▁대한민국을', '▁방문하여', '▁관계가', '▁다소', '▁회복', '되었다', '.', '[SEP]', '▁그러나', '[MASK]', '▁이란', '▁미국', '▁대사관', '[MASK]', '[MASK]', '▁사건에서', '▁인', '질', '[MASK]', '▁실패를', '▁이유로', '[MASK]', '[MASK]', '▁대통령', '▁선거에서', '▁공화', '당의', '▁로', '널드', '▁레이', '건', '▁후보', '에게', '▁', '져', '▁결국', '▁재', '선에', '▁실패했다', '.', '▁또한', '▁임기', '[MASK]', '▁터', '진', '▁소련의', '▁아프가니스탄', '▁침공', '▁사건으로', '▁인해', '▁1980', '년', '[MASK]', '▁올림픽에', '▁반공', '국가', '들의', '[MASK]', '[MASK]', '[MASK]', '▁내세', '웠다', '.', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [24, 25, 50, 51, 52, 53, 73, 74, 77, 78, 82, 85, 86, 106, 116, 121, 122, 123], 'mask_label': ['▁반', '대에', '▁불', '협', '화', '음을', '▁주', '▁이란', '▁인', '질', '▁구출', '▁1980', '년', '▁말기에', '▁하계', '▁보이', '콧', '을']}\n",
      "enc_token: [5, 27604, 2760, 673, 49, 27737, 1949, 1633, 24438, 1262, 5337, 2390, 345, 27599, 330, 24438, 27722, 3069, 2576, 1071, 1468, 27873, 27601, 511, 6, 6, 11574, 28178, 24438, 941, 4626, 27917, 27636, 1083, 23453, 859, 26346, 38, 189, 11330, 27599, 276, 5298, 13574, 5636, 550, 50, 786, 2408, 9, 6, 6, 6, 6, 15139, 191, 27604, 2995, 27625, 125, 27662, 27, 27946, 27604, 16187, 14905, 4857, 5421, 3332, 43, 27599, 4, 330, 6, 3290, 243, 18590, 6, 6, 23937, 42, 27892, 6, 22684, 1827, 6, 6, 663, 5249, 4460, 1547, 194, 8631, 1169, 27803, 958, 113, 27596, 27944, 875, 174, 2087, 9510, 27599, 276, 11034, 6, 870, 27713, 5569, 7676, 3232, 6322, 751, 1640, 27625, 6, 5825, 13948, 4398, 247, 6, 6, 6, 5890, 1853, 27599, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 0\n",
      "label_mim: [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "   141   867     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0   128 27993 27683   969     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0    37  3290     0     0    42 27892     0     0     0 11560     0\n",
      "     0  1640 27625     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0 12145     0\n",
      "     0     0     0     0     0     0     0     0  2219     0     0     0\n",
      "     0  3052 28805 27607     0     0     0     0]\n",
      "\n",
      "{'tokens': ['[CLS]', ',', '▁박정희', '▁대통령이', '▁기묘', '韶', '▁중앙정보', '부', '장에', '▁의해', '▁살해', '된', '▁것에', '▁대해', '▁그는', '▁이', '▁사건으로', '▁큰', '▁충격을', '▁받았으며', ',', '[MASK]', '[MASK]', '▁밴', '스', '▁국무', '장', '관을', '▁조', '문사', '절로', '▁파견했다', '.', '▁12', '·', '12', '[MASK]', '▁반란', '과', '▁5.', '17', '▁쿠데타', '에', '[MASK]', '▁초기에는', '▁강하게', '▁비난', '했으나', ',', '▁미국', '[MASK]', '▁신군', '부를', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁있었고', '▁결국', '▁묵', '인', '하는', '[MASK]', '▁태도를', '▁보이게', '▁됐다', '.', '[SEP]', '▁퇴임', '▁이후', '▁민간', '▁자원을', '▁적극', '▁활용한', '▁비영리', '▁기구', '인', '▁카터', '▁재', '단을', '▁설립한', '[MASK]', '[MASK]', '▁실현', '을', '▁위해', '▁제', '▁3', '세계의', '[MASK]', '[MASK]', '▁활동', '▁및', '▁기니', '▁벌', '레', '에', '▁의한', '▁드라', '쿤', '쿠르', '스', '▁질병', '▁방', '재를', '▁장안', '▁힘썼다', '.', '▁미국의', '▁빈곤', '층', '▁지원', '▁활동', ',', '▁사랑의', '▁집', '짓', '기', '▁운동', ',', '▁국제', '▁분쟁', '▁중재', '▁등의', '▁활동도', '▁했다', '.', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [4, 5, 21, 22, 36, 43, 50, 53, 54, 55, 56, 62, 77, 81, 82, 89, 90, 105], 'mask_label': ['▁김재', '규', '▁사이', '러스', '▁군사', '▁대해', '▁정부가', '▁설득', '하는데', ',', '▁한계가', '▁듯한', '▁카터', '▁뒤', '▁민주주의', '▁선거', '▁감시', '▁위해']}\n",
      "enc_token: [5, 27604, 5298, 4864, 27387, 31931, 18525, 27638, 1312, 355, 2591, 27711, 2057, 433, 202, 8, 6322, 459, 10688, 5325, 27604, 6, 6, 1228, 27626, 4444, 27651, 1657, 53, 27181, 17544, 26520, 27599, 196, 27873, 1335, 6, 2342, 27644, 11262, 1695, 14078, 27600, 6, 6797, 7015, 3560, 1003, 27604, 243, 6, 26826, 1191, 6, 6, 6, 6, 2492, 875, 5374, 27628, 38, 6, 11162, 16915, 3842, 27599, 4, 13826, 165, 3174, 17304, 2929, 20639, 16068, 6673, 27628, 25250, 174, 1574, 7301, 6, 6, 5031, 27607, 231, 30, 49, 21655, 6, 6, 375, 228, 18137, 813, 27740, 27600, 1332, 17378, 28956, 16453, 27626, 5225, 95, 4445, 15108, 19607, 27599, 679, 14197, 28083, 770, 375, 27604, 14003, 313, 28333, 27614, 887, 27604, 605, 4476, 13267, 507, 27328, 345, 27599, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 1\n",
      "label_mim: [    0     0     0     0  9918 27958     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0   328  2086     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "  1250     0     0     0     0     0     0   433     0     0     0     0\n",
      "     0     0  3840     0     0  5523  1294 27604 20984     0     0     0\n",
      "     0     0 10180     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0 25250     0     0     0   339  9889     0\n",
      "     0     0     0     0     0   822  7049     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0   231     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "\n",
      "{'tokens': ['[CLS]', '[MASK]', '[MASK]', '▁카터', '▁행정부', '▁이후', '▁미국이', '▁북', '핵', '▁위기', ',', '▁코소보', '▁전쟁', ',', '▁이라크', '▁전쟁과', '▁같이', '▁미국이', '[MASK]', '[MASK]', '▁최후', '로', '▁선택하는', '▁전통적', '▁사고를', '▁버리고', '▁나이에', '▁행동을', '▁선행', '하는', '▁행위에', '▁대해', '▁깊은', '▁유', '감을', '▁표시', '▁하며', '▁미국의', '▁군사적', '▁활동에', '▁강한', '▁반대', '▁입장을', '▁보이고', '▁있다', '.', '[SEP]', '▁특히', '▁국제', '▁분쟁', '[MASK]', '▁위해', '▁북한의', '▁김일성', ',', '▁아이', '티의', '▁세', '드', '라스', '▁장군', ',', '▁팔', '레인', '스타', '인의', '[MASK]', '[MASK]', '[MASK]', '▁보스', '니아의', '▁세르비아', '계', '▁정권', '▁같이', '▁미국', '▁정부에', '▁대해', '▁협상을', '▁거부', '하면서', '▁사태', '의', '▁위기를', '▁초래', '한', '▁인물', '▁및', '▁단체를', '▁직접', '[MASK]', '▁분쟁', '의', '[MASK]', '▁근본적으로', '▁해결하기', '▁위해', '▁힘썼다', '.', '▁이', '▁과정에서', '▁미국', '▁행정', '부와', '▁갈등을', '[MASK]', '▁했지만', ',', '▁전직', '▁대통령의', '▁권한', '과', '[MASK]', '[MASK]', '[MASK]', '▁인사', '들의', '[MASK]', '[MASK]', '[MASK]', '▁나갔다', '.', '▁1978', '년에', '▁채', '결', '된', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 2, 18, 19, 26, 50, 66, 67, 68, 90, 93, 105, 112, 113, 114, 117, 118, 119], 'mask_label': ['▁카', '터는', '▁군사적', '▁행동을', '▁군사적', '▁조정을', '▁하', '마스', ',', '▁만나', '▁원인을', '▁보이기도', '▁재', '야', '▁유명', '▁활약으로', '▁해결', '해']}\n",
      "enc_token: [5, 6, 6, 25250, 21862, 165, 8424, 251, 28166, 10622, 27604, 26202, 506, 27604, 6157, 17305, 733, 8424, 6, 6, 12241, 27603, 26028, 15644, 13098, 8275, 7441, 5616, 16374, 38, 19690, 433, 4508, 46, 2196, 2466, 1368, 679, 9641, 8253, 2632, 1216, 5168, 7010, 28, 27599, 4, 698, 605, 4476, 6, 231, 9305, 11444, 27604, 520, 10694, 74, 27681, 1951, 4379, 27604, 961, 5346, 936, 692, 6, 6, 6, 6076, 4174, 4543, 27704, 5752, 733, 243, 6633, 433, 12149, 2324, 421, 4597, 27601, 11239, 8200, 27612, 1178, 228, 19762, 1069, 6, 4476, 27601, 6, 24806, 13425, 231, 19607, 27599, 8, 2208, 243, 895, 2576, 12627, 6, 3379, 27604, 5605, 5744, 3753, 27644, 6, 6, 6, 3329, 247, 6, 6, 6, 9946, 27599, 3331, 169, 481, 27783, 27711, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 1\n",
      "label_mim: [    0   207  4612     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0  9641  5616     0     0     0     0\n",
      "     0     0  9641     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0 23144     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0    27  3678 27604     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0  2142     0     0 13635     0     0\n",
      "     0     0     0     0     0     0     0     0     0 23828     0     0\n",
      "     0     0     0     0   174 27775   939     0     0 17462  2317 27645\n",
      "     0     0     0     0     0     0     0     0]\n",
      "\n",
      "{'tokens': ['[CLS]', '▁북한에', '▁대한', '▁미국의', '▁군사적', '▁행동이', '▁임', '박', '했으나', ',', '[MASK]', '▁전직', '▁대통령', '으로는', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁미국과', '▁북', '[MASK]', '▁중재', '에', '▁큰', '▁기여를', '▁해', '▁위기를', '▁해결', '했다는', '[MASK]', '▁받았다', '.', '▁또한', '▁이', '▁때', '[MASK]', '▁대통령과', '맏', '▁주', '석의', '▁만남', '을', '▁주선', '했다', '.', '▁하지만', '▁그로부터', '▁수', '주일', '▁후', '▁김일', '성이', '▁갑자기', '▁사망하여', '▁김일', '성과', '▁김영삼', '의', '▁정상회담', '은', '▁이루어지지', '▁못했다', '.', '[SEP]', '▁미국의', '▁관', '타나', '모', '▁수용', '소', '▁문제', ',', '▁세계의', '▁인권', '문제', '에서도', '▁관심이', '▁깊', '어', '▁유엔', '에', '▁유엔', '인권', '고등', '판', '무', '관의', '▁제도를', '▁시행', '하도록', '▁노력', '하여', '▁독재', '자들의', '▁인권', '▁유', '린', '에', '▁대해', '▁제', '약을', '▁하고', ',', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁만드는', '▁데', '▁기여', '하여', '▁독재', '자들', '▁같은', '▁인권', '유', '린', '범죄', '자를', '▁재판', '소로', '▁회', '부', '하여', '▁국제적인', '▁처벌을', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [10, 14, 15, 16, 17, 18, 21, 30, 31, 32, 35, 36, 38, 65, 104, 105, 106, 107], 'mask_label': ['▁미국', '▁처음으로', '▁북한', '을', '▁방문', '하고', '▁양국의', '▁평가를', '▁받았다', '.', '▁때', '▁김영삼', '▁김일성', '▁미국의', '▁국제', '형사', '재판', '소를']}\n",
      "enc_token: [5, 25086, 92, 679, 9641, 18507, 273, 27914, 1003, 27604, 6, 5605, 663, 1030, 6, 6, 6, 6, 6, 5672, 251, 6, 13267, 27600, 459, 13856, 87, 11239, 2317, 2351, 6, 772, 27599, 276, 8, 84, 6, 13799, 29164, 37, 5361, 11842, 27607, 25754, 31, 27599, 589, 14313, 19, 10106, 81, 4636, 684, 5908, 26809, 4636, 1693, 9133, 27601, 27509, 27613, 13475, 2041, 27599, 4, 679, 88, 8011, 27716, 2237, 27688, 550, 27604, 5467, 5636, 5515, 643, 8181, 1910, 27633, 3708, 27600, 3708, 12972, 5059, 27841, 27725, 2429, 6520, 2404, 1816, 3375, 54, 7559, 2653, 5636, 46, 27870, 27600, 433, 30, 3297, 644, 27604, 6, 6, 6, 6, 3002, 189, 2187, 54, 7559, 3989, 226, 5636, 27690, 27870, 8822, 690, 2474, 2661, 270, 27638, 54, 12835, 19956, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 1\n",
      "label_mim: [    0     0     0     0     0     0     0     0     0     0   243     0\n",
      "     0     0  1307  1876 27607  2017    48     0     0 25764     0     0\n",
      "     0     0     0     0     0     0  4549   772 27599     0     0    84\n",
      "  9133     0 11444     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0   679     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0   605 17905  4731  1358\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 라인 단위로 처리\n",
    "with open(pretrain_json_path, \"r\") as f:\n",
    "    for i, line in enumerate(tqdm(f, total=total)):\n",
    "        if 5 < i: # 테스트를 위해서 5개만 확인\n",
    "            break\n",
    "        data = json.loads(line)\n",
    "        # encoder token\n",
    "        enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "        enc_token += [0] * (n_seq - len(enc_token))\n",
    "        # segment\n",
    "        segment = data[\"segment\"]\n",
    "        segment += [0] * (n_seq - len(segment))\n",
    "        # nsp label\n",
    "        label_nsp = data[\"is_next\"]\n",
    "        # mim label\n",
    "        mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
    "        mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
    "        label_mim = np.full(n_seq, dtype=np.int, fill_value=0)\n",
    "        label_mim[mask_idx] = mask_label\n",
    "        \n",
    "        print(data)\n",
    "        print(\"enc_token:\", enc_token)\n",
    "        print(\"segment:\", segment)\n",
    "        print(\"label_nsp:\", label_nsp)\n",
    "        print(\"label_mim:\", label_mim)\n",
    "        print()\n",
    "        \n",
    "        assert len(enc_token) == len(segment) == len(label_mim) == n_seq\n",
    "        \n",
    "        enc_tokens[i] = enc_token\n",
    "        segments[i] = segment\n",
    "        labels_nsp[i] = label_nsp\n",
    "        labels_mim[i] = label_mim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-anniversary",
   "metadata": {},
   "source": [
    "### load_pre_train_data() : 학습에 필요한 데이터를 로딩하는 함수\n",
    "`np.memmap`을 사용해 메모리 효율적으로 만들어진 데이터를 로딩하는 함수를 아래와 같이 구성하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "absent-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pre_train_data(vocab, filename, n_seq, count=None):\n",
    "    \"\"\"\n",
    "    학습에 필요한 데이터를 로드\n",
    "    :param vocab: vocab\n",
    "    :param filename: 전처리된 json 파일\n",
    "    :param n_seq: 시퀀스 길이 (number of sequence)\n",
    "    :param count: 데이터 수 제한 (None이면 전체)\n",
    "    :return enc_tokens: encoder inputs\n",
    "    :return segments: segment inputs\n",
    "    :return labels_nsp: nsp labels\n",
    "    :return labels_mlm: mlm labels\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            total += 1\n",
    "            # 데이터 수 제한\n",
    "            if count is not None and count <= total:\n",
    "                break\n",
    "    \n",
    "    # np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
    "    enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "    labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i, line in enumerate(tqdm(f, total=total)):\n",
    "            if total <= i:\n",
    "                print(\"data load early stop\", total, i)\n",
    "                break\n",
    "            data = json.loads(line)\n",
    "            # encoder token\n",
    "            enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "            enc_token += [0] * (n_seq - len(enc_token))\n",
    "            # segment\n",
    "            segment = data[\"segment\"]\n",
    "            segment += [0] * (n_seq - len(segment))\n",
    "            # nsp label\n",
    "            label_nsp = data[\"is_next\"]\n",
    "            # mlm label\n",
    "            mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
    "            mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
    "            label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
    "            label_mlm[mask_idx] = mask_label\n",
    "\n",
    "            assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "            enc_tokens[i] = enc_token\n",
    "            segments[i] = segment\n",
    "            labels_nsp[i] = label_nsp\n",
    "            labels_mlm[i] = label_mlm\n",
    "\n",
    "    return (enc_tokens, segments), (labels_nsp, labels_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "social-prophet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefbb4501ddf4bacb10bf872b60b59ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load early stop 128000 128000\n"
     ]
    }
   ],
   "source": [
    "# 128000건만 메모리에 로딩\n",
    "pre_train_inputs, pre_train_labels = load_pre_train_data(vocab, pretrain_json_path, 128, count=128000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "incoming-sheffield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memmap([    5,  1605, 27599,  5551, 14146, 15991,  8637, 27599,    13,\n",
       "             6, 25987,  2247, 15033, 27873, 14475, 27813, 27873, 28196,\n",
       "         27636, 10185, 16285,  1232, 22935, 27599,  4777, 27625,   243,\n",
       "          2780,    14,  1509, 22095,   414,   165,  1697, 28290, 27873,\n",
       "         27703, 27683,   593,    21, 29007,   399,  5540,   813,    17,\n",
       "         27599,   307, 16905,     6,     6,     6, 19041, 27718,    98,\n",
       "         27878, 15784,  2543,     6,     6,     6,     6,     6,  4578,\n",
       "         27599,     4,  4427,  1239,     6,    37, 11234,  2378,  5249,\n",
       "          9858,  3294,    13, 20590,  2386,  2163, 27596, 27671,   969,\n",
       "          8047,   173,   607,  2387,   317, 27604,  3926, 27625,  5551,\n",
       "            37, 18995,  8198,  9858,  1447,     6,     6,  5551,    37,\n",
       "            18,   451,  4267, 27599,     6,  6436,    25,  5551, 27646,\n",
       "         18205,   928,   157, 27821,    61, 27773,   530, 27604,  3372,\n",
       "           523,     6,     6,  5551,    18,   982, 13264, 27599,  5551,\n",
       "             6,     4], dtype=int32),\n",
       " memmap([    5,  2191, 27599,  5078,    81, 27604,   342,  4812, 27625,\n",
       "           294, 14456,     6, 24930,  2540, 27600,   488,  4871,  2524,\n",
       "         13358,   171, 27599,   330, 27604, 14456,     6,  4842, 27682,\n",
       "         27625,  2131, 14135,  9943,   761, 28254,   658,   171, 27599,\n",
       "            13,     6, 13069, 11312,   496,  8020,  1910, 27633,  4216,\n",
       "           664,   926,  5238,  1053,  5583, 27614,  2419,  2470, 27604,\n",
       "         21622, 27602,   838, 15403, 27760,   824,  3525, 13998,  7619,\n",
       "         27599,     4,   371, 27604,    29, 28018, 27793,  1326, 27787,\n",
       "            66,   412, 22289,    28, 27599,  1326,  5884,     6,  2573,\n",
       "            66,  1599, 27653,   639,  3883,   353, 27599, 17506,  5263,\n",
       "          1326,  5884,    19,   402,     6,     6,     6,     6,     6,\n",
       "          2742,    31, 27599,     6, 16343,     6,     6,     6,     6,\n",
       "             6,     6,     6,     6, 10603, 27616,     9, 25545,  1599,\n",
       "         27653,   639,   254,   238,   787,  2654,   784, 27604,  1925,\n",
       "           259,     4], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " 1,\n",
       " 0,\n",
       " memmap([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            81,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,   103, 28313, 28290,     0,     0,     0,\n",
       "             0,     0,     0,   309,   337,  5771, 27616, 27603,     0,\n",
       "             0,     0,  3715, 27625,  5551,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,  1921, 27625,     0,     0,\n",
       "             0,     0,     0,     0,  4864,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,  3409,   673,     0,     0,     0,     0,     0,     0,\n",
       "          5053,     0], dtype=int32),\n",
       " memmap([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,    89,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0, 15170,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,  4031,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0, 11497,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,   231, 11497,  9933, 27607,  2042,\n",
       "             0,     0,     0, 11364,     0,  1911, 27604,    68, 27650,\n",
       "         27617,  3065, 28116, 27601,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0], dtype=int32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 처음과 마지막 확인\n",
    "pre_train_inputs[0][0], pre_train_inputs[0][-1], pre_train_inputs[1][0], pre_train_inputs[1][-1], pre_train_labels[0][0], pre_train_labels[0][-1], pre_train_labels[1][0], pre_train_labels[1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-crest",
   "metadata": {},
   "source": [
    "## BERT 모델 구현\n",
    "BERT가 transformer encoder로 구현되어 있다는 것은 잘 알고 계시리라 생각합니다. 이미 여러 번 다뤄보셨을 transformer의 모델 구조와 거의 유사하지만, 아래 그림과 같이 3개의 embedding 레이어를 가진다는 점에 유의해야 합니다."
   ]
  },
  {
   "attachments": {
    "GN-8-P-02.max-800x600.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "normal-postcard",
   "metadata": {},
   "source": [
    "![GN-8-P-02.max-800x600.png](attachment:GN-8-P-02.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-accreditation",
   "metadata": {},
   "source": [
    "우선 몇 가지 유틸리티 함수를 정의하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cognitive-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    pad mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: pad mask (pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_ahead_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    ahead mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    n_seq = tf.shape(tokens)[1]\n",
    "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
    "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
    "    pad_mask = get_pad_mask(tokens, i_pad)\n",
    "    mask = tf.maximum(ahead_mask, pad_mask)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "demographic-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def gelu(x):\n",
    "    \"\"\"\n",
    "    gelu activation 함수\n",
    "    :param x: 입력 값\n",
    "    :return: gelu activation result\n",
    "    \"\"\"\n",
    "    return 0.5 * x * (1 + K.tanh(x * 0.7978845608 * (1 + 0.044715 * x * x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "available-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_initializer(stddev=0.02):\n",
    "    \"\"\"\n",
    "    parameter initializer 생성\n",
    "    :param stddev: 생성할 랜덤 변수의 표준편차\n",
    "    \"\"\"\n",
    "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
    "\n",
    "\n",
    "def bias_initializer():\n",
    "    \"\"\"\n",
    "    bias initializer 생성\n",
    "    \"\"\"\n",
    "    return tf.zeros_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ecological-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    \"\"\"\n",
    "    json을 config 형태로 사용하기 위한 Class\n",
    "    :param dict: config dictionary\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        \"\"\"\n",
    "        file에서 Config를 생성 함\n",
    "        :param file: filename\n",
    "        \"\"\"\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-proof",
   "metadata": {},
   "source": [
    "이제 본격적으로 embedding 레이어를 쌓아나가겠습니다. 아래는 Token Embedding의 구현입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cooked-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Weighed Shaed Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.n_vocab = config.n_vocab\n",
    "        self.d_model = config.d_model\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        shared weight 생성\n",
    "        :param input_shape: Tensor Shape (not used)\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"shared_embedding_weight\"):\n",
    "            self.shared_weights = self.add_weight(\n",
    "                \"weights\",\n",
    "                shape=[self.n_vocab, self.d_model],\n",
    "                initializer=kernel_initializer()\n",
    "            )\n",
    "\n",
    "    def call(self, inputs, mode=\"embedding\"):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :param mode: 실행 모드\n",
    "        :return: embedding or linear 실행 결과\n",
    "        \"\"\"\n",
    "        # mode가 embedding일 경우 embedding lookup 실행\n",
    "        if mode == \"embedding\":\n",
    "            return self._embedding(inputs)\n",
    "        # mode가 linear일 경우 linear 실행\n",
    "        elif mode == \"linear\":\n",
    "            return self._linear(inputs)\n",
    "        # mode가 기타일 경우 오류 발생\n",
    "        else:\n",
    "            raise ValueError(f\"mode {mode} is not valid.\")\n",
    "    \n",
    "    def _embedding(self, inputs):\n",
    "        \"\"\"\n",
    "        embedding lookup\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
    "        return embed\n",
    "\n",
    "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
    "        \"\"\"\n",
    "        linear 실행\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        n_batch = tf.shape(inputs)[0]\n",
    "        n_seq = tf.shape(inputs)[1]\n",
    "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
    "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
    "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-carter",
   "metadata": {},
   "source": [
    "Positional Embedding 레이어는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "sporting-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Positional Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"position_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :return embed: positional embedding lookup 결과\n",
    "        \"\"\"\n",
    "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
    "        embed = self.embedding(position)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-stuff",
   "metadata": {},
   "source": [
    "상대적으로 매우 간단한 Segment Embedding은 별도의 레이어를 구현하지 않고 BERT 클래스에서 간단히 포함하도록 하겠습니다.  \n",
    "  \n",
    "아래는 ScaleDotProductAttention과 이를 활용한 MultiHeadAttention입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "forbidden-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Scale Dot Product Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
    "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        attn_scale = tf.math.divide(attn_score, scale)\n",
    "        attn_scale -= 1.e9 * attn_mask\n",
    "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
    "        attn_out = tf.matmul(attn_prob, V)\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "judicial-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi Head Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"multi_head_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.d_model = config.d_model\n",
    "        self.n_head = config.n_head\n",
    "        self.d_head = config.d_head\n",
    "\n",
    "        # Q, K, V input dense layer\n",
    "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        # Scale Dot Product Attention class\n",
    "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
    "        # output dense layer\n",
    "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        # reshape Q, K, V, attn_mask\n",
    "        batch_size = tf.shape(Q)[0]\n",
    "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
    "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
    "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
    "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)  # (bs, n_head, Q_len, d_head)\n",
    "        # transpose and liner\n",
    "        attn_out_m = tf.transpose(attn_out, perm=[0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
    "        attn_out = tf.reshape(attn_out_m, [batch_size, -1, config.n_head * config.d_head])  # (bs, Q_len, d_model)\n",
    "        attn_out = self.W_O(attn_out) # (bs, Q_len, d_model)\n",
    "\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-rendering",
   "metadata": {},
   "source": [
    "이를 바탕으로 transformer encoder 레이어를 구성하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "residential-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Wise Feed Forward Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"feed_forward\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: inputs\n",
    "        :return ff_val: feed forward 실행 결과\n",
    "        \"\"\"\n",
    "        ff_val = self.W_2(self.W_1(inputs))\n",
    "        return ff_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "precise-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder Layer Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"encoder_layer\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(config)\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.ffn = PositionWiseFeedForward(config)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    " \n",
    "    def call(self, enc_embed, self_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param enc_embed: enc_embed 또는 이전 EncoderLayer의 출력\n",
    "        :param self_mask: enc_tokens의 pad mask\n",
    "        :return enc_out: EncoderLayer 실행 결과\n",
    "        \"\"\"\n",
    "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
    "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
    "\n",
    "        ffn_val = self.ffn(norm1_val)\n",
    "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
    "\n",
    "        return enc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-replica",
   "metadata": {},
   "source": [
    "최종적으로 구성할 BERT 레이어는 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "accessory-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    BERT Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"bert\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.i_pad = config.i_pad\n",
    "        self.embedding = SharedEmbedding(config)\n",
    "        self.position = PositionalEmbedding(config)\n",
    "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: (enc_tokens, segments)\n",
    "        :return logits: dec_tokens에 대한 다음 토큰 예측 결과 logits\n",
    "        \"\"\"\n",
    "        enc_tokens, segments = inputs\n",
    "\n",
    "        enc_self_mask = tf.keras.layers.Lambda(get_pad_mask, output_shape=(1, None), name='enc_self_mask')(enc_tokens, self.i_pad)\n",
    "\n",
    "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
    "\n",
    "        enc_out = self.dropout(enc_embed)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
    "\n",
    "        logits_cls = enc_out[:,0]\n",
    "        logits_lm = self.embedding(enc_out, mode=\"linear\")\n",
    "        return logits_cls, logits_lm\n",
    "    \n",
    "    def get_embedding(self, tokens, segments):\n",
    "        \"\"\"\n",
    "        token embedding, position embedding lookup\n",
    "        :param tokens: 입력 tokens\n",
    "        :param segments: 입력 segments\n",
    "        :return embed: embedding 결과\n",
    "        \"\"\"\n",
    "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
    "        embed = self.norm(embed)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-karaoke",
   "metadata": {},
   "source": [
    "BERT 레이어를 바탕으로 최종적으로 만들어질 pretrain용 BERT 모델 구성은 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "incredible-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Layer class 정의\n",
    "class PooledOutput(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, n_output, name=\"pooled_output\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(config.d_model, activation=tf.nn.tanh, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.dense2 = tf.keras.layers.Dense(n_output, use_bias=False, activation=tf.nn.softmax, name=\"nsp\", kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    " \n",
    "    def call(self, inputs):\n",
    "        outputs = self.dense1(inputs)\n",
    "        outputs = self.dense2(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "labeled-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_pre_train(config):\n",
    "    enc_tokens = tf.keras.layers.Input((None,), name=\"enc_tokens\")\n",
    "    segments = tf.keras.layers.Input((None,), name=\"segments\")\n",
    "\n",
    "    bert = BERT(config)\n",
    "    logits_cls, logits_lm = bert((enc_tokens, segments))\n",
    "\n",
    "    logits_cls = PooledOutput(config, 2, name=\"pooled_nsp\")(logits_cls)\n",
    "    outputs_nsp = tf.keras.layers.Softmax(name=\"nsp\")(logits_cls)\n",
    "\n",
    "    outputs_mlm = tf.keras.layers.Softmax(name=\"mlm\")(logits_lm)\n",
    "\n",
    "    model = tf.keras.Model(inputs=(enc_tokens, segments), outputs=(outputs_nsp, outputs_mlm))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-validity",
   "metadata": {},
   "source": [
    "아주 작은 pretrain용 BERT 모델(test_model)을 생성하여 동작을 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "desperate-intelligence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d_model': 256,\n",
       " 'n_head': 4,\n",
       " 'd_head': 64,\n",
       " 'dropout': 0.1,\n",
       " 'd_ff': 1024,\n",
       " 'layernorm_epsilon': 0.001,\n",
       " 'n_layer': 3,\n",
       " 'n_seq': 256,\n",
       " 'n_vocab': 32007,\n",
       " 'i_pad': 0}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 256, \"n_vocab\": 0, \"i_pad\": 0})\n",
    "config.n_vocab = len(vocab)\n",
    "config.i_pad = vocab.pad_id()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "acquired-scanning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2/2 [==============================] - 4s 32ms/step - loss: 11.1932 - nsp_loss: 0.7411 - mlm_loss: 10.4521 - nsp_acc: 0.6000 - mlm_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 10.0369 - nsp_loss: 0.6172 - mlm_loss: 9.4197 - nsp_acc: 0.8000 - mlm_acc: 0.0133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f81bb09fc90>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_seq = 10\n",
    "\n",
    "# make test inputs\n",
    "enc_tokens = np.random.randint(0, len(vocab), (10, n_seq))\n",
    "segments = np.random.randint(0, 2, (10, n_seq))\n",
    "labels_nsp = np.random.randint(0, 2, (10,))\n",
    "labels_mlm = np.random.randint(0, len(vocab), (10, n_seq))\n",
    "\n",
    "test_model = build_model_pre_train(config)\n",
    "test_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=[\"acc\"])\n",
    "\n",
    "# test model fit\n",
    "test_model.fit((enc_tokens, segments), (labels_nsp, labels_mlm), epochs=2, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-transparency",
   "metadata": {},
   "source": [
    "## pretrain 진행\n",
    "loss나 accuracy같이 기본적으로 필요한 계산 함수를 미리 정의해 둡시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "figured-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    loss 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # loss 계산\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    return loss * 20  # mlm을 더 잘 학습하도록 20배 증가 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "hollywood-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    acc 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # 정답 여부 확인\n",
    "    y_pred_class = tf.cast(K.argmax(y_pred, axis=-1), tf.float32)\n",
    "    matches = tf.cast(K.equal(y_true, y_pred_class), tf.float32)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=matches.dtype)\n",
    "    matches *= mask\n",
    "    # 정확도 계산\n",
    "    accuracy = K.sum(matches) / K.maximum(K.sum(mask), 1)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-serial",
   "metadata": {},
   "source": [
    "Learning Rate 스케줄링도 아래와 같이 구현합니다. WarmUp 이후 consine 형태로 감소하는 스케줄을 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "noted-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    CosineSchedule Class\n",
    "    \"\"\"\n",
    "    def __init__(self, train_steps=4000, warmup_steps=2000, max_lr=2.5e-4):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param train_steps: 학습 step 총 합\n",
    "        :param warmup_steps: warmup steps\n",
    "        :param max_lr: 최대 learning rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        assert 0 < warmup_steps < train_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.train_steps = train_steps\n",
    "        self.max_lr = max_lr\n",
    "\n",
    "    def __call__(self, step_num):\n",
    "        \"\"\"\n",
    "        learning rate 계산\n",
    "        :param step_num: 현재 step number\n",
    "        :retrun: 계산된 learning rate\n",
    "        \"\"\"\n",
    "        state = tf.cast(step_num <= self.warmup_steps, tf.float32)\n",
    "        lr1 = tf.cast(step_num, tf.float32) / self.warmup_steps\n",
    "        progress = tf.cast(step_num - self.warmup_steps, tf.float32) / max(1, self.train_steps - self.warmup_steps)\n",
    "        lr2 = 0.5 * (1.0 + tf.math.cos(math.pi * progress))\n",
    "        return (state * lr1 + (1 - state) * lr2) * self.max_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "retired-coordinator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute lr \n",
    "test_schedule = CosineSchedule(train_steps=4000, warmup_steps=500)\n",
    "lrs = []\n",
    "for step_num in range(4000):\n",
    "    lrs.append(test_schedule(float(step_num)).numpy())\n",
    "\n",
    "# draw\n",
    "plt.plot(lrs, 'r-', label='learning_rate')\n",
    "plt.xlabel('Step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-agency",
   "metadata": {},
   "source": [
    "모델을 실제로 빌드 해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "liked-discussion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_tokens (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segments (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BERT)                     ((None, 256), (None, 10629632    enc_tokens[0][0]                 \n",
      "                                                                 segments[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pooled_nsp (PooledOutput)       (None, 2)            66304       bert[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "nsp (Softmax)                   (None, 2)            0           pooled_nsp[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlm (Softmax)                   (None, None, 32007)  0           bert[0][1]                       \n",
      "==================================================================================================\n",
      "Total params: 10,695,936\n",
      "Trainable params: 10,695,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "pre_train_model = build_model_pre_train(config)\n",
    "pre_train_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-portfolio",
   "metadata": {},
   "source": [
    "이제 본격적으로 학습을 진행합니다. 1Epoch만 학습하는 데도 10분 이상의 상당한 시간이 소요될 것입니다. 그리고 메모리 오류가 날 수 있으니 배치 사이즈에도 유의해 주세요. 참고로 우리는 전체 데이터셋 중의 1/7 수준인 128000건만 로딩해서 사용 중이라는 것을 기억합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "swiss-netscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_steps: 6000\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "batch_size = 64\n",
    "\n",
    "# optimizer\n",
    "train_steps = math.ceil(len(pre_train_inputs[0]) / batch_size) * epochs\n",
    "print(\"train_steps:\", train_steps)\n",
    "learning_rate = CosineSchedule(train_steps=train_steps, warmup_steps=max(100, train_steps // 10))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# compile\n",
    "pre_train_model.compile(loss=(tf.keras.losses.sparse_categorical_crossentropy, lm_loss), optimizer=optimizer, metrics={\"nsp\": \"acc\", \"mlm\": lm_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "passing-guatemala",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 1129s 563ms/step - loss: 23.3268 - nsp_loss: 0.6576 - mlm_loss: 22.6693 - nsp_acc: 0.5813 - mlm_lm_acc: 0.0900\n",
      "\n",
      "Epoch 00001: mlm_lm_acc improved from -inf to 0.09918, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 1130s 565ms/step - loss: 20.0668 - nsp_loss: 0.6082 - mlm_loss: 19.4585 - nsp_acc: 0.6534 - mlm_lm_acc: 0.1256\n",
      "\n",
      "Epoch 00002: mlm_lm_acc improved from 0.09918 to 0.12831, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 1130s 565ms/step - loss: 19.3210 - nsp_loss: 0.5722 - mlm_loss: 18.7488 - nsp_acc: 0.7129 - mlm_lm_acc: 0.1359\n",
      "\n",
      "Epoch 00003: mlm_lm_acc improved from 0.12831 to 0.13645, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n"
     ]
    }
   ],
   "source": [
    "# save weights callback\n",
    "save_weights = tf.keras.callbacks.ModelCheckpoint(f\"{model_dir}/bert_pre_train.hdf5\", monitor=\"mlm_lm_acc\", verbose=1, save_best_only=True, mode=\"max\", save_freq=\"epoch\", save_weights_only=True)\n",
    "# train\n",
    "history = pre_train_model.fit(pre_train_inputs, pre_train_labels, epochs=epochs, batch_size=batch_size, callbacks=[save_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "crude-wrapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training result\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['nsp_loss'], 'b-', label='nsp_loss')\n",
    "plt.plot(history.history['mlm_loss'], 'r--', label='mlm_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['nsp_acc'], 'g-', label='nsp_acc')\n",
    "plt.plot(history.history['mlm_lm_acc'], 'k--', label='mlm_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-stanley",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
